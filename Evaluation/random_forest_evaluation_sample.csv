article,category,summary
Solving probability puzzles with logic toolkit,Artificial Intelligence,proposed approach formalise probabilistic puzzle equational fol two formalisations are needed one theory all models given puzzle second theory favorable models then mace computes all interpretation models fol theory called twice first it asked compute all possible models second additional constraint added mace computes only favourabile models finally definition probability applied number favorable models divided number possible models proposed approach equips students logic tribe find correct solution puzzles probabilitistic tribe using their favourite instruments modelling formalisation have exemplified here five probabilistic puzzles how they can be solved translating min fol then find corresponding interpretation models mace was tool choice here ongoing work investigating limits method various collections probabilistic puzzles
"The path inference filter: model-based low-latency map matching of probe
  vehicle data",Artificial Intelligence,we consider problem reconstructing vehicle trajectories sparse sequences gps points which sampling interval between seconds minutes we introduce new class algorithms called altogether path inference filter pif maps gps data real time variety tradeoffs scenarios high throughput numerous prior approaches mapmatching can be shown be special cases path inference filter presented article we present efficient procedure automatically training filter new data without ground truth observations framework evaluated large san francisco taxi dataset shown improve upon current state art filter also provides insights about driving patterns drivers path inference filter has been deployed industrial scale inside mobile millennium traffic information system used map fleets data san francisco sacramento stockholm porto
"Hybrid Probabilistic Inference with Logical Constraints: Tractability
  and Message Passing",Artificial Intelligence,weighted model integration wmi very appealing framework probabilistic inference it allows express complex dependencies realworld hybrid scenarios where variables are heterogeneous nature both continuous discrete via language satisfiability modulo theories smt well computing probabilistic queries arbitrarily complex logical constraints recent work has shown wmi inference be reducible model integration mi problem under some assumptions thus effectively allowing hybrid probabilistic reasoning volume computations paper we introduce novel formulation mi via message passing scheme allows efficiently compute marginal densities statistical moments all variables linear time such we are able amortize inference arbitrarily rich mi queries when they conform problem structure here represented primal graph associated smt formula furthermore we theoretically trace tractability boundaries exact mi indeed we prove terms structural requirements primal graph make our mi algorithm tractable bounding its diameter treewidth bounds are not only sufficient but necessary tractable inference via mi
"Medical Knowledge Embedding Based on Recursive Neural Network for
  Multi-Disease Diagnosis",Artificial Intelligence,representation knowledge based firstorder logic captures richness natural language supports multiple probabilistic inference models although symbolic representation enables quantitative reasoning statistical probability it difficult utilize machine learning models they perform numerical operations contrast knowledge embedding ie highdimensional continuous vectors feasible approach complex reasoning can not only retain semantic information knowledge but also establish quantifiable relationship among them paper we propose recursive neural knowledge network rnkn which combines medical knowledge based firstorder logic recursive neural network multidisease diagnosis after rnkn efficiently trained manually annotated chinese electronic medical records cemrs diagnosisoriented knowledge embeddings weight matrixes are learned experimental results verify diagnostic accuracy rnkn superior some classical machine learning models markov logic network mln results also demonstrate more explicit evidence extracted cemrs better performance achieved rnkn gradually exhibits interpretation knowledge embeddings number training epochs increases
"Self Generated Wargame AI: Double Layer Agent Task Planning Based on
  Large Language Model",Artificial Intelligence,large language models represented chatgpt have disruptive impact field artificial intelligence but it mainly focuses natural language processing speech recognition machine learning natural language understanding paper innovatively applies large language model field intelligent decisionmaking places large language model decisionmaking center constructs agent architecture large language model core based it further proposes twolayer agent task planning issues executes decision commands through interaction natural language carries out simulation verification through wargame simulation environment through game confrontation simulation experiment it found intelligent decisionmaking ability large language model significantly stronger than commonly used reinforcement learning ai rule ai intelligence understandability generalization are all better through experiments it was found intelligence large language model closely related prompt work also extends large language model previous humancomputer interaction field intelligent decisionmaking which has important reference value significance development intelligent decisionmaking
Training dynamically balanced excitatory-inhibitory networks,Disordered Systems and Neural Networks,construction biologically plausible models neural circuits crucial understanding computational properties nervous system constructing functional networks composed separate excitatory inhibitory neurons obeying dales law presents number challenges we show how targetbased approach when combined fast online constrained optimization technique capable building functional models rate spiking recurrent neural networks which excitation inhibition are balanced balanced networks can be trained produce complicated temporal patterns solve inputoutput tasks while retaining biologically desirable features such dales law response variability
"Exploring Structural Nonlinearity in Binary Polariton-Based Neuromorphic
  Architectures",Disordered Systems and Neural Networks,study investigates performance binarized neuromorphic network leveraging polariton dyads optically excited pairs interfering polariton condensates within microcavity function binary logic gate neurons employing numerical simulations we explore various neuron configurations both linear nand nor nonlinear xnor assess their effectiveness image classification tasks we demonstrate structural nonlinearity derived networks layout plays crucial role facilitating complex computational tasks effectively reducing reliance inherent nonlinearity individual neurons our findings suggest networks configuration interaction among its elements can emulate benefits nonlinearity thus potentially simplifying design manufacturing neuromorphic systems enhancing their scalability shift focus individual neuron properties network architecture could lead significant advancements efficiency applicability neuromorphic computing
Deep learning systems as complex networks,Disordered Systems and Neural Networks,thanks availability large scale digital datasets massive amounts computational power deep learning algorithms can learn representations data exploiting multiple levels abstraction these machine learning methods have greatly improved stateoftheart many challenging cognitive tasks such visual object recognition speech processing natural language understanding automatic translation particular one class deep learning models known deep belief networks can discover intricate statistical structure large data sets completely unsupervised fashion learning generative model data using hebbianlike learning mechanisms although these selforganizing systems can be conveniently formalized within framework statistical mechanics their internal functioning remains opaque because their emergent dynamics cannot be solved analytically article we propose study deep belief networks using techniques commonly employed study complex networks order gain some insights into structural functional properties computational graph resulting learning process
"Dense Hebbian neural networks: a replica symmetric picture of supervised
  learning",Disordered Systems and Neural Networks,we consider dense associative neuralnetworks trained teacher ie supervision we investigate their computational capabilities analytically via statisticalmechanics spin glasses numerically via monte carlo simulations particular we obtain phase diagram summarizing their performance function control parameters such quality quantity training dataset network storage noise valid limit large network size structureless datasets these networks may work ultrastorage regime where they can handle huge amount patterns if compared shallow neural networks ultradetection regime where they can perform pattern recognition prohibitive signaltonoise ratios if compared shallow neural networks guided random theory reference framework we also test numerically learning storing retrieval capabilities shown these networks structured datasets mnist fashion mnist technical remarks analytic side we implement large deviations stability analysis within guerras interpolation tackle notgaussian distributions involved postsynaptic potentials while computational counterpart we insert plefka approximation monte carlo scheme speed up evaluation synaptic tensors overall obtaining novel broad approach investigate supervised learning neural networks beyond shallow limit general
"Pattern recognition in the nucleation kinetics of non-equilibrium
  self-assembly",Disordered Systems and Neural Networks,inspired biologys most sophisticated computer brain neural networks constitute profound reformulation computational principles remarkably analogous highdimensional highlyinterconnected computational architectures also arise within informationprocessing molecular systems inside living cells such signal transduction cascades genetic regulatory networks might neuromorphic collective modes be found more broadly other physical chemical processes even those ostensibly play noninformationprocessing roles such protein synthesis metabolism structural selfassembly here we examine nucleation during selfassembly multicomponent structures showing highdimensional patterns concentrations can be discriminated classified manner similar neural network computation specifically we design set dna tiles can selfassemble three alternative ways such competitive nucleation depends sensitively extent colocalization highconcentration tiles within three structures system was trained insilico classify set grayscale pixel images into three categories experimentally fluorescence atomic force microscopy monitoring during after hour anneal established all trained images were correctly classified while test set image variations probed robustness results while slow compared prior biochemical neural networks our approach surprisingly compact robust scalable success suggests ubiquitous physical phenomena such nucleation may hold powerful information processing capabilities when scaled up highdimensional multicomponent systems
Prove Symbolic Regression is NP-hard by Symbol Graph,Computational Complexity,symbolic regression sr task discovering symbolic expression fits given data set space mathematical expressions despite abundance research surrounding sr problem theres scarcity works confirm its nphard nature therefore paper introduces concept symbol graph comprehensive representation entire mathematical expression space effectively illustrating nphard characteristics sr problem leveraging symbol graph we establish connection between sr problem task identifying optimally fitted degreeconstrained steiner arborescence dcsap complexity dcsap which proven be nphard directly implies nphard nature sr problem
"Improved Algorithms for Allen's Interval Algebra by Dynamic Programming
  with Sublinear Partitioning",Computational Complexity,allens interval algebra one most wellknown calculi qualitative temporal reasoning numerous applications artificial intelligence recently there has been surge improvements finegrained complexity nphard reasoning tasks improving running time naive onn even faster algorithms unit intervals bounded number overlapping intervals ocdot notation suppresses polynomial factors despite these improvements best known lower bound still only under exponentialtime hypothesis major improvements either direction seemingly require fundamental advances computational complexity paper we propose novel framework solving nphard qualitative reasoning problems which we refer dynamic programming sublinear partitioning using technique we obtain major improvement ofraccnlognn allens interval algebra demonstrate technique applicable more domains we apply it problem qualitative spatial reasoning cardinal direction point algebra solve it ofraccnlognn time hence not only do we significantly advance stateoftheart nphard qualitative reasoning problems but obtain novel algorithmic technique likely applicable many problems where time algorithms are unlikely
On SAT representations of XOR constraints,Computational Complexity,we study representation systems linear equations over twoelement field aka xor parityconstraints via conjunctive normal forms boolean clausesets first we consider problem finding arcconsistent representation ac meaning unitclause propagation will fix all forced assignments all possible instantiations xorvariables our main negative result there no polysize acrepresentation general positive side we show finding such acrepresentation fixedparameter tractable fpt number equations then we turn stronger criterion representation namely propagation completeness pc while ac only covers variables now all variables variables plus auxiliary variables are considered pc we show standard translation actually yields pc representation one equation but fails so two equations fact arbitrarily badly we show more intelligent translation we can also easily compute translation pc two equations we conjecture computing representation pc fpt number equations
"Optimization hardness as transient chaos in an analog approach to
  constraint satisfaction",Computational Complexity,boolean satisfiability ksat one most studied optimization problems efficient polynomialtime solution ksat kgeq implies efficient solutions large number hard optimization problems here we propose mapping ksat into deterministic continuoustime dynamical system unique correspondence between its attractors ksat solution clusters we show beyond constraint density threshold analog trajectories become transiently chaotic boundaries between basins attraction solution clusters become fractal signaling appearance optimization hardness analytical arguments simulations indicate system always finds solutions satisfiable formulae even frozen regimes random sat locked occupation problems considered among hardest algorithmic benchmarks property partly due systems hyperbolic character system finds solutions polynomial continuoustime however expense exponential fluctuations its energy function
Local Backbones,Computational Complexity,backbone propositional cnf formula variable whose truth value same every truth assignment satisfies formula notion backbones cnf formulas has been studied various contexts paper we introduce local variants backbones study computational complexity detecting them particular we consider kbackbones which are backbones subformulas consisting most clauses iterative kbackbones which are backbones result after repeated instantiations kbackbones we determine parameterized complexity deciding whether variable kbackbone iterative kbackbone various restricted formula classes including horn definite horn krom we also present some first empirical results regarding backbones cnfsatisfiability sat empirical results we obtain show large fraction backbones structured sat instances are local contrast random instances which appear have few local backbones
Hypertableau Reasoning for Description Logics,Logic in Computer Science,we present novel reasoning calculus description logic shoiqa knowledge representation formalism applications areas such semantic web unnecessary nondeterminism construction large models are two primary sources inefficiency tableaubased reasoning calculi used stateoftheart reasoners order reduce nondeterminism we base our calculus hypertableau hyperresolution calculi which we extend blocking condition ensure termination order reduce size constructed models we introduce anywhere pairwise blocking we also present improved nominal introduction rule ensures termination presence nominals inverse roles number restrictionsa combination dl constructs has proven notoriously difficult handle our implementation shows significant performance improvements over stateoftheart reasoners several wellknown ontologies
A syllogistic system for propositions with intermediate quantifiers,Logic in Computer Science,paper describes formalism subsumes petersons intermediate quantifier syllogistic system extends ideas van eijck aristotles logic syllogisms are expressed concise form making use extending monotonicity calculus contradictory contrary relationships are added so deduction can derive propositions expressing form negation
Logical Foundations of RDF(S) with Datatypes,Logic in Computer Science,resource description framework rdf semantic web standard provides data language simply called rdf well lightweight ontology language called rdf schema we investigate embeddings rdf logic show how standard logic programming description logic technology can be used reasoning rdf we subsequently consider extensions rdf datatype support considering entailment defined rdf semantics specification entailment semantic weakening entailment introduced ter horst we use embeddings properties logics establish novel upper bounds complexity deciding entailment we subsequently establish two novel lower bounds establishing rdfs entailment ptimecomplete simpled entailment conphard when considering arbitrary datatypes both size entailing graph results indicate rdfs may not be lightweight one may expect
"The role of semantics in mining frequent patterns from knowledge bases
  in description logics with rules",Logic in Computer Science,we propose new method mining frequent patterns language combines both semantic web ontologies rules particular we consider setting using language combines description logics dlsafe rules setting important practical application data mining semantic web we focus relation semantics representation formalism task frequent pattern discovery core our method we propose algorithm exploits semantics combined knowledge base we have developed proofofconcept data mining implementation using we have empirically shown using combined knowledge base perform semantic tests can make data mining faster pruning useless candidate patterns before their evaluation we have also shown quality set patterns produced may be improved patterns are more compact there are fewer patterns we conclude exploiting semantics chosen representation formalism key design application ontorelational frequent pattern discovery methods note appear theory practice logic programming tplp
Simple Strategies in Multi-Objective MDPs (Technical Report),Logic in Computer Science,we consider verification multiple expected reward objectives once markov decision processes mdps enables tradeoff analysis among multiple objectives obtaining pareto front we focus strategies are easy employ implement strategies are pure no randomization have bounded memory we show checking whether point achievable pure stationary strategy npcomplete even two objectives we provide milp encoding solve corresponding problem bounded memory case can be reduced stationary one product construction experimental results using storm gurobi show feasibility our algorithms
"Inducing Stackelberg Equilibrium through Spatio-Temporal Sequential
  Decision-Making in Multi-Agent Reinforcement Learning",Multiagent Systems,multiagent reinforcement learning marl selfinterested agents attempt establish equilibrium achieve coordination depending game structure however existing marl approaches are mostly bound simultaneous actions all agents markov game mg framework few works consider formation equilibrium strategies via asynchronous action coordination view advantages stackelberg equilibrium se over nash equilibrium we construct spatiotemporal sequential decisionmaking structure derived mg propose nlevel policy model based conditional hypernetwork shared all agents approach allows asymmetric training symmetric execution each agent responding optimally conditioned decisions made superior agents agents can learn heterogeneous se policies while still maintaining parameter sharing which leads reduced cost learning storage enhanced scalability number agents increases experiments demonstrate our method effectively converges se policies repeated matrix game scenarios performs admirably immensely complex settings including cooperative tasks mixed tasks
AGENT: An Adaptive Grouping Entrapping Method of Flocking Systems,Multiagent Systems,study proposes distributed algorithm makes agents adaptive grouping entrap multiple targets via automatic decision making smooth flocking welldistributed entrapping agents make their own decisions about which targets surround based environmental information improved artificial potential field method proposed enable agents smoothly naturally change formation adapt environment proposed strategies guarantee coordination swarm agents develops phenomenon multiple targets entrapping swarm level we validate performance proposed method using simulation experiments design indicators analysis these simulation physical experiments
Agent Based Approaches to Engineering Autonomous Space Software,Multiagent Systems,current approaches engineering space software such satellite control systems are based around development feedback controllers using packages such matlabs simulink toolbox these provide powerful tools engineering real time systems adapt changes environment but are limited when controller itself needs be adapted we are investigating ways which ideas temporal logics agent programming can be integrated use such control systems provide more powerful layer autonomous decision making paper will discuss our initial approaches engineering such systems
"Ball Trajectory Inference from Multi-Agent Sports Contexts Using Set
  Transformer and Hierarchical Bi-LSTM",Multiagent Systems,artificial intelligence spreads out numerous fields application ai sports analytics also spotlight however one major challenges difficulty automated acquisition continuous movement data during sports matches particular it conundrum reliably track tiny ball wide soccer pitch obstacles such occlusion imitations tackling problem paper proposes inference framework ball trajectory player trajectories costefficient alternative ball tracking we combine set transformers get permutationinvariant equivariant representations multiagent contexts hierarchical architecture intermediately predicts player ball possession support final trajectory inference also we introduce reality loss term postprocessing secure estimated trajectories be physically realistic experimental results show our model provides natural accurate trajectories well admissible player ball possession same time lastly we suggest several practical applications our framework including missing trajectory imputation semiautomated pass annotation automated zoomin match broadcasting calculating possessionwise running performance metrics
"Modeling Sensorimotor Coordination as Multi-Agent Reinforcement Learning
  with Differentiable Communication",Multiagent Systems,multiagent reinforcement learning has shown promise variety cooperative tasks consequence recent developments differentiable interagent communication however most architectures are limited pools homogeneous agents limiting their applicability here we propose modular framework learning complex tasks which traditional monolithic agent framed collection cooperating heterogeneous agents we apply approach model sensorimotor coordination neocortex multiagent reinforcement learning problem our results demonstrate proofofconcept proposed architecture open new avenues learning complex tasks understanding functional localization brain future intelligent systems
"HCGR: Hyperbolic Contrastive Graph Representation Learning for
  Session-based Recommendation",Information Retrieval,sessionbased recommendation sbr learns users preferences capturing shortterm sequential patterns evolution user behaviors among studies sbr field graphbased approaches are relatively powerful kind way which generally extract item information message aggregation under euclidean space however such methods cant effectively extract hierarchical information contained among consecutive items session which critical represent users preferences paper we present hyperbolic contrastive graph recommender hcgr principled sessionbased recommendation framework involving lorentz hyperbolic space adequately capture coherence hierarchical representations items within framework we design novel adaptive hyperbolic attention computation aggregate graph message each users preference sessionbased behavior sequence addition contrastive learning leveraged optimize item representation considering geodesic distance between positive negative samples hyperbolic space extensive experiments four realworld datasets demonstrate hcgr consistently outperforms stateoftheart baselines terms hitrate ndcg mrr
Efficient AUC Optimization for Information Ranking Applications,Information Retrieval,adequate evaluation information retrieval system estimate future performance crucial task area under roc curve auc widely used evaluate generalization retrieval system however objective function optimized many retrieval systems error rate not auc value paper provides efficient effective nonlinear approach optimize auc using additive regression trees special emphasis use multiclass auc mauc because multiple relevance levels are widely used many ranking applications compared conventional linear approach performance nonlinear approach comparable binaryrelevance benchmark datasets better multirelevance benchmark datasets
"Zero-Shot Cross-Lingual Reranking with Large Language Models for
  Low-Resource Languages",Information Retrieval,large language models llms have shown impressive zeroshot capabilities various document reranking tasks despite their successful implementations there still gap existing literature their effectiveness lowresource languages address gap we investigate how llms function rerankers crosslingual information retrieval clir systems african languages our implementation covers english four african languages hausa somali swahili yoruba we examine crosslingual reranking queries english passages african languages additionally we analyze compare effectiveness monolingual reranking using both query document translations we also evaluate effectiveness llms when leveraging their own generated translations get grasp effectiveness multiple llms our study focuses proprietary models rankgpt rankgpt along opensource model rankzephyr while reranking remains most effective english our results reveal crosslingual reranking may be competitive reranking african languages depending multilingual capability llm
"Évaluation des capacités de réponse de larges modèles de langage
  (LLM) pour des questions d'historiens",Information Retrieval,large language models llms like chatgpt bard have revolutionized information retrieval captivated audience their ability generate custom responses record time regardless topic article we assess capabilities various llms producing reliable comprehensive sufficiently relevant responses about historical facts french achieve we constructed testbed comprising numerous historyrelated questions varying types themes levels difficulty our evaluation responses ten selected llms reveals numerous shortcomings both substance form beyond overall insufficient accuracy rate we highlight uneven treatment french language well issues related verbosity inconsistency responses provided llms
"Leaf-FM: A Learnable Feature Generation Factorization Machine for
  Click-Through Rate Prediction",Information Retrieval,clickthrough rate ctr prediction plays important role personalized advertising recommender systems though many models have been proposed such fm ffm deepfm recent years feature engineering still very important way improve model performance many applications because using raw features can rarely lead optimal results example continuous features are usually transformed power forms adding new feature allow it easily form nonlinear functions feature however kind feature engineering heavily relies peoples experience it both time consuming labor consuming other side concise ctr model both fast online serving speed good model performance critical many real life applications paper we propose leaffm model based fm generate new features original feature embedding learning transformation functions automatically we also design three concrete leaffm models according different strategies combing original generated features extensive experiments are conducted three realworld datasets results show leaffm model outperforms standard fms large margin compared ffms leaffm can achieve significantly better performance much less parameters avazu malware dataset add version leaffm achieves comparable performance some deep learning based models such dnn autoint improved fm model leaffm has same computation complexity fm online serving phase it means leaffm applicable many industry applications because its better performance high computation efficiency
"Trajectory Planning for Autonomous Vehicles Using Hierarchical
  Reinforcement Learning",Robotics,planning safe trajectories under uncertain dynamic conditions makes autonomous driving problem significantly complex current samplingbased methods such rapidly exploring random trees rrts are not ideal problem because high computational cost supervised learning methods such imitation learning lack generalization safety guarantees address these problems order ensure robust framework we propose hierarchical reinforcement learning hrl structure combined proportionalintegralderivative pid controller trajectory planning hrl helps divide task autonomous vehicle driving into subgoals supports network learn policies both highlevel options lowlevel trajectory planner choices introduction subgoals decreases convergence time enables policies learned be reused other scenarios addition proposed planner made robust guaranteeing smooth trajectories handling noisy perception system egocar pid controller used tracking waypoints which ensures smooth trajectories reduces jerk problem incomplete observations handled using longshorttermmemory lstm layer network results highfidelity carla simulator indicate proposed method reduces convergence time generates smoother trajectories able handle dynamic surroundings noisy observations
"Reinforcement Learning in Robotic Motion Planning by Combined
  Experience-based Planning and Self-Imitation Learning",Robotics,highquality representative data essential both imitation learning il reinforcement learning rlbased motion planning tasks real robots it challenging collect enough qualified data either demonstrations il experiences rl due safety considerations environments obstacles we target challenge proposing selfimitation learning planning plus silp algorithm which efficiently embeds experiencebased planning into learning architecture mitigate datacollection problem planner generates demonstrations based successfully visited states current rl policy policy improves learning these demonstrations way we relieve demand human expert operators collect demonstrations required il improve rl performance well various experimental results show silp achieves better training efficiency higher more stable success rate complex motion planning tasks compared several other methods extensive tests physical robots illustrate effectiveness silp physical setting
"Online Damage Recovery for Physical Robots with Hierarchical
  Quality-Diversity",Robotics,realworld environments robots need be resilient damages robust unforeseen scenarios qualitydiversity qd algorithms have been successfully used make robots adapt damages seconds leveraging diverse set learned skills high diversity skills increases chances robot succeed overcoming new situations since there are more potential alternatives solve new taskhowever finding storing large behavioural diversity multiple skills often leads increase computational complexity furthermore robot planning large skill space additional challenge arises increased number skills hierarchical structures can help reducing search storage complexity breaking down skills into primitive skills paper we introduce hierarchical trial error algorithm which uses hierarchical behavioural repertoire learn diverse skills leverages them make robot adapt quickly physical world we show hierarchical decomposition skills enables robot learn more complex behaviours while keeping learning repertoire tractable experiments hexapod robot show our method solves maze navigation tasks less actions simulation less actions physical world most challenging scenarios than best baselines while having less complete failures
"Graph Convolution-Based Deep Reinforcement Learning for Multi-Agent
  Decision-Making in Mixed Traffic Environments",Robotics,efficient reliable multiagent decisionmaking system highly demanded safe efficient operation connected autonomous vehicles intelligent transportation systems current researches mainly focus deep reinforcement learning drl methods however utilizing drl methods interactive traffic scenarios hard represent mutual effects between different vehicles model dynamic traffic environments due lack interactive information representation environments which results low accuracy cooperative decisions generation tackle these difficulties research proposes framework enable different graph reinforcement learning grl methods decisionmaking compares their performance interactive driving scenarios grl methods combinate graph neural network gnn drl achieve better decisions generation interactive scenarios autonomous vehicles where features interactive scenarios are extracted gnn cooperative behaviors are generated drl framework several grl approaches are summarized implemented proposed framework evaluate performance proposed grl methods interactive driving scenarios highway two ramps constructed simulated experiment sumo platform carried out evaluate performance different grl approaches finally results are analyzed multiple perspectives dimensions compare characteristic different grl approaches intelligent transportation scenarios results show implementation gnn can well represents interaction between vehicles combination gnn drl able improve performance generation lanechange behaviors source code our work can be found httpsgithubcomjacklinkktorchgrl
Reinforcement Learning with Time-dependent Goals for Robotic Musicians,Robotics,reinforcement learning promising method accomplish robotic control tasks task playing musical instruments however largely unexplored because it involves challenge achieving sequential goals melodies have temporal dimension paper we address robotic musicianship introducing temporal extension goalconditioned reinforcement learning timedependent goals we demonstrate these can be used train robotic musician play theremin instrument we train robotic agent simulation transfer acquired policy realworld robotic thereminist supplemental video httpsyoutubejvcmpzdqn
Cardinality Estimation in DBMS: A Comprehensive Benchmark Evaluation,Databases,cardinality estimation cardest plays significant role generating highquality query plans query optimizer dbms last decade increasing number advanced cardest methods especially mlbased have been proposed outstanding estimation accuracy inference latency however there exists no study systematically evaluates quality these methods answer fundamental problem what extent can these methods improve performance query optimizer realworld settings which ultimate goal cardest method paper we comprehensively systematically compare effectiveness cardest methods real dbms we establish new benchmark cardest which contains new complex realworld dataset stats diverse query workload statsceb we integrate multiple most representative cardest methods into opensource database system postgresql comprehensively evaluate their true effectiveness improving query plan quality other important aspects affecting their applicability ranging inference latency model size training time update efficiency accuracy we obtain number key findings cardest methods under different data query settings furthermore we find widely used estimation accuracy metricqerror cannot distinguish importance different subplan queries during query optimization thus cannot truly reflect query plan quality generated cardest methods therefore we propose new metric perror evaluate performance cardest methods which overcomes limitation qerror able reflect overall endtoend performance cardest methods we have made all benchmark data evaluation code publicly available httpsgithubcomnathanielhanendtoendcardestbenchmark
A General Early-Stopping Module for Crowdsourced Ranking,Databases,crowdsourcing can be used determine total order object set eg top nba players based crowd opinions ranking problem often decomposed into set microtasks eg pairwise comparisons these microtasks are passed large number workers their answers are aggregated infer ranking number microtasks depends budget allocated problem intuitively higher number microtask answers more accurate ranking becomes however it often hard decide budget required accurate ranking we study how ranking process can be terminated early yet achieve highquality ranking great savings budget we use statistical tools estimate quality ranking result any stage crowdsourcing process terminate process soon desired quality achieved our proposed earlystopping module can be seamlessly integrated most existing inference algorithms task assignment methods we conduct extensive experiments show our earlystopping module better than other existing general stopping criteria we also implement prototype system demonstrate usability effectiveness our approach practice
"A Framework for Inferring Causality from Multi-Relational Observational
  Data using Conditional Independence",Databases,study causality causal inference how much given treatment causally affects given outcome population goes way beyond correlation association analysis variables critical making sound data driven decisions policies multitude applications gold standard causal inference performing controlled experiments which often not possible due logistical ethical reasons alternative inferring causality observational data based neymanrubin potential outcome model has been extensively used statistics economics social sciences over several decades paper we present formal framework sound causal analysis observational datasets are given multiple relations where population under study obtained joining these base relations we study crucial condition inferring causality observational data called strong ignorability assumption treatment outcome variables should be independent joined relation given observed covariates using known conditional independences hold base relations we also discuss how structure conditional independences base relations given graphical models help infer new conditional independences joined relation proposed framework combines concepts databases statistics graphical models aims initiate new research directions spanning these fields facilitate powerful datadriven decisions todays big data world
Mining for trees in a graph is NP-complete,Databases,mining trees graph shown be npcomplete
TaSPM: Targeted Sequential Pattern Mining,Databases,sequential pattern mining spm important technique pattern mining which has many applications reality although many efficient sequential pattern mining algorithms have been proposed there are few studies can focus target sequences targeted querying sequential patterns can not only reduce number sequences generated spm but also improve efficiency users performing pattern analysis current algorithms available targeted sequence querying are based specific scenarios cannot be generalized other applications paper we formulate problem targeted sequential pattern mining propose generic framework namely taspm based fast cmspam algorithm whats more improve efficiency taspm largescale datasets multipleitemsbased sequence datasets we propose several pruning strategies reduce meaningless operations mining processes totally four pruning strategies are designed taspm hence it can terminate unnecessary pattern extensions quickly achieve better performance finally we conduct extensive experiments different datasets compare existing spm algorithms taspm experiments show novel targeted mining algorithm taspm can achieve faster running time less memory consumption
"REFRESH: Responsible and Efficient Feature Reselection Guided by SHAP
  Values",Machine Learning,feature selection crucial step building machine learning models process often achieved accuracy objective can be cumbersome computationally expensive largescale datasets several additional model performance characteristics such fairness robustness are importance model development regulations are driving need more trustworthy models deployed models need be corrected model characteristics associated responsible artificial intelligence when feature selection done respect one model performance characteristic eg accuracy feature selection secondary model performance characteristics eg fairness robustness objectives would require going through computationally expensive selection process scratch paper we introduce problem feature emphreselection so features can be selected respect secondary model performance characteristics efficiently even after feature selection process has been done respect primary objective address problem we propose refresh method reselect features so additional constraints are desirable towards model performance can be achieved without having train several new models refreshs underlying algorithm novel technique using shap values correlation analysis can approximate predictions model without having train these models empirical evaluations three datasets including largescale loan defaulting dataset show refresh can help find alternate models better model characteristics efficiently we also discuss need reselection refresh based regulation desiderata
"GANTL: Towards Practical and Real-Time Topology Optimization with
  Conditional GANs and Transfer Learning",Machine Learning,many machine learning methods have been recently developed circumvent high computational cost gradientbased topology optimization these methods typically require extensive costly datasets training have difficult time generalizing unseen boundary loading conditions new domains do not take into consideration topological constraints predictions which produces predictions inconsistent topologies we present deep learning method based generative adversarial networks generative design exploration proposed method combines generative power conditional gans knowledge transfer capabilities transfer learning methods predict optimal topologies unseen boundary conditions we also show knowledge transfer capabilities embedded design proposed algorithm significantly reduces size training dataset compared traditional deep learning neural adversarial networks moreover we formulate topological loss function based bottleneck distance obtained persistent diagram structures demonstrate significant improvement topological connectivity predicted structures we use numerous examples explore efficiency accuracy proposed approach both seen unseen boundary conditions
Least squares binary quantization of neural networks,Machine Learning,quantizing weights activations deep neural networks results significant improvement inference efficiency cost lower accuracy source accuracy gap between full precision quantized models quantization error work we focus binary quantization which values are mapped we provide unified framework analyze different scaling strategies inspired paretooptimality bits versus bit quantization we introduce novel bits quantization provably least squares error our quantization algorithms can be implemented efficiently hardware using bitwise operations we present proofs show our proposed methods are optimal also provide empirical error analysis we conduct experiments imagenet dataset show reduced accuracy gap when using proposed least squares quantization algorithms
"Handling Data Heterogeneity in Federated Learning via Knowledge
  Distillation and Fusion",Machine Learning,federated learning fl supports distributed training global machine learning model across multiple devices help central server however data heterogeneity across different devices leads client model drift issue results model performance degradation poor model fairness address issue we design federated learning globallocal knowledge fusion fedkf scheme paper key idea fedkf let server return global knowledge be fused local knowledge each training round so local model can be regularized towards global optima therefore client model drift issue can be mitigated fedkf we first propose activeinactive model aggregation technique supports precise global knowledge representation then we propose datafree knowledge distillation kd approach enable each client model learn global knowledge embedded global model while each client model can still learn local knowledge embedded local dataset simultaneously thereby realizing globallocal knowledge fusion process theoretical analysis intensive experiments demonstrate superiority fedkf over previous solutions
How Out-of-Distribution Data Hurts Semi-Supervised Learning,Machine Learning,recent semisupervised learning algorithms have demonstrated greater success higher overall performance due betterunlabeled data representations nonetheless recent research suggests performance ssl algorithm can be degraded when unlabeled set contains outofdistribution examples oods work addresses following question how do outofdistribution ood data adversely affect semisupervised learning algorithms answer question we investigate critical causes oods negative effect ssl algorithms particular we found certain kinds ood data instances are close decision boundary have more significant impact performance than those are further away batch normalization bn popular module may degrade rather than improve performance when unlabeled set contains oods context we developed unified weighted robust ssl framework can be easily extended many existing ssl algorithms improve their robustness against oods more specifically we developed efficient bilevel optimization algorithm could accommodate highorder approximations objective scale multiple inner optimization steps learn massive number weight parameters while outperforming existing loworder approximations bilevel optimization further we conduct theoretical study impact faraway oods bn step propose weighted batch normalization wbn procedure improved performance finally we discuss connection between our approach loworder approximation techniques our experiments synthetic realworld datasets demonstrate our proposed approach significantly enhances robustness four representative ssl algorithms against oods compared four stateoftheart robust ssl strategies
"Emotion Twenty Questions Dialog System for Lexical Emotional
  Intelligence",Computation and Language (Natural Language Processing),paper presents webbased demonstration emotion twenty questions emoq dialog game whose purpose study how people describe emotions emoq can also be used develop artificially intelligent dialog agents can play game previous work emoq agent used sequential bayesian machine learning model could play questionasking role newer transformerbased neural machine learning models have made it possible develop agent questionanswering role demo paper describes recent developments questionanswering role emoq game which requires agent respond more openended inputs furthermore we also describe design system including webbased frontend agent architecture programming updates earlier software used demo system will be available collect pilot data during acii design
"Language Does More Than Describe: On The Lack Of Figurative Speech in
  Text-To-Image Models",Computation and Language (Natural Language Processing),impressive capacity shown recent texttoimage diffusion models generate highquality pictures textual input prompts has leveraged debate about very definition art nonetheless these models have been trained using text data collected contentbased labelling protocols focus describing items actions image but neglect any subjective appraisal consequently these automatic systems need rigorous descriptions elements pictorial style image be generated otherwise failing deliver potential indicators actual artistic capabilities current generative models we characterise sentimentality objectiveness degree abstraction publicly available text data used train current texttoimage diffusion models considering sharp difference observed between their language style typically employed artistic contexts we suggest generative models should incorporate additional sources subjective information their training order overcome least alleviate some their current limitations thus effectively unleashing truly artistic creative generation
Statistical Analysis of Perspective Scores on Hate Speech Detection,Computation and Language (Natural Language Processing),hate speech detection has become hot topic recent years due exponential growth offensive language social media it has proven stateoftheart hate speech classifiers are efficient only when tested data same feature distribution training data consequence model architecture plays second role improve current results such diverse data distribution relying low level features main cause deficiency due natural bias data thats why we need use high level features avoid biased judgement paper we statistically analyze perspective scores their impact hate speech detection we show different hate speech datasets are very similar when it comes extract their perspective scores eventually we prove oversampling perspective scores hate speech dataset can significantly improve generalization performance when it comes be tested other hate speech datasets
"Hypernyms under Siege: Linguistically-motivated Artillery for Hypernymy
  Detection",Computation and Language (Natural Language Processing),fundamental role hypernymy nlp has motivated development many methods automatic identification relation most which rely word distribution we investigate extensive number such unsupervised measures using several distributional semantic models differ context type feature weighting we analyze performance different methods based their linguistic motivation comparison stateoftheart supervised methods shows while supervised methods generally outperform unsupervised ones former are sensitive distribution training instances hurting their reliability being based general linguistic hypotheses independent training data unsupervised measures are more robust therefore are still useful artillery hypernymy detection
Paper Abstract Writing through Editing Mechanism,Computation and Language (Natural Language Processing),we present paper abstract writing system based attentive neural sequencetosequence model can take title input automatically generate abstract we design novel writingediting network can attend both title previously generated abstract drafts then iteratively revise polish abstract two series turing tests where human judges are asked distinguish systemgenerated abstracts humanwritten ones our system passes turing tests junior domain experts rate up nonexpert rate up
Inference Over Programs That Make Predictions,Programming Languages,abstract extends previous work describes possible further steps extend work such ultimately automatic probabilistic program synthesis can generalise over any reasonable set inputs outputs particular regard text image video data
"New parallel programming language design: a bridge between brain models
  and multi-core/many-core computers?",Programming Languages,recurrent theme paper sequences long temporal patterns opposed sequences simple statements are be fed into computation devices being them new proposed models brain activity multicoremanycore computers such models parts these long temporal patterns are already committed while other are predicted combination matching patterns making predictions appears key element producing intelligent processing brain models getting efficient speculative execution multicoremanycore computers bridge between these farapart models computation could be provided appropriate design massively parallel interactive programming languages agapia recently proposed language kind where user controlled long highlevel temporal structures occur interaction interfaces processes paper agapia used link htms brain models trips multicoremanycore architectures
"Data types as a more ergonomic frontend for Grammar-Guided Genetic
  Programming",Programming Languages,genetic programming gp heuristic method can be applied many machine learning optimization engineering problems particular it has been widely used software engineering testcase generation program synthesis improvement software gi grammarguided genetic programming gggp approaches allow user refine domain valid program solutions backus normal form most popular interface describing contextfree grammars cfg gggp bnf its derivatives have disadvantage interleaving grammar language target language program we propose embed grammar internal domainspecific language host language framework approach has same expressive power bnf ebnf while using host language typesystem take advantage all existing tooling linters formatters typecheckers autocomplete legacy code support these tools have practical utility designing software general gp systems particular we also present metahandlers userdefined overrides treegeneration system technique extends our objectoriented encoding more practicability expressive power than existing cfg approaches achieving same expressive power attribute grammars but without grammar vs target language duality furthermore we evidence approach feasible showing example python implementation proof we also compare our approach against textual bnfrepresentations wrt expressive power ergonomics these advantages do not come cost performance shown our empirical evaluation benchmarks our example implementation against ponyge we conclude our approach has better ergonomics same expressive power performance textual bnfbased grammar encodings
"Timed Soft Concurrent Constraint Programs: An Interleaved and a Parallel
  Approach",Programming Languages,we propose timed soft extension concurrent constraint programming time extension based hypothesis bounded asynchrony computation takes bounded period time measured discrete global clock action prefixing then considered syntactic marker which distinguishes time instant next one supported soft constraints instead crisp ones tell ask agents are now equipped preference consistency threshold which used determine their success suspension paper we provide language describe agents behavior together its operational denotational semantics which we also prove compositionality correctness properties after presenting semantics using maximal parallelism actions we also describe version their interleaving single processor maximal parallelism time elapsing coordinating agents need take decisions both preference values time events may benefit language appear theory practice logic programming tplp
Synthesizing Imperative Programs from Examples Guided by Static Analysis,Programming Languages,we present novel algorithm synthesizes imperative programs introductory programming courses given set inputoutput examples partial program our algorithm generates complete program consistent every example our key idea combine enumerative program synthesis static analysis which aggressively prunes out large search space while guaranteeing find if any correct solution we have implemented our algorithm tool called simpl evaluated it problems used introductory programming courses results show simpl able solve benchmark problems seconds average
"Adaptive Task Allocation for Asynchronous Federated and Parallelized
  Mobile Edge Learning","Distributed, Parallel, and Cluster Computing",paper proposes scheme efficiently execute distributed learning tasks asynchronous manner while minimizing gradient staleness wireless edge nodes heterogeneous computing communication capacities approach considered paper ensures all devices work certain duration covers time datamodel distribution learning iterations model collection global aggregation resulting problem integer nonconvex program quadratic equality constraints well linear equality inequality constraints because problem nphard we relax integer constraints order solve it efficiently available solvers analytical bounds are derived using kkt conditions lagrangian analysis conjunction suggestandimprove approach results show our approach reduces gradient staleness can offer better accuracy than synchronous scheme asynchronous scheme equal task allocation
"Beyond the Memory Wall: A Case for Memory-centric HPC System for Deep
  Learning","Distributed, Parallel, and Cluster Computing",models datasets train deep learning dl models scale system architects are faced new challenges one which memory capacity bottleneck where limited physical memory inside accelerator device constrains algorithm can be studied we propose memorycentric deep learning system can transparently expand memory capacity available accelerators while also providing fast interdevice communication parallel training our proposal aggregates pool memory modules locally within deviceside interconnect which are decoupled host interface function vehicle transparent memory capacity expansion compared conventional systems our proposal achieves average speedup eight dl applications increases systemwide memory capacity tens tbs
Simulating Performance of ML Systems with Offline Profiling,"Distributed, Parallel, and Cluster Computing",we advocate simulation based offline profiling promising approach better understand improve complex ml systems our approach uses operationlevel profiling dataflow based simulation ensure it offers unified automated solution all frameworks ml models also accurate considering various parallelization strategies real system
"Tessel: Boosting Distributed Execution of Large DNN Models via Flexible
  Schedule Search","Distributed, Parallel, and Cluster Computing",increasingly complex diverse deep neural network dnn models necessitate distributing execution across multiple devices training inference tasks also require carefully planned schedules performance however existing practices often rely predefined schedules may not fully exploit benefits emerging diverse modelaware operator placement strategies handcrafting highefficiency schedules can be challenging due large varying schedule space paper presents tessel automated system searches efficient schedules distributed dnn training inference diverse operator placement strategies reduce search costs tessel leverages insight most efficient schedules often exhibit repetitive pattern repetend across different data inputs leads twophase approach repetend construction schedule completion exploring schedules various operator placement strategies tessel significantly improves both training inference performance experiments representative dnn models demonstrate tessel achieves up training performance speedup up inference latency reduction
"Toward Scalable Machine Learning and Data Mining: the Bioinformatics
  Case","Distributed, Parallel, and Cluster Computing",effort overcome data deluge computational biology bioinformatics facilitate bioinformatics research era big data we identify some most influential algorithms have been widely used bioinformatics community these top data mining machine learning algorithms cover classification clustering regression graphical modelbased learning dimensionality reduction goal study guide focus scalable computing experts endeavor applying new storage scalable computation designs bioinformatics algorithms merit their attention most following engineering maxim optimize common case
A Learned Performance Model for Tensor Processing Units,Performance,accurate hardware performance models are critical efficient code generation they can be used compilers make heuristic decisions superoptimizers minimization objective autotuners find optimal configuration specific program however they are difficult develop because contemporary processors are complex recent proliferation deep learning accelerators has increased development burden we demonstrate method learning performance models corpus tensor computation graph programs tensor processing unit tpu instances we show our learned model outperforms heavilyoptimized analytical performance model two tasks tilesize selection operator fusion it helps autotuner discover faster programs setting where access tpus limited expensive
"On the Practicality of Intrinsic Reconfiguration As a Fault Recovery
  Method in Analog Systems",Performance,evolvable hardware combines powerful search capability evolutionary algorithms flexibility reprogrammable devices thereby providing natural framework reconfiguration framework has generated interest using evolvable hardware faulttolerant systems because reconfiguration can effectively deal hardware faults whenever it impossible provide spares but systems cannot tolerate faults indefinitely which means reconfiguration does have deadline focus previous evolvable hardware research relating faulttolerance has been primarily restricted restoring functionality no real consideration time constraints paper we are concerned evolvable hardware performing reconfiguration under deadline constraints particular we investigate reconfigurable hardware undergoes intrinsic evolution we show fault recovery done intrinsic reconfiguration has some restrictions which designers cannot ignore
A Comparative Measurement Study of Deep Learning as a Service Framework,Performance,big data powered deep learning dl its applications have blossomed recent years fueled three technological trends large amount digitized data openly accessible growing number dl software frameworks open source commercial markets selection affordable parallel computing hardware devices however no single dl framework date dominates terms performance accuracy even baseline classification tasks standard datasets making selection dl framework overwhelming task paper takes holistic approach conduct empirical comparison analysis four representative dl frameworks three unique contributions first given selection cpugpu configurations we show specific dl framework different configurations its hyperparameters may have significant impact both performance accuracy dl applications second best our knowledge study first identify opportunities improving training time performance accuracy dl frameworks configuring parallel computing libraries tuning individual multiple hyperparameters third we also conduct comparative measurement study resource consumption patterns four dl frameworks their performance accuracy implications including cpu memory usage their correlations varying settings hyperparameters under different configuration combinations hardware parallel computing libraries we argue measurement study provides indepth empirical comparison analysis four representative dl frameworks offers practical guidance service providers deploying delivering dl service dlaas application developers dlaas consumers select right dl frameworks right dl workloads
"RL-QN: A Reinforcement Learning Framework for Optimal Control of
  Queueing Systems",Performance,rapid advance information technology network systems have become increasingly complex hence underlying system dynamics are often unknown difficult characterize finding good network control policy significant importance achieve desirable network performance eg high throughput low delay work we consider using modelbased reinforcement learning rl learn optimal control policy queueing networks so average job delay equivalently average queue backlog minimized traditional approaches rl however cannot handle unbounded state spaces network control problem overcome difficulty we propose new algorithm called reinforcement learning queueing networks rlqn which applies modelbased rl methods over finite subset state space while applying known stabilizing policy rest states we establish average queue backlog under rlqn appropriately constructed subset can be arbitrarily close optimal result we evaluate rlqn dynamic server allocation routing switching problems simulation results show rlqn minimizes average queue backlog effectively
A Learned Performance Model for Tensor Processing Units,Performance,accurate hardware performance models are critical efficient code generation they can be used compilers make heuristic decisions superoptimizers minimization objective autotuners find optimal configuration specific program however they are difficult develop because contemporary processors are complex recent proliferation deep learning accelerators has increased development burden we demonstrate method learning performance models corpus tensor computation graph programs tensor processing unit tpu instances we show our learned model outperforms heavilyoptimized analytical performance model two tasks tilesize selection operator fusion it helps autotuner discover faster programs setting where access tpus limited expensive
"A Cumulative Multi-Niching Genetic Algorithm for Multimodal Function
  Optimization",Neural and Evolutionary Computing,paper presents cumulative multiniching genetic algorithm cmn ga designed expedite optimization problems have computationallyexpensive multimodal objective functions never discarding individuals population cmn ga makes use information every objective function evaluation it explores design space fitnessrelated population density control over design space reduces unnecessary objective function evaluations algorithms novel arrangement genetic operations provides fast robust convergence multiple local optima benchmark tests alongside three other multiniching algorithms show cmn ga has greater convergence ability provides orderofmagnitude reduction number objective function evaluations required achieve given level convergence
"High-Order Associative Learning Based on Memristive Circuits for
  Efficient Learning",Neural and Evolutionary Computing,memristive associative learning has gained significant attention its ability mimic fundamental biological learning mechanisms while maintaining system simplicity work we introduce highorder memristive associative learning framework biologically realistic structure utilizing memristors synaptic modules their state information bridge different orders associative learning our design effectively establishes associations between multiple stimuli replicates transient nature highorder associative learning pavlovs classical conditioning experiments our design achieves improvement learning efficiency compared previous works memristor power consumption synaptic modules remaining below muw largescale image recognition tasks we utilize memristor array represent images enabling system recognize label test images semantic information accuracy scalability across different tasks highlights frameworks potential wide range applications offering enhanced learning efficiency current memristorbased neuromorphic systems
Training an Ising Machine with Equilibrium Propagation,Neural and Evolutionary Computing,ising machines which are hardware implementations ising model coupled spins have been influential development unsupervised learning algorithms origins artificial intelligence ai however their application ai has been limited due complexities matching supervised training methods ising machine physics even though these methods are essential achieving high accuracy study we demonstrate novel approach train ising machines supervised way through equilibrium propagation algorithm achieving comparable results softwarebased implementations we employ quantum annealing procedure dwave ising machine train fullyconnected neural network mnist dataset furthermore we demonstrate machines connectivity supports convolution operations enabling training compact convolutional network minimal spins per neuron our findings establish ising machines promising trainable hardware platform ai potential enhance machine learning applications
"EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking
  Neural Networks",Neural and Evolutionary Computing,vast majority spiking neural networks snns are trained based inductive biases are not necessarily good fit several critical tasks require lowlatency power efficiency inferring brain behavior based associated electroenchephalography eeg signals example how networks training inference efficiency can be heavily impacted learning spatiotemporal dependencies up now snns rely solely general inductive biases model dynamic relations between different data streams here we propose graph spiking neural network architecture multichannel eeg classification eegsn learns dynamic relational information present distributed eeg sensors our method reduced inference computational complexity times compared stateoftheart snns while achieved comparable accuracy motor execution classification tasks overall our work provides framework interpretable efficient training graph spiking networks are suitable lowlatency lowpower realtime applications
"Why don't the modules dominate - Investigating the Structure of a
  Well-Known Modularity-Inducing Problem Domain",Neural and Evolutionary Computing,wagners modularity inducing problem domain key contribution study evolution modularity including both evolutionary theory evolutionary computation we study its behavior under classical genetic algorithms unlike what we seem observe nature emergence modularity highly conditional dependent example eagerness search nature modular solutions generally dominate populations whereas domain modularity when it emerges relatively rare variant emergence modularity depends heavily random fluctuations fitness function randomly varied but unchanging fitness function modularity evolved far more rarely interestingly highfitness nonmodular solutions could frequently be converted into evenhigherfitness modular solutions manually removing all intermodule edges despite careful exploration we do not yet have full explanation why genetic algorithm was unable find these better solutions
"Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent
  Large Spatial-Temporal Data-Driven Approach -- Part 1","Computational Engineering, Finance, and Science",study novel coordinative scheduling optimization approach proposed enhance port efficiency reducing average wait time turnaround time proposed approach consists enhanced particle swarm optimization epso kernel augmented firefly algorithm afa global optimal search two paradigm methods proposed approach are investigated which are batch method rolling horizon method experimental results show both paradigm methods proposed approach can effectively enhance port efficiency average wait time could be significantly reduced average turnaround time could eventually save respect historical benchmarks moreover paradigm method rolling horizon could reduce mins running time over month datasets rather than hrs batch method corresponding maximum performance
"Investigating the Detection of Adverse Drug Events in a UK General
  Practice Electronic Health-Care Database","Computational Engineering, Finance, and Science",datamining techniques have frequently been developed spontaneous reporting databases these techniques aim find adverse drug events accurately efficiently spontaneous reporting databases are prone missing information under reporting incorrect entries often results detection lag prevents detection some adverse drug events these limitations do not occur electronic healthcare databases paper existing methods developed spontaneous reporting databases are implemented both spontaneous reporting database general practice electronic healthcare database compared results suggests application existing methods general practice database may help find signals have gone undetected when using spontaneous reporting system database addition general practice database provides far more supplementary information if incorporated analysis could provide wealth information identifying adverse events more accurately
"A New Approach to the Solution of Economic Dispatch Using Particle Swarm
  Optimization with Simulated Annealing","Computational Engineering, Finance, and Science",new approach solution economic dispatch using particle swarm optimization presented it progression allocating production amongst dedicated units such restriction forced are fulfilled power needs are reduced more just soft computing method has received supplementary concentration was used quantity successful sensible applications here attempt has been made find out minimum cost using particle swarm optimization algorithm using data three generating units work data has been taken such loss coefficients maxmin power limit cost function pso simulated annealing are functional put out least amount dissimilar energy requirements when outputs are compared conventional method pso seems give improved result enhanced convergence feature all methods are executed matlab environment effectiveness feasibility proposed method were demonstrated three generating units case study output gives hopeful results signifying projected method calculation competent economically formative advanced eminence solutions addressing economic dispatch problems
"A Self-Taught Artificial Agent for Multi-Physics Computational Model
  Personalization","Computational Engineering, Finance, and Science",personalization process fitting model patient data critical step towards application multiphysics computational models clinical practice designing robust personalization algorithms often tedious timeconsuming model dataspecific process we propose use artificial intelligence concepts learn task inspired how human experts manually perform it problem reformulated terms reinforcement learning offline phase vito our selftaught artificial agent learns representative decision process model through exploration computational model it learns how model behaves under change parameters agent then automatically learns optimal strategy online personalization algorithm modelindependent applying it new model requires only adjusting few hyperparameters agent defining observations match full knowledge model itself not required vito was tested synthetic scenario showing it could learn how optimize cost functions generically then vito was applied inverse problem cardiac electrophysiology personalization wholebody circulation model obtained results suggested vito could achieve equivalent if not better goodness fit than standard methods while being more robust up higher success rates faster up seven times convergence rate our artificial intelligence approach could thus make personalization algorithms generalizable selfadaptable any patient any model
"Plastic Arbor: a modern simulation framework for synaptic plasticity
  $\unicode{x2013}$ from single synapses to networks of morphological neurons","Computational Engineering, Finance, and Science",arbor software library designed efficient simulation largescale networks biological neurons detailed morphological structures it combines customizable neuronal synaptic mechanisms highperformance computing supporting multicore cpu gpu systems humans other animals synaptic plasticity processes play vital role cognitive functions including learning memory recent studies have shown intracellular molecular processes dendrites significantly influence singleneuron dynamics however understanding how complex interplay between dendrites synaptic processes influences network dynamics computational modeling required enable modeling largescale networks morphologically detailed neurons diverse plasticity processes we have extended arbor library plastic arbor framework supporting simulations large variety spikedriven plasticity paradigms showcase features new framework we present examples computational models beginning singlesynapse dynamics progressing multisynapse rules finally scaling up large recurrent networks while crossvalidating our implementations comparison other simulators we show arbor allows simulating plastic networks multicompartment neurons nearly no additional cost runtime compared pointneuron simulations using new framework we have already been able investigate impact dendritic structures network dynamics across timescale several hours showing relation between length dendritic trees ability network efficiently store information our extension arbor we aim provide valuable tool will support future studies impact synaptic plasticity especially conjunction neuronal morphology large networks
Momen(e)t: Flavor the Moments in Learning to Classify Shapes,Computational Geometry,fundamental question learning classify shapes how treat data way would allow us construct efficient accurate geometric processing analysis procedures here we restrict ourselves networks operate point clouds there were several attempts treat point clouds nonstructured data sets which neural network trained extract discriminative properties idea using coordinates class identifiers motivated us extend line thought shape classification comparing attributes could easily account shape moments here we propose add polynomial functions coordinates allowing network account higher order moments given shape experiments two benchmarks show suggested network able provide state art results same token learn more efficiently terms memory computational complexity
Structural Design Using Laplacian Shells,Computational Geometry,we introduce method design lightweight shell objects are structurally robust under external forces they may experience during use given input model general description external forces our algorithm generates structurallysound minimum weight shell object our approach works altering local shell thickness repeatedly based stresses develop inside object key issue shell design large thickness values might result selfintersections inner boundary creating significant computational challenge during optimization address we propose shape parametrization based solution laplaces equation guarantees smooth intersectionfree shell boundaries combined our gradientfree optimization algorithm our method provides practical solution structural design hollow objects single inner cavity we demonstrate our method variety problems arbitrary models under complex force configurations validate its performance physical experiments
"Peacock Bundles: Bundle Coloring for Graphs with Globality-Locality
  Trade-off",Computational Geometry,bundling graph edges nodetonode connections common technique enhance visibility overall trends edge structure large graph layout large variety bundling algorithms have been proposed however strong bundling it becomes hard identify origins destinations individual edges we propose solution we optimize edge coloring differentiate bundled edges we quantify strength bundling flexible pairwise fashion between edges among bundled edges we quantify how dissimilar their colors should be dissimilarity their origins destinations we solve resulting nonlinear optimization which also interpretable novel dimensionality reduction task large graphs necessary compromise whether differentiate colors sharply between locally occurring strongly bundled edges local bundles also between weakly bundled edges occurring globally over graph global bundles we allow userset globallocal tradeoff we call technique peacock bundles experiments show coloring clearly enhances comprehensibility graph layouts edge bundling
A Grid-based Approach for Convexity Analysis of a Density-based Cluster,Computational Geometry,paper presents novel geometrical approach investigate convexity densitybased cluster our approach gridbased we are about calibrate value space cluster however cluster objects are coming infinite distribution their number finite thus regarding shape will not be sharp therefore we establish precision grid properly way reliable approximate boundaries cluster are founded after regarding simple notion convex sets midpoint convexity we investigate whether not densitybased cluster convex moreover our experiments synthetic datasets demonstrate desirable performance our method
"The Effectiveness of Johnson-Lindenstrauss Transform for High
  Dimensional Optimization With Adversarial Outliers, and the Recovery",Computational Geometry,paper we consider robust optimization problems high dimensions because realworld dataset may contain significant noise even specially crafted samples some attacker we are particularly interested optimization problems arbitrary potentially adversarial outliers we focus two fundamental optimization problems em svm outliers em kcenter clustering outliers they are fact extremely challenging combinatorial optimization problems since we cannot impose any restriction adversarial outliers therefore their computational complexities are quite high especially when we consider instances high dimensional spaces em johnsonlindenstrauss jl transform one most popular methods dimension reduction though jl transform has been widely studied past decades its effectiveness dealing adversarial outliers has never been investigated before best our knowledge based some novel insights geometry we prove complexities these two problems can be significantly reduced through jl transform moreover we prove solution dimensionalityreduced space can be efficiently recovered original mathbbrd while quality still preserved experiments we compare jl transform several other well known dimension reduction methods study their performances synthetic real datasets
Interpreting Deep Learning-Based Networking Systems,Networking and Internet Architecture,while many deep learning dlbased networking systems have demonstrated superior performance underlying deep neural networks dnns remain blackboxes stay uninterpretable network operators lack interpretability makes dlbased networking systems prohibitive deploy practice paper we propose metis framework provides interpretability two general categories networking problems spanning local global control accordingly metis introduces two different interpretation methods based decision tree hypergraph where it converts dnn policies interpretable rulebased controllers highlight critical components based analysis over hypergraph we evaluate metis over several stateoftheart dlbased networking systems show metis provides humanreadable interpretations while preserving nearly no degradation performance we further present four concrete use cases metis showcasing how metis helps network operators design debug deploy adhoc adjust dlbased networking systems
"DeepSIP: A System for Predicting Service Impact of Network Failure by
  Temporal Multimodal CNN",Networking and Internet Architecture,when failure occurs network network operators need recognize service impact since service impact essential information handling failures paper we propose deep learning based service impact prediction deepsip system predict time recovery failure loss traffic volume due failure network element using temporal multimodal convolutional neural network cnn since time recovery useful information service level agreement sla loss traffic volume directly related severity failures we regard these service impact service impact challenging predict since network element does not explicitly contain any information about service impact thus we aim predict service impact syslog messages traffic volume extracting hidden information about failures extract useful features prediction syslog messages traffic volume which are multimodal strongly correlated have temporal dependencies we use temporal multimodal cnn we experimentally evaluated deepsip deepsip reduced prediction error approximately comparison other nnbased methods synthetic dataset
Machine Learning for Wireless Link Quality Estimation: A Survey,Networking and Internet Architecture,since emergence wireless communication networks plethora research papers focus their attention quality aspects wireless links analysis rich body existing literature link quality estimation using models developed data traces indicates techniques used modeling link quality estimation are becoming increasingly sophisticated number recent estimators leverage machine learning ml techniques require sophisticated design development process each which has great potential significantly affect overall model performance paper we provide comprehensive survey link quality estimators developed empirical data then focus subset use ml algorithms we analyze mlbased link quality estimation lqe models two perspectives using performance data firstly we focus how they address quality requirements are important perspective applications they serve secondly we analyze how they approach standard design steps commonly used ml community having analyzed scientific body survey we review existing open source datasets suitable lqe research finally we round up our survey lessons learned design guidelines mlbased lqe development dataset collection
"Intelligent Automated Diagnosis of Client Device Bottlenecks in Private
  Clouds",Networking and Internet Architecture,we present automated solution rapid diagnosis client device problems private cloud environments intelligent automated client diagnostic iacd system clients are diagnosed aid transmission control protocol tcp packet traces observation anomalous artifacts occurring result each fault ii subsequent use inference capabilities softmargin support vector machine svm classifiers iacd system features modular design extendible new faults detection capability unaffected tcp variant used client experimental evaluation iacd system controlled environment demonstrated overall diagnostic accuracy
"Cardinality Estimation in a Virtualized Network Device Using Online
  Machine Learning",Networking and Internet Architecture,cardinality estimation algorithms receive stream elements possible repetitions return number distinct elements stream such algorithms seek minimize required memory cpu resource consumption price inaccuracy their output computer networks cardinality estimation algorithms are mainly used counting number distinct flows they are divided into two categories sketching algorithms sampling algorithms sketching algorithms require processing all packets they are therefore usually implemented dedicated hardware sampling algorithms do not require processing all packets but they are known their inaccuracy work we identify one major drawbacks samplingbased cardinality estimation algorithms their inability adapt changes flow size distribution address problem we propose new samplingbased adaptive cardinality estimation framework which uses online machine learning we evaluate our framework using real traffic traces show significantly better accuracy compared best known samplingbased algorithms same fraction processed packets
Reasoning about Human-Friendly Strategies in Repeated Keyword Auctions,Computer Science and Game Theory,online advertising search engines sell ad placements keywords continuously through auctions problem can be seen infinitely repeated game since auction executed whenever user performs query keyword advertisers may frequently change their bids game will have large set equilibria potentially complex strategies paper we propose use natural strategies reasoning such setting they are processable artificial agents limited memory andor computational power well understandable human users reach goal we introduce quantitative version strategy logic natural strategies setting imperfect information first step we show how model strategies repeated keyword auctions take advantage model proving properties evaluating game second step we study logic relation distinguishing power expressivity modelchecking complexity strategies without recall
Multi-scale Online Learning and its Applications to Online Auctions,Computer Science and Game Theory,we consider revenue maximization online auctionpricing problems seller sells identical item each period new buyer new set buyers online posted pricing problem we show regret bounds scale best fixed price rather than range values we also show regret bounds are almost scale free match offline sample complexity when comparing benchmark requires lower bound market share these results are obtained generalizing classical learning experts multiarmed bandit problems their multiscale versions version reward each action different range regret wrt given action scales its own range rather than maximum range
Safe Search for Stackelberg Equilibria in Extensive-Form Games,Computer Science and Game Theory,stackelberg equilibrium solution concept twoplayer games where leader has commitment rights over follower recent years it has become cornerstone many security applications including airport patrolling wildlife poaching prevention even though many these settings are sequential nature existing techniques precompute entire solution ahead time paper we present theoretically sound empirically effective way apply search which leverages extra online computation improve solution computation stackelberg equilibria generalsum games instead leader attempting solve full game upfront approximate blueprint solution first computed offline then improved online particular subgames encountered actual play we prove our search technique guaranteed perform no worse than precomputed blueprint strategy empirically demonstrate it enables approximately solving significantly larger games compared purely offline methods we also show our search operation may be cast smaller stackelberg problem making our method complementary existing algorithms based strategy generation
A Decision-Optimization Approach to Quantum Mechanics and Game Theory,Computer Science and Game Theory,fundamental laws quantum world upsets logical foundation classic physics they are completely counterintuitive many bizarre behaviors however paper shows they may make sense perspective general decisionoptimization principle cooperation principle also offers generalization nash equilibrium key concept game theory better payoffs stability game playing
Differentially Private Condorcet Voting,Computer Science and Game Theory,designing private voting rules important pressing problem trustworthy democracy paper under framework differential privacy we propose novel famliy randomized voting rules based wellknown condorcet method focus three classes voting rules family laplacian condorcet method cmlaplambda exponential condorcet method cmexplambda randomized response condorcet method cmrrlambda where lambda represents level noise we prove all our rules satisfy absolute monotonicity lexiparticipation probabilistic pareto efficiency approximate probabilistic condorcet criterion approximate sdstrategyproofness addition cmrrlambda satisfies nonapproximate probabilistic condorcet criterion while cmlaplambda cmexplambda satisfy strong lexiparticipation finally we regard differential privacy voting axiom discuss its relations other axioms
Is Mapping Necessary for Realistic PointGoal Navigation?,Computer Vision and Pattern Recognition,can autonomous agent navigate new environment without building explicit map task pointgoal navigation go delta delta under idealized settings no rgbd actuation noise perfect gpscompass answer clear yes mapless neural models composed taskagnostic components cnns rnns trained largescale reinforcement learning achieve success standard dataset gibson however pointnav realistic setting rgbd actuation noise no gpscompass open question one we tackle paper strongest published result task success first we identify main perhaps only cause drop performance absence gpscompass agent perfect gpscompass faced rgbd sensing actuation noise achieves success gibsonv val suggests paraphrase meme robust visual odometry all we need realistic pointnav if we can achieve we can ignore sensing actuation noise our operating hypothesis we scale dataset model size develop humanannotationfree dataaugmentation techniques train models visual odometry we advance state art habitat realistic pointnav challenge success relative spl relative while our approach does not saturate solve dataset strong improvement combined promising zeroshot simreal transfer locobot provides evidence consistent hypothesis explicit mapping may not be necessary navigation even realistic setting
Sparse R-CNN: End-to-End Object Detection with Learnable Proposals,Computer Vision and Pattern Recognition,we present sparse rcnn purely sparse method object detection images existing works object detection heavily rely dense object candidates such anchor boxes predefined all grids image feature map size htimes our method however fixed sparse set learned object proposals total length are provided object recognition head perform classification location eliminating hwk up hundreds thousands handdesigned object candidates eg learnable proposals sparse rcnn completely avoids all efforts related object candidates design manytoone label assignment more importantly final predictions are directly output without nonmaximum suppression postprocedure sparse rcnn demonstrates accuracy runtime training convergence performance par wellestablished detector baselines challenging coco dataset eg achieving ap standard times training schedule running fps using resnet fpn model we hope our work could inspire rethinking convention dense prior object detectors code available httpsgithubcompeizesunsparsercnn
"MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale
  Point Clouds",Computer Vision and Pattern Recognition,semantic segmentation point cloud essential task autonomous driving environment perception pipeline most pointwise point cloud semantic segmentation methods includes points sampling neighbor searching feature aggregation classification neighbor searching method like knearest neighbors algorithm knn has been widely applied however complexity knn always bottleneck efficiency paper we propose endtoend neural architecture multiple view pointwise net mvpnet efficiently directly infer largescale outdoor point cloud without knn any complex prepostprocessing instead assumptionbased space filling curves multirotation point cloud methods are introduced point feature aggregation receptive field expanding numerical experiments show proposed mvpnet times faster than most efficient pointwise semantic segmentation method randlanet achieves same accuracy largescale benchmark semantickitti dataset
RBIR Based on Signature Graph,Computer Vision and Pattern Recognition,paper approaches image retrieval system base visual features local region rbir regionbased image retrieval first all paper presents method extracting interest points based harrislaplace create feature region image next order reduce storage space speed up query image paper builds binary signature structure describe visual content image based images binary signature paper builds sg signature graph classify store images binary signatures since then paper builds image retrieval algorithm sg through similar measure emd earth movers distance between images binary signatures last but not least paper gives image retrieval model rbir experiments assesses image retrieval method corel image database over images
Densely Nested Top-Down Flows for Salient Object Detection,Computer Vision and Pattern Recognition,goal identifying pixelwise salient object regions each input image salient object detection sod has been receiving great attention recent years one kind mainstream sod methods formed bottomup feature encoding procedure topdown information decoding procedure while numerous approaches have explored bottomup feature extraction task design topdown flows still remains understudied end paper revisits role topdown modeling salient object detection designs novel densely nested topdown flows dntdfbased framework every stage dntdf features higher levels are read via progressive compression shortcut paths pcsp notable characteristics our proposed method are follows propagation highlevel features which usually have relatively strong semantic information enhanced decoding procedure help pcsp gradient vanishing issues caused nonlinear operations topdown information flows can be alleviated thanks full exploration highlevel features decoding process our method relatively memory efficient compared against those existing methods integrating dntdf efficientnet we construct highly lightweighted sod model very low computational complexity demonstrate effectiveness proposed model comprehensive experiments are conducted six widelyused benchmark datasets comparisons most stateoftheart methods well carefullydesigned baseline models verify our insights topdown flow modeling sod code paper available httpsgithubcomnewstoneobjectdntd
Aerospace Human System Integration Evolution over the Last 40 Years,Human-Computer Interaction,chapter focuses evolution humancentered design hcd aerospace systems over last forty years human factors ergonomics first shifted study physical medical issues cognitive issues circa advent computers brought it development humancomputer interaction hci which then expanded into field digital interaction design user experience ux we ended up concept interactive cockpits not because pilots interacted mechanical things but because they interacted using pointing devices computer displays since early complexity organizational issues gained prominence point complex systems design management found itself center stage spotlight role human element organizational setups today human systems integration hsi no longer only singleagent problem but multiagent research field systems are systems systems considered representations people machines they are made statically dynamically articulated structures functions when they are work they are living organisms generate emerging functions structures need be considered evolution ie their constant redesign chapter will more specifically focus human factors such humancentered systemic representations life critical systems organizational issues complexity management modeling simulation flexibility tangibility autonomy discussion will be based several examples civil aviation air combat well aerospace
"Emotion Recognition From Gait Analyses: Current Research and Future
  Directions",Human-Computer Interaction,human gait refers daily motion represents not only mobility but it can also be used identify walker either human observers computers recent studies reveal gait even conveys information about walkers emotion individuals different emotion states may show different gait patterns mapping between various emotions gait patterns provides new source automated emotion recognition compared traditional emotion detection biometrics such facial expression speech physiological parameters gait remotely observable more difficult imitate requires less cooperation subject these advantages make gait promising source emotion detection article reviews current research gaitbased emotion detection particularly how gait parameters can be affected different emotion states how emotion states can be recognized through distinct gait patterns we focus detailed methods techniques applied whole process emotion recognition data collection preprocessing classification last we discuss possible future developments efficient effective gaitbased emotion recognition using state art techniques intelligent computation big data
"PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators
  and Participants in Children's Collaborative Learning",Human-Computer Interaction,childrens collaborative learning effective peer conversations can significantly enhance quality childrens collaborative interactions integration large language model llm agents into setting explores their novel role peers assessing impacts team moderators participants we invited two groups participants engage collaborative learning workshop where they discussed proposed conceptual solutions design problem peer conversation transcripts were analyzed using thematic analysis we discovered peer agents while managing discussions effectively team moderators sometimes have their instructions disregarded participants they foster childrens creative thinking but may not consistently provide timely feedback these findings highlight potential design improvements considerations peer agents both roles
"DeepShovel: An Online Collaborative Platform for Data Extraction in
  Geoscience Literature with AI Assistance",Human-Computer Interaction,geoscientists well researchers many fields need read huge amount literature locate extract aggregate relevant results data enable future research build scientific database but there no existing system support use case well paper based findings formative study about how geoscientists collaboratively annotate literature extract aggregate data we proposed deepshovel publiclyavailable aiassisted data extraction system support their needs deepshovel leverages stateoftheart neural network models support researchers easily accurately annotate papers pdf format extract data tables figures maps etc humanai collaboration manner followup user evaluation researchers suggested deepshovel improved users efficiency data extraction building scientific databases encouraged teams form larger scale but more tightlycoupled collaboration
"Post-human interaction design, yes, but cautiously",Human-Computer Interaction,posthuman design runs risk obscuring fact ai technology actually imports cartesian humanist logic which subsequently influences how we design conceive socalled smart intelligent objects leads unwanted metaphorical attributions human qualities smart objects instead starting embodied sensemaking perspective designers should demand engineers radically transform very structure ai technology order truly support critical posthuman values collectivity relationality community building
"A proactive malicious software identification approach for digital
  forensic examiners",Cryptography and Security,digital investigators often get involved cases which seemingly point responsibility person which computer belongs but after thorough examination malware proven be cause causing loss precious time whilst antivirus av software can assist investigator identifying presence malware increase zeroday attacks errors exist av tools something cannot be relied upon aim paper investigate behaviour malware upon various windows operating system versions order determine correlate relationship between malicious software os artifacts will enable investigator be more efficient identifying presence new malware provide starting point further investigation
WebEye - Automated Collection of Malicious HTTP Traffic,Cryptography and Security,malware detection techniques increasingly adopting machine learning approaches creation precise training sets becomes more more important large data sets realistic web traffic correctly classified benign malicious are needed not only train classic deep learning algorithms but also serve evaluation benchmarks existing malware detection products interestingly despite vast number versatility threats user may encounter when browsing web actual malicious content often hard come since prerequisites such browser operating system type version must be met order receive payload malware distributing server combination privacy constraints data sets actual user traffic it difficult researchers product developers evaluate antimalware solutions against largescale data sets realistic web traffic paper we present webeye framework autonomously creates realistic http traffic enriches recorded traffic additional information classifies records malicious benign using different classifiers we are using webeye collect malicious html javascript show how datasets created webeye can be used train machine learning based malware detection algorithms we regard webeye data sets it creates tool researchers product developers evaluate improve their aibased antimalware solutions against largescale benchmarks
Robust Physical-World Attacks on Deep Learning Models,Cryptography and Security,recent studies show stateoftheart deep neural networks dnns are vulnerable adversarial examples resulting smallmagnitude perturbations added input given emerging physical systems are using dnns safetycritical situations adversarial examples could mislead these systems cause dangerous situationstherefore understanding adversarial examples physical world important step towards developing resilient learning algorithms we propose general attack algorithmrobust physical perturbations rp generate robust visual adversarial perturbations under different physical conditions using realworld case road sign classification we show adversarial examples generated using rp achieve high targeted misclassification rates against standardarchitecture road sign classifiers physical world under various environmental conditions including viewpoints due current lack standardized testing method we propose twostage evaluation methodology robust physical adversarial examples consisting lab field tests using methodology we evaluate efficacy physical adversarial manipulations real objects witha perturbation form only black white stickerswe attack real stop sign causing targeted misclassification images obtained lab settings captured video frames obtained moving vehiclefield test target classifier
Examining Zero-Shot Vulnerability Repair with Large Language Models,Cryptography and Security,human developers can produce code cybersecurity bugs can emerging smart code completion tools help repair those bugs work we examine use large language models llms code such openais codex ais jurassic zeroshot vulnerability repair we investigate challenges design prompts coax llms into generating repaired versions insecure code difficult due numerous ways phrase key information both semantically syntactically natural languages we perform large scale study five commercially available blackbox offtheshelf llms well opensource model our own locallytrained model mix synthetic handcrafted realworld security bug scenarios our experiments demonstrate while approach has promise llms could collectively repair our synthetically generated handcrafted scenarios qualitative evaluation models performance over corpus historical realworld examples highlights challenges generating functionally correct code
Learning the Associations of MITRE ATT&CK Adversarial Techniques,Cryptography and Security,mitre attck framework provides rich actionable repository adversarial tactics techniques procedures ttp however information would be highly useful attack diagnosis ie forensics mitigation ie intrusion response if we can reliably construct technique associations will enable predicting unobserved attack techniques based observed ones paper we present our statistical machine learning analysis apt software attack data reported mitre attck infer technique clustering represents significant correlation can be used technique prediction due complex multidimensional relationships between techniques many traditional clustering methods could not obtain usable associations our approach using hierarchical clustering inferring attack technique associations confidence provides statistically significant explainable technique correlations our analysis discovers different technique associations ie clusters both apt software attacks our evaluation results show techniques associated our algorithm exhibit significant mutual information indicates reasonably high predictability
"Application Specific Instrumentation (ASIN): A Bio-inspired Paradigm to
  Instrumentation using recognition before detection",Other Computer Science,paper we present new scheme instrumentation which has been inspired way small mammals sense their environment we call scheme application specific instrumentation asin conventional instrumentation system focuses gathering much information about scene possible usually generic system whose data can be used another system take specific action asin fuses these two steps into one major merit proposed scheme it uses low resolution sensors much less computational overhead give good performance highly specialised application
Neighbourhood Evaluation Criteria for Vertex Cover Problem,Other Computer Science,neighbourhood evaluation criteria heuristical approximate algorithm attempts solve minimum vertex cover degree count kept check each vertex highest count based vertex included our cover set case multiple equivalent vertices one lowest neighbourhood influence selected case still existing multiple equivalent vertices one lowest remaining active vertex count highest independent set enabling count selected tiebreaker
On the Expressiveness of Line Drawings,Other Computer Science,can expressiveness drawing be traced computer study neural network perceptron support vector machine are used classify line drawings do line drawings are attributed values according kinematic model diffusion model lines they consist values both models are related looking times extreme values according these models both extremely short extremely long looking times are interpreted indicating expressiveness results strongly indicate expressiveness sense can be detected least neural network
Choose Your Weapon: Survival Strategies for Depressed AI Academics,Other Computer Science,are you ai researcher academic institution are you anxious you are not coping current pace ai advancements do you feel you have no very limited access computational human resources required ai research breakthrough you are not alone we feel same way growing number ai academics can no longer find means resources compete global scale somewhat recent phenomenon but accelerating one private actors investing enormous compute resources into cutting edge ai research here we discuss what you can do stay competitive while remaining academic we also briefly discuss what universities private sector could do improve situation if they are so inclined not exhaustive list strategies you may not agree all them but it serves start discussion
"Efficient Programmable Random Variate Generation Accelerator from Sensor
  Noise",Other Computer Science,we introduce method nonuniform random number generation based sampling physical process controlled environment we demonstrate one proofofconcept implementation method reduces error monte carlo integration univariate gaussian times while doubling speed monte carlo simulation we show supply voltage temperature physical process must be controlled prevent mean standard deviation random number generator drifting
"Caching and Reproducibility: Making Data Science experiments faster and
  FAIRer",Software Engineering,small mediumscale data science experiments often rely research software developed adhoc individual scientists small teams often there no time make research software fast reusable open access consequence twofold first subsequent researchers must spend significant work hours building upon proposed hypotheses experimental framework worst case others cannot reproduce experiment reuse findings subsequent research second suppose adhoc research software fails during often longrunning computationally expensive experiments case overall effort iteratively improve software rerun experiments creates significant time pressure researchers we suggest making caching integral part research software development process even before first line code written article outlines caching recommendations developing research software data science projects our recommendations provide perspective circumvent common problems such propriety dependence speed etc same time caching contributes reproducibility experiments open science workflow concerning four guiding principles ie findability accessibility interoperability reusability fair we foresee including proposed recommendation research software development will make data related software fairer both machines humans we exhibit usefulness some proposed recommendations our recently completed research software project mathematical information retrieval
"Object Oriented Analysis using Natural Language Processing concepts: A
  Review",Software Engineering,software development life cycle sdlc starts eliciting requirements customers form software requirement specification srs srs document needed software development mostly written natural languagenl convenient client srs document only class name its attributes functions incorporated body class are traced based preknowledge analyst paper intends present review object oriented oo analysis using natural language processing nlp techniques analysis can be manual where domain expert helps generate required diagram automated system where system generates required diagram input form srs
Predicting the Number of Reported Bugs in a Software Repository,Software Engineering,bug growth pattern prediction complicated unrelieved task which needs considerable attention advance knowledge likely number bugs discovered software system helps software developers designating sufficient resources convenient time developers may also use such information take necessary actions increase quality system turn customer satisfaction study we examine eight different time series forecasting models including long short term memory neural networks lstm autoregressive integrated moving average arima random forest regressor further we assess impact exogenous variables such software release dates incorporating those into prediction models we analyze quality longterm prediction each model based different performance metrics assessment conducted mozilla which large opensource software application dataset originally mined bugzilla contains number bugs project between jan dec our numerical analysis provides insights evaluating trends bug repository we observe lstm effective when considering longrun predictions whereas random forest regressor enriched exogenous variables performs better predicting number bugs short term
"The Pipeline for the Continuous Development of Artificial Intelligence
  Models -- Current State of Research and Practice",Software Engineering,companies struggle continuously develop deploy ai models complex production systems due ai characteristics while assuring quality ease development process continuous pipelines ai have become active research area where consolidated indepth analysis regarding terminology triggers tasks challenges required paper includes multivocal literature review where we consolidated relevant formal informal sources addition ninesemi structured interviews participants academia industry verified extended obtained information based these sources paper provides compares terminologies devops cicd ai mlops endtoend lifecycle management cdml furthermore paper provides aggregated list potential triggers reiterating pipeline such alert systems schedules addition work uses taxonomy creation strategy present consolidated pipeline comprising tasks regarding continuous development ai pipeline consists four stages data handling model learning software development system operations moreover we map challenges regarding pipeline implementation adaption usage continuous development ai these four stages
"The application of artificial intelligence in software engineering: a
  review challenging conventional wisdom",Software Engineering,field artificial intelligence ai witnessing recent upsurge research tools development deployment applications multiple software companies are shifting their focus developing intelligent systems many others are deploying ai paradigms their existing processes parallel academic research community injecting ai paradigms provide solutions traditional engineering problems similarly ai has evidently been proved useful software engineering se when one observes se phases requirements design development testing release maintenance it becomes clear multiple ai paradigms such neural networks machine learning knowledgebased systems natural language processing could be applied improve process eliminate many major challenges se field has been facing survey chapter review most commonplace methods ai applied se review covers methods between years requirements phase major aidriven methods are found design development testing release maintenance furthermore purpose chapter threefold firstly answer following questions there sufficient intelligence se lifecycle what does applying ai se entail secondly measure formulize evaluate overlap se phases ai disciplines lastly chapter aims provide serious questions challenging current conventional wisdom ie status quo stateoftheart craft call action redefine path forward
Logical-Combinatorial Approaches in Dynamic Recognition Problems,Discrete Mathematics,pattern recognition scenario where instead object classification into classes learning set algorithm aims allocate all objects same socalled normal class research objective
Embedded-Graph Theory,Discrete Mathematics,paper we propose new type graph denoted embeddedgraph its theory which employs distributed representation describe relations graph edges embeddedgraphs can express linguistic complicated relations which cannot be expressed existing edgegraphs weightedgraphs we introduce mathematical definition embeddedgraph translation edge distance graph similarity we can transform embeddedgraph into weightedgraph weightedgraph into edgegraph translation method threshold calculation respectively edge distance embeddedgraph distance based components target vector it calculated through cosine similarity target vector graph similarity obtained considering relations linguistic complexity addition we provide some examples data structures embeddedgraphs paper
Hidden Hamiltonian Cycle Recovery via Linear Programming,Discrete Mathematics,we introduce problem hidden hamiltonian cycle recovery where there unknown hamiltonian cycle nvertex complete graph needs be inferred noisy edge measurements measurements are independent distributed according calpn edges cycle calqn otherwise formulation motivated problem genome assembly where goal order set contigs genome subsequences according their positions genome using longrange linking measurements between contigs computing maximum likelihood estimate model reduces traveling salesman problem tsp despite nphardness tsp we show simple linear programming lp relaxation namely fractional factor ff lp recovers hidden hamiltonian cycle high probability infty provided alphan log infty where alphan triangleq log int sqrtd pn qn renyi divergence order frac condition informationtheoretically optimal sense under mild distributional assumptions alphan geq log necessary any algorithm succeed regardless computational cost departing usual proof techniques based dual witness construction analysis relies combinatorial characterization particular halfintegrality extreme points ff polytope represented bicolored multigraphs these extreme points are further decomposed into simpler blossomtype structures large deviation analysis counting arguments evaluation algorithm real data shows improvements over existing approaches
An Algebra to Merge Heterogeneous Classifiers,Discrete Mathematics,distributed classification each learner observes its environment deduces classifier learner has only local view its environment classifiers can be exchanged among learners integrated merged improve accuracy however operation merging not defined most classifiers furthermore classifiers have be merged may be different types settings such adhoc networks which several generations sensors may be creating classifiers we introduce decision spaces framework merging possibly different classifiers we formally study merging operation algebra prove it satisfies desirable set properties impact time discussed two main data mining settings firstly decision spaces can naturally be used nonstationary distributions such data collected sensor networks impact model decays over time secondly we introduce approach stationary distributions such homogeneous databases partitioned over different learners which ensures all models have same impact we also present method uses storage flexibly achieve different types decay nonstationary distributions finally we show algebraic approach developed merging can also be used analyze behaviour other operators
"Weighted majority tournaments and Kemeny ranking with 2-dimensional
  Euclidean preferences",Discrete Mathematics,assumption voters preferences share some common structure standard way circumvent nphardness results social choice problems while kemeny ranking problem nphard general case it known become easy if preferences are dimensional euclidean note we prove kemeny ranking problem remains nphard kdimensional euclidean preferences kge under norms ell ell ellinfty showing any weighted tournament resp weighted bipartite tournament weights same parity resp even weights inducible weighted majority tournament profile euclidean preferences under norm ell resp ellellinfty computable polynomial time more generally result regarding weighted tournaments implies essentially hardness results relying weighted majority tournament hold general case eg nphardness slater ranking are still true dimensional euclidean preferences
"Bayes Blocks: An Implementation of the Variational Bayesian Building
  Blocks Framework",Mathematical Software,software library constructing learning probabilistic models presented library offers set building blocks which large variety static dynamic models can be built these include hierarchical models variances other variables many nonlinear models underlying variational bayesian machinery providing fast robust estimation but being mathematically rather involved almost completely hidden user thus making it very easy use library building blocks include gaussian rectified gaussian mixtureofgaussians variables computational nodes which can be combined rather freely
The Ocean Tensor Package,Mathematical Software,matrix tensor operations form basis wide range fields applications many cases constitute substantial part overall computational complexity ability generalpurpose gpus speed up many these operations enable others has resulted widespread adaptation these devices order tensor operations take full advantage computational power specialized software required currently there exist several packages predominantly area deep learning incorporate tensor operations both cpu gpu nevertheless standalone framework supports general tensor operations still missing paper we fill gap propose ocean tensor library modular tensorsupport package designed serve foundational layer applications require dense tensor operations variety device types api carefully designed be powerful extensible same time easy use package available open source
Glyph: Symbolic Regression Tools,Mathematical Software,we present glyph python package genetic programming based symbolic regression glyph designed usage let numerical simulations let real world experiments experimentalists glyphremote provides separation tasks zeromq interface splits genetic programming optimization task evaluation experimental numerical run glyph can be accessed httpgithubcomambrosysglyph domain experts are be able employ symbolic regression their experiments ease even if they are not expert programmers reuse potential kept high generic interface design glyph available pypi github
"FFTc: An MLIR Dialect for Developing HPC Fast Fourier Transform
  Libraries",Mathematical Software,discrete fourier transform dft libraries are one most critical software components scientific computing inspired fftw widely used library dft hpc calculations we apply compiler technologies development hpc fourier transform libraries work we introduce fftc domainspecific language based multilevel intermediate representation mlir expressing fourier transform algorithms we present initial design implementation preliminary results fftc
Fast solving of Weighted Pairing Least-Squares systems,Mathematical Software,paper presents generalization weighted leastsquares wls named weighted pairing leastsquares wpls which uses rectangular weight matrix suitable data alignment problems two fast solving methods suitable solving full rank systems well rank deficient systems are studied computational experiments clearly show best method terms speed accuracy numerical stability based special inverse whose computation reduces very simple generalization usual cholesky factorizationbackward substitution method solving linear systems
"Online Matching in Sparse Random Graphs: Non-Asymptotic Performances of
  Greedy Algorithm",Data Structures and Algorithms,motivated sequential budgeted allocation problems we investigate online matching problems where connections between vertices are not iid but they have fixed degree distributions socalled configuration model we estimate competitive ratio simplest algorithm greedy approximating some relevant stochastic discrete processes their continuous counterparts are solutions explicit system partial differential equations technique gives precise bounds estimation errors arbitrarily high probability problem size increases particular it allows formal comparison between different configuration models we also prove quite surprisingly greedy can have better performance guarantees than ranking another celebrated algorithm online matching usually outperforms former
"Multi-dimensional sparse structured signal approximation using split
  Bregman iterations",Data Structures and Algorithms,paper focuses sparse approximation signals using overcomplete representations such it preserves prior structure multidimensional signals underlying optimization problem tackled using multidimensional split bregman optimization approach extensive empirical evaluation shows how proposed approach compares state art depending signal features
"Low-Autocorrelation Binary Sequences: On Improved Merit Factors and
  Runtime Predictions to Achieve Them",Data Structures and Algorithms,search binary sequences high figure merit known low autocorrelation binary sequence labs problem represents formidable computational challenge mitigate computational constraints problem we consider solvers accept odd values sequence length return solutions skewsymmetric binary sequences only consequence not all best solutions under constraint will be optimal each order improve both search best merit factor asymptotic runtime performance we instrumented three stochastic solvers first two are stateoftheart solvers rely variants memetic tabu search lssmats lssrrts third solver lssorel organizes search sequence independent contiguous selfavoiding walk segments adapting rigorous statistical methodology performance testing all three combinatorial solvers experiments show solver best asymptotic averagecase performance lssorel has best chance finding solutions improve increases figures merit reported date same methodology can be applied engineering new labs solvers may return merit factors even closer conjectured asymptotic value
Inferring Networks of Diffusion and Influence,Data Structures and Algorithms,information diffusion virus propagation are fundamental processes taking place networks while it often possible directly observe when nodes become infected virus adopt information observing individual transmissions ie who infects whom who influences whom typically very difficult furthermore many applications underlying network over which diffusions propagations spread actually unobserved we tackle these challenges developing method tracing paths diffusion influence through networks inferring networks over which contagions propagate given times when nodes adopt pieces information become infected we identify optimal network best explains observed infection times since optimization problem nphard solve exactly we develop efficient approximation algorithm scales large datasets finds provably nearoptimal networks we demonstrate effectiveness our approach tracing information diffusion set million blogs news articles over one year period infer how information flows through online media space we find diffusion network news top media sites blogs tends have coreperiphery structure small set core media sites diffuse information rest web these sites tend have stable circles influence more general news media sites acting connectors between them
Adaptive and Dynamic Multi-Resolution Hashing for Pairwise Summations,Data Structures and Algorithms,paper we propose adamhash adaptive dynamic multiresolution hashing datastructure fast pairwise summation estimation given dataset subset mathbbrd binary function fmathbbrdtimes mathbbrdto mathbbr point mathbbrd pairwise summation estimate mathrmpsexy fracx sumx fxy any given dataset we need design datastructure such given any query point mathbbrd datastructure approximately estimates mathrmpsexy time sublinear prior works problem have focused exclusively case where dataset static queries are independent paper we design hashingbased pse datastructure which works more practical textitdynamic setting which insertions deletions replacements points are allowed moreover our proposed adamhash also robust adaptive pse queries where adversary can choose query qj mathbbrd depending output previous queries dots qj
Institutionalising Ethics in AI through Broader Impact Requirements,Computers and Society,turning principles into practice one most pressing challenges artificial intelligence ai governance article we reflect novel governance initiative one worlds largest ai requirement submitting societal impacts their research drawing insights similar governance initiatives including institutional review boards irbs impact requirements funding applications we investigate risks challenges potential benefits such initiative among challenges we list lack recognised best practice procedural transparency researcher opportunity costs institutional social pressures cognitive biases inherently difficult nature task potential benefits other hand include improved anticipation identification impacts better communication policy governance experts general strengthening norms around responsible research maximise chance success we recommend measures increase transparency improve guidance create incentives engage earnestly process facilitate public deliberation requirements merits future perhaps most important contribution analysis are insights we can gain regarding effective communitybased governance role responsibility ai research community more broadly
"AppsPred: Predicting Context-Aware Smartphone Apps using Random Forest
  Learning",Computers and Society,due popularity contextawareness internet things iot recent advanced features most popular iot device ie smartphone modeling predicting personalized usage behavior based relevant contexts can be highly useful assisting them carry out daily routines activities usage patterns different categories smartphone apps such social networking communication entertainment daily life services related apps usually vary greatly between individuals people use these apps differently different contexts such temporal context spatial context individual mood preference work status internet connectivity like wifi status device related status like phone profile battery level etc thus we consider individuals apps usage multiclass contextaware problem personalized modeling prediction random forest learning one most popular machine learning techniques build multiclass prediction model therefore paper we present effective contextaware smartphone apps prediction model name it appspred using random forest machine learning technique takes into account optimal number trees based such multidimensional contexts build resultant forest effectiveness model examined conducting experiments smartphone apps usage datasets collected individual users experimental results show our appspred significantly outperforms other popular machine learning classification approaches like zeror naive bayes decision tree support vector machines logistic regression while predicting smartphone apps various contextaware test cases
"Feasibility of Social-Network-Based eHealth Intervention on the
  Improvement of Healthy Habits among Children",Computers and Society,study shows feasibility ehealth solution tackling eating habits physical activity adolescent population participants were children years old intervention was carried out students intervention group students control group two schools during weeks intervention group had access web through user account password they were able create friendship relationships post comments give likes interact other users well receive notifications information about nutrition physical activity daily basis get virtual rewards improving their habits control group did not have access any these features homogeneity samples terms gender age body mass index initial healthrelated habits was demonstrated pre postmeasurements were collected through selfreports application website after applying multivariate analysis variance significant alteration ageadjusted body mass index percentile was observed intervention group versus control group well paqa score kidmed score it can be concluded ehealth interventions can help obtain healthy habits more research needed examine effectiveness achieving adherence these new habits
"Immune Moral Models? Pro-Social Rule Breaking as a Moral Enhancement
  Approach for Ethical AI",Computers and Society,we are moving towards future where artificial intelligence ai based agents make many decisions behalf humans healthcare decision making social media censoring these agents face problems make decisions ethical societal implications ethical behaviour critical characteristic we would like humancentric ai common observation humancentric industries like service industry healthcare their professionals tend break rules if necessary prosocial reasons behaviour among humans defined prosocial rule breaking make ai agents more human centric we argue there need mechanism helps ai agents identify when break rules set their designers understand when ai agents need break rules we examine conditions under which humans break rules prosocial reasons paper we present study introduces vaccination strategy dilemma human participants analyses their responses dilemma one needs decide whether they would distribute covid vaccines only members highrisk group follow enforced rule selected cases administer vaccine few social influencers break rule which might yield overall greater benefit society results empirical study suggest relationship between stakeholder utilities prosocial rule breaking psrb which neither deontological nor utilitarian ethics completely explain finally paper discusses design characteristics ethical agent capable psrb future research directions psrb ai realm we hope will inform design future ai agents their decisionmaking behaviour
"Making Things Explainable vs Explaining: Requirements and Challenges
  under the GDPR",Computers and Society,european union eu through highlevel expert group artificial intelligence aihleg general data protection regulation gdpr has recently posed interesting challenge explainable ai xai community demanding more usercentred approach explain automated decisionmaking systems adms looking relevant literature xai currently focused producing explainable software explanations generally follow approach we could term onesizefitsall unable meet requirement centring user needs one causes limit belief making things explainable alone enough have pragmatic explanations thus insisting clear separation between explainabilty something can be explained explanations we point explanatory ai yai alternative more powerful approach win aihleg challenge yai builds over xai goal collect organize explainable information articulating it into something we called usercentred explanatory discourses through use explanatory discoursesnarratives we represent problem generating explanations automated decisionmaking systems adms into identification appropriate path over explanatory space allowing explainees interactively explore it produce explanation best suited their needs
"Notes on neighborhood semantics for logics of unknown truths and false
  beliefs",Logic,article we study logics unknown truths false beliefs under neighborhood semantics we compare relative expressivity two logics it turns out they are incomparable over various classes neighborhood models combination two logics are equally expressive standard modal logic over any class neighborhood models we propose morphisms each logic which can help us explore frame definability problem show general soundness completeness result generalize some results literature we axiomatize two logics over various classes neighborhood frames last but not least we extend results case public announcements which has good applications moore sentences some others
Relations on FP-Soft Sets Applied to Decision Making Problems,Logic,work we first define relations fuzzy parametrized soft sets study their properties we also give decision making method based these relations approximate reasoning relations fuzzy parametrized soft sets have shown be primordial importance finally method successfully applied problems contain uncertainties
On the classifiability of cellular automata,Logic,based computer simulations wolfram presented several papers conjectured classifications cellular automata into types he distinguishes classes cellular automata evolution pattern generated applying cellular automaton finite input wolframs qualitative classification based examination large number simulations addition classification based rate growth he conjectured similar classification according eventual pattern we consider here one formalization his rate growth suggestion after completing our major results based only wolframs work we investigated other contributions area we report relation some them our discoveries
Intensional Models for the Theory of Types,Logic,paper we define intensional models classical theory types thus arriving intensional type logic itl intensional models generalize henkins general models have natural definition class they do not validate axiom extensionality we give cutfree sequent calculus type theory show completeness calculus respect class intensional models via model existence theorem after we turn our attention applications firstly it argued since itl truly intensional it can be used model ascriptions propositional attitude without predicting logical omniscience order illustrate small fragment english defined provided itl semantics secondly it shown itl models contain certain objects can be identified possible worlds essential elements modal logic become available within classical type theory once axiom extensionality given up
Dialogues for proof search,Logic,dialogue games are twoplayer semantics variety logics including intuitionistic classical logic dialogues can be viewed kind analytic calculus not unlike tableaux can dialogue games be effective foundation proof search intuitionistic logic both firstorder propositional we announce kuno automated theorem prover intuitionistic firstorder logic based dialogue games
Machine Learning assisted Chimera and Solitary states in Networks,Adaptation and Self-Organizing Systems,chimera solitary states have captivated scientists engineers due their peculiar dynamical states corresponding coexistence coherent incoherent dynamical evolution coupled units various natural artificial systems it has been further demonstrated such states can be engineered systems coupled oscillators suitable implementation communication delays here using supervised machine learning we predict precise value delay which sufficient engineering chimera solitary states given set system parameters well intensity incoherence such engineered states results are demonstrated two different examples consisting single layer multi layer networks first chimera states solitary states are engineered establishing delays neighboring links node interlayer links lattice multiplex network oscillators then different machine learning classifiers knn svm mlpneural network are employed feeding data obtained network models once machine learning model trained using limited amount data it makes predictions given unknown systems parameter values testing accuracy sensitivity specificity analysis reveal mlpnn classifier better suited than knn svm classifier predictions parameters values engineered chimera solitary states technique provides easy methodology predict critical delay values well intensity incoherence designing experimental setup create solitary chimera states
Cognitive Aging as Interplay between Hebbian Learning and Criticality,Adaptation and Self-Organizing Systems,cognitive ageing seems be story global degradation one ages there are number physical chemical biological changes take place therefore it logical assume brain no exception phenomenon principle purpose project use models neural dynamics learning based underlying principle selforganised criticality account age related cognitive effects regard learning neural networks can serve model acquisition skills knowledge early development stages ie ageing process criticality network serves optimum state cognitive abilities possible candidate mechanisms ageing neural network are loss connectivity neurons increase level noise reduction white matter more interestingly longer learning history competition among several optimization objectives paper we are primarily interested affect longer learning history memory thus optimality brain hence it hypothesized prolonged learning form associative memory patterns can destroy state criticality network we base our model tsodyks markrams model dynamic synapses process explore effect combining standard hebbian learning phenomenon selforganised criticality project mainly consists evaluations simulations networks integrate fireneurons have been subjected various combinations neurallevel ageing effects aim establishing primary hypothesis understanding decline cognitive abilities due ageing using one its important characteristics longer learning history
Learning Criticality in an Embodied Boltzmann Machine,Adaptation and Self-Organizing Systems,many biological cognitive systems do not operate deep into one other regime activity instead they exploit critical surfaces poised transitions their parameter space pervasiveness criticality natural systems suggests there may be general principles inducing behaviour however there lack conceptual models explaining how embodied agents propel themselves towards these critical points paper we present learning model driving embodied boltzmann machine towards critical behaviour maximizing heat capacity network we test corroborate model implementing embodied agent mountain car benchmark controlled boltzmann machine adjust its weights according model we find neural controller reaches point criticality which coincides transition point behaviour agent between two regimes behaviour maximizing synergistic information between its sensors hidden motor neurons finally we discuss potential our learning model study contribution criticality behaviour embodied living systems scenarios not necessarily constrained biological restrictions examples criticality we find nature
"Emergence of Self-Reproducing Metabolisms as Recursive Algorithms in an
  Artificial Chemistry",Adaptation and Self-Organizing Systems,one main goals artificial life research conditions emergence life not necessarily it but it could be artificial chemistries are one most important tools purpose because they provide us basic framework investigate under which conditions metabolisms capable reproducing themselves ultimately evolving can emerge while there have been successful attempts producing examples emergent selfreproducing metabolisms set rules involved remain too complex shed much light underlying principles work paper we hypothesize key property needed selfreproducing metabolisms emerge existence autocatalyzed subset turingcomplete reactions we validate hypothesis minimalistic artificial chemistry conservation laws which based turingcomplete rewriting system called combinatory logic our experiments show single run chemistry starting tabula rasa state discovers no external intervention wide range emergent structures including ones selfreproduce each cycle all these structures take form recursive algorithms acquire basic constituents environment decompose them process remarkably similar biological metabolisms
Notes on information geometry and evolutionary processes,Adaptation and Self-Organizing Systems,order analyze extract different structural properties distributions one can introduce different coordinate systems over manifold distributions evolutionary computation walsh bases building block bases are often used describe populations which simplifies analysis evolutionary operators applying populations quite independent these approaches information geometry has been developed geometric way analyze different order dependencies between random variables eg neural activations genes these notes briefly review essentials various coordinate bases information geometry goal give overview make approaches comparable besides introducing meaningful coordinate bases information geometry also offers explicit way distinguish different order interactions it offers geometric view manifold thereby also operators apply manifold instance uniform crossover can be interpreted orthogonal projection population along mgeodesic monotonously reducing thetacoordinates describe interactions between genes
"Deep Recurrent Neural Network for Protein Function Prediction from
  Sequence",Quantitative Methods in Biology,highthroughput biological sequencing becomes faster cheaper need extract useful information sequencing becomes ever more paramount often limited lowthroughput experimental characterizations proteins accurate prediction their functions directly their primary aminoacid sequences has been long standing challenge here machine learning using artificial recurrent neural networks rnn was applied towards classification protein function directly primary sequence without sequence alignment heuristic scoring feature engineering rnn models containing longshorttermmemory lstm units trained public annotated datasets uniprot achieved high performance inclass prediction four important protein functions tested particularly compared other machine learning algorithms using sequencederived protein features rnn models were used also outofclass predictions phylogenetically distinct protein families similar functions including proteins crisprassociated nuclease ferritinlike iron storage cytochrome families applying trained rnn models partially unannotated uniref database predicted not only candidates validated existing annotations but also currently unannotated sequences some rnn predictions ferritinlike iron sequestering function were experimentally validated even though their sequences differ significantly known characterized proteins each other cannot be easily predicted using popular bioinformatics methods sequencing experimental characterization data increases rapidly machinelearning approach based rnn could be useful discovery prediction homologues wide range protein functions
"Reducing complexity and unidentifiability when modelling human atrial
  cells",Quantitative Methods in Biology,mathematical models cellular action potential cardiac modelling have become increasingly complex particularly gating kinetics which control opening closing individual ion channel currents cardiac models advance towards use personalised medicine inform clinical decisionmaking it critical understand uncertainty hidden parameter estimates their calibration experimental data study applies approximate bayesian computation recalibrate gating kinetics four ion channels two existing human atrial cell models their original datasets providing measure uncertainty indication potential issues selecting single unique value given available experimental data two approaches are investigated reduce uncertainty present recalibrating models more complete dataset using less complex formulation fewer parameters constrain recalibrated models are inserted back into full cell model study overall effect action potential use more complete datasets does not eliminate uncertainty present parameter estimates less complex model particularly fast sodium current gave better fit experimental data alongside lower parameter uncertainty improved computational speed
"Predicting protein-protein interactions based on rotation of proteins in
  3D-space",Quantitative Methods in Biology,proteinprotein interactions ppis perform essential roles biological functions although some experimental techniques have been developed detect ppis they suffer high false positive high false negative rates consequently efforts have been devoted during recent years develop computational approaches predict interactions utilizing various sources information therefore unique category prediction approaches has been devised which based protein sequence information however finding appropriate feature encoding characterize sequence proteins major challenge such methods presented work sequence based method proposed predict proteinprotein interactions using ngram encoding approaches describe amino acids relaxed variable kernel density estimator rvkde machine learning tool moreover since proteins can rotate dspace amino acid compositions have been considered undirected property which leads reduce dimensions vector space results show our proposed method achieves superiority prediction performance improving fmeasure human protein reference dataset hprd
"Feature Decomposition Based Saliency Detection in Electron
  Cryo-Tomograms",Quantitative Methods in Biology,electron cryotomography ect allows visualization subcellular structures submolecular resolution close native state however due high degree structural complexity imaging limits automatic segmentation cellular components ect images very difficult complement speed up existing segmentation methods it desirable develop generic cell component segmentation method not specific particular types cellular components able segment unknown cellular components fully unsupervised does not rely availability training data important step towards goal paper we propose saliency detection method computes likelihood subregion tomogram stands out background our method consists four steps supervoxel oversegmentation feature extraction feature matrix decomposition computation saliency method produces distribution map represents regions saliency tomograms our experiments show our method can successfully label most salient regions detected human observer able filter out regions not containing cellular components therefore our method can remove majority background region significantly speed up subsequent processing segmentation recognition cellular components captured ect
"Evolutionary Inference for Function-valued Traits: Gaussian Process
  Regression on Phylogenies",Quantitative Methods in Biology,biological data objects often have both following features they are functions rather than single numbers vectors ii they are correlated due phylogenetic relationships paper we give flexible statistical model such data combining assumptions phylogenetics gaussian processes we describe its use nonparametric bayesian prior distribution both prediction placing posterior distributions ancestral functions model selection comparing rates evolution across phylogeny identifying most likely phylogenies consistent observed data our work integrative extending popular phylogenetic brownian motion ornsteinuhlenbeck models functional data bayesian inference extending gaussian process regression phylogenies we provide brief illustration application our method
Machine learning applied to quantum synchronization-assisted probing,Quantum Physics,probing scheme considered accessible controllable qubit used probe outof equilibrium system consisting second qubit interacting environment quantum spontaneous synchronization between probe system emerges model tuning probe frequency can occur both inphase antiphase we analyze capability machine learning probing scheme based quantum synchronization artificial neural network used infer probe observable main dissipation features such environment ohmicity index efficiency algorithm presence some noise dataset also considered we show performance either classification regression significantly improved due inantiphase synchronization transition opens way characterization environments arbitrary spectral densities
Continuous-variable quantum neural networks,Quantum Physics,we introduce general method building neural networks quantum computers quantum neural network variational quantum circuit built continuousvariable cv architecture which encodes quantum information continuous degrees freedom such amplitudes electromagnetic field circuit contains layered structure continuously parameterized gates which universal cv quantum computation affine transformations nonlinear activation functions two key elements neural networks are enacted quantum network using gaussian nongaussian gates respectively nongaussian gates provide both nonlinearity universality model due structure cv model cv quantum neural network can encode highly nonlinear transformations while remaining completely unitary we show how classical network can be embedded into quantum formalism propose quantum versions various specialized model such convolutional recurrent residual networks finally we present numerous modeling experiments built strawberry fields software library these experiments including classifier fraud detection network which generates tetris images hybrid classicalquantum autoencoder demonstrate capability adaptability cv quantum neural networks
The Expressive Power of Parameterized Quantum Circuits,Quantum Physics,parameterized quantum circuits pqcs have been broadly used hybrid quantumclassical machine learning scheme accomplish generative tasks however whether pqcs have better expressive power than classical generative neural networks such restricted deep boltzmann machines remains open issue paper we prove pqcs simple structure already outperform any classical neural network generative tasks unless polynomial hierarchy collapses our proof builds known results tensor networks quantum circuits particular instantaneous quantum polynomial circuits addition pqcs equipped ancillary qubits postselection have even stronger expressive power than those without postselection we employ them application bayesian learning since it possible learn prior probabilities rather than assuming they are known we expect it will find many more applications semisupervised learning where prior distributions are normally assumed be unknown lastly we conduct several numerical experiments using rigetti forest platform demonstrate performance proposed bayesian quantum circuit
Quantum computing overview: discrete vs. continuous variable models,Quantum Physics,near intermediatescale quantum era there are two types nearterm quantum devices available cloud superconducting quantum processing units qpus based discrete variable model linear optics photonics qpus based continuous variable cv model quantum computation discrete variable model performed finite dimensional quantum state space cv model infinite dimensional space implementing quantum algorithms cv model offers more quantum gates are not available discrete variable model cvbased photonic quantum computers provide additional flexibility controlling length output vectors quantum circuits using different methods measurement notion cutoff dimension
Online optimal exact identification of a quantum change point,Quantum Physics,we consider online detection strategies identifying change point stream quantum particles allegedly prepared identical states we show identification change point can be done without error via sequential local measurements while attaining optimal performance bound set quantum mechanics way we establish task exactly identifying quantum change point instance where local protocols are powerful global ones optimal online detection strategy requires only one bit memory between subsequent measurements it amenable experimental realization current technology
"The Wind in Our Sails: Developing a Reusable and Maintainable Dutch
  Maritime History Knowledge Graph",Digital Libraries,digital sources are more prevalent than ever but effectively using them can be challenging one core challenge digitized sources are often distributed thus forcing researchers spend time collecting interpreting aligning different sources knowledge graph can accelerate research providing single connected source truth humans machines can query during two designtest cycles we convert four data sets historical maritime domain into knowledge graph focus during these cycles creating sustainable usable approach can be adopted other linked data conversion efforts furthermore our knowledge graph available maritime historians other interested users investigate daily business dutch east india company through unified portal
"Using Titles vs. Full-text as Source for Automated Semantic Document
  Annotation",Digital Libraries,significant part largest knowledge graph today linked open data cloud consists metadata about documents such publications news reports other media articles while widespread access document metadata tremendous advancement it yet not so easy assign semantic annotations organize documents along semantic concepts providing semantic annotations like concepts skos thesauri classical research topic but typically it conducted fulltext documents first time we offer systematic comparison classification approaches investigate how far semantic annotations can be conducted using just metadata documents such titles published labels linked open data cloud we compare classifications obtained analyzing documents titles semantic annotations obtained analyzing fulltext apart prominent text classification baselines knn svm we also compare recent techniques learning rank neural networks revisit traditional methods logistic regression rocchio naive bayes results show across three our four datasets performance classifications using only titles reaches over quality compared classification performance when using fulltext thus conducting document classification just using titles reasonable approach automated semantic annotation opens up new possibilities enriching knowledge graphs
SAINE: Scientific Annotation and Inference Engine of Scientific Research,Digital Libraries,we present saine scientific annotation inference engine based set standard opensource software such label studio mlflow we show our annotation engine can benefit further development more accurate classification based our previous work hierarchical discipline classifications we demonstrate its application using saine understanding space scholarly publications user study our annotation results shows user input collected help our system can help us better understand classification process we believe our work will help foster greater transparency better understand scientific research our annotation inference engine can further support downstream metascience projects we welcome collaboration feedback scientific community these projects demonstration video can be accessed httpsyoutubeytoogyqk live demo website available httpsappheartexcomusersignuptokeneaffa upon free registration
PST-Bench: Tracing and Benchmarking the Source of Publications,Digital Libraries,tracing source research papers fundamental yet challenging task researchers billionscale citation relations between papers hinder researchers understanding evolution science efficiently date there still lack accurate scalable dataset constructed professional researchers identify direct source their studied papers based which automatic algorithms can be developed expand evolutionary knowledge science paper we study problem paper source tracing pst construct highquality everincreasing dataset pstbench computer science based pstbench we reveal several intriguing discoveries such differing evolution patterns across various topics exploration various methods underscores hardness pstbench pinpointing potential directions topic dataset codes have been available httpsgithubcomthudmpapersourcetrace
"OntoMath Digital Ecosystem: Ontologies, Mathematical Knowledge Analytics
  and Management",Digital Libraries,article we consider basic ideas approaches results developing mathematical knowledge management technologies based ontologies these solutions form basis specialized digital ecosystem ontomath which consists ontology logical structure mathematical documents mocassin ontology mathematical knowledge ontomathpro tools text analysis recommender system other applications manage mathematical knowledge studies are according ideas creating distributed system interconnected repositories digitized versions mathematical documents project create world digital mathematical library
"Adaptive Synaptic Failure Enables Sampling from Posterior Predictive
  Distributions in the Brain",Neurons and Cognition,bayesian interpretations neural processing require biological mechanisms represent operate upon probability distributions accordance bayes theorem many have speculated synaptic failure constitutes mechanism variational ie approximate bayesian inference brain whereas models have previously used synaptic failure sample over uncertainty model parameters we demonstrate adapting transmission probabilities learned network weights synaptic failure can sample not only over model uncertainty but complete posterior predictive distributions well our results potentially explain brains ability perform probabilistic searches approximate complex integrals these operations are involved numerous calculations including likelihood evaluation state value estimation complex planning
Non-linear motor control by local learning in spiking neural networks,Neurons and Cognition,learning weights spiking neural network hidden neurons using local stable online rules control nonlinear body dynamics open problem here we employ supervised scheme feedbackbased online local learning weights follow train network heterogeneous spiking neurons hidden layers control twolink arm so reproduce desired state trajectory network first learns inverse model nonlinear dynamics ie state trajectory input network it learns infer continuoustime command produced trajectory connection weights are adjusted via local plasticity rule involves presynaptic firing postsynaptic feedback error inferred command we choose network architecture termed differential feedforward gives lowest test error different feedforward recurrent architectures learned inverse model then used generate continuoustime motor command control arm given desired trajectory
Radically Compositional Cognitive Concepts,Neurons and Cognition,despite ample evidence our concepts our cognitive architecture mathematics itself are all deeply compositional few models take advantage structure we therefore propose radically compositional approach computational neuroscience drawing methods applied category theory we describe how these tools grant us means overcome complexity improve interpretability supply rigorous common language scientific modelling analogous type theories computer science case study we sketch how translate compositional narrative concepts neural circuits back again
"Comparing noisy neural population dynamics using optimal transport
  distances",Neurons and Cognition,biological artificial neural systems form highdimensional neural representations underpin their computational capabilities methods quantifying geometric similarity neural representations have become popular tool identifying computational principles are potentially shared across neural systems these methods generally assume neural responses are deterministic static however responses biological systems some artificial systems are noisy dynamically unfold over time furthermore these characteristics can have substantial influence systems computational capabilities here we demonstrate existing metrics can fail capture key differences between neural systems noisy dynamic responses we then propose metric comparing geometry noisy neural trajectories which can be derived optimal transport distance between gaussian processes we use metric compare models neural responses different regions motor system compare dynamics latent diffusion models texttoimage synthesis
"A model of sensory neural responses in the presence of unknown
  modulatory inputs",Neurons and Cognition,neural responses are highly variable some portion variability arises fluctuations modulatory factors alter their gain such adaptation attention arousal expected actual reward emotion local metabolic resource availability regardless their origin fluctuations these signals can confound bias inferences one derives spiking responses recent work demonstrates sensory neurons these effects can be captured modulated poisson model whose rate product stimulusdriven response function unknown modulatory signal here we extend model incorporating explicit modulatory elements are known specifically spikehistory dependence previous models constraining remaining latent modulatory signals be smooth time we develop inference procedures fitting entire model including hyperparameters via evidence optimization apply these simulated data responses ferret auditory midbrain cortical neurons complex sounds we show integrating out latent modulators yields better more readilyinterpretable receptive field estimates than standard poisson model conversely integrating out stimulus dependence yields estimates slowlyvarying latent modulators
"An inverse scattering approach for geometric body generation: a machine
  learning perspective",Graphics,paper we are concerned geometric shape generation prescribing set characteristic values specific geometric body one major motivations our study human body generation various applications we develop novel method can generate desired body customized characteristic values proposed method follows machinelearning flavour generates inferred geometric body input characteristic parameters training dataset one critical ingredients novelties our method borrowing inverse scattering techniques theory wave propagation body generation done establishing delicate onetoone correspondence between geometric body farfield pattern source scattering problem governed helmholtz system it turn enables us establish onetoone correspondence between geometric body space function space defined farfield patterns hence farfield patterns can act shape generators shape generation prescribed characteristic parameters achieved first manipulating shape generators then reconstructing corresponding geometric body obtained shape generator stable multiplefrequency fourier method our method easy implement produces more efficient stable body generations we provide both theoretical analysis extensive numerical experiments proposed method study first attempt introduce inverse scattering approaches combination machine learning geometric body generation it opens up many opportunities further developments
Data-Driven Synthesis of Smoke Flows with CNN-based Feature Descriptors,Graphics,we present novel datadriven algorithm synthesize highresolution flow simulations reusable repositories spacetime flow data our work we employ descriptor learning approach encode similarity between fluid regions differences resolution numerical viscosity we use convolutional neural networks generate descriptors fluid data such smoke density flow velocity same time we present deformation limiting patch advection method which allows us robustly track deformable fluid regions help patch advection we generate stable spacetime data sets detailed fluids our repositories we can then use our learned descriptors quickly localize suitable data set when running new simulation makes our approach very efficient resolution independent we will demonstrate several examples our method yields volumes very high effective resolutions nondissipative small scale details naturally integrate into motions underlying flow
Wassersplines for Neural Vector Field--Controlled Animation,Graphics,much computergenerated animation created manipulating meshes rigs while approach works well animating articulated objects like animals it has limited flexibility animating less structured freeform objects we introduce wassersplines novel trajectory inference method animating unstructured densities based recent advances continuous normalizing flows optimal transport key idea train neurallyparameterized velocity field represents motion between keyframes trajectories are then computed advecting keyframes through velocity field we solve additional wasserstein barycenter interpolation problem guarantee strict adherence keyframes our tool can stylize trajectories through variety pdebased regularizers create different visual effects we demonstrate our tool various keyframe interpolation problems produce temporallycoherent animations without meshing rigging
"Efficient Cloth Simulation using Miniature Cloth and Upscaling Deep
  Neural Networks",Graphics,cloth simulation requires fast stable method interactively realistically visualizing fabric materials using computer graphics we propose efficient cloth simulation method using miniature cloth simulation upscaling deep neural networks dnn upscaling dnns generate target cloth simulation results physicallybased simulations miniature cloth has similar physical properties those target cloth we have verified utility proposed method through experiments results demonstrate it possible generate fast stable cloth simulations under various conditions
Clustering of the Blendshape Facial Model,Graphics,digital human animation relies highquality models human face rigs face rig must be accurate same time fast compute one most common rigging models blendshape model we present novel approach learning inverse rig parameters increased accuracy decreased computational cost same time it based twofold clustering blendshape face model our method focuses exclusively underlying space deformation produces clusters both mesh space controller space something was not investigated previous literature segmentation finds intuitive meaningful connections between groups vertices face deformation controls further these segments can be observed independently separate model solving inverse rig problem then learned each segment our method completely unsupervised highly parallelizable
"mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large
  Language Model",Multimedia,recently strong text creation ability large language modelsllms has given rise many tools assisting paper reading even writing however weak diagram analysis abilities llms multimodal llms greatly limit their application scenarios especially scientific academic paper writing work towards more versatile copilot academic paper writing we mainly focus strengthening multimodal diagram analysis ability multimodal llms parsing latex source files highquality papers we carefully build multimodal diagram understanding dataset mpaper aligning diagrams paper related paragraphs we construct professional diagram analysis samples training evaluation mpaper first dataset support joint comprehension multiple scientific diagrams including figures tables format images latex codes besides better align copilot users intention we introduce outline control signal which could be directly given user revised based autogenerated ones comprehensive experiments stateoftheart mumtimodal llm demonstrate training our dataset shows stronger scientific diagram understanding performance including diagram captioning diagram analysis outline recommendation dataset code model are available httpsgithubcomxplugmplugdocowltreemainpaperowl
Image Authentication Based on Neural Networks,Multimedia,neural network has been attracting more more researchers since past decades properties such parameter sensitivity random similarity learning ability etc make it suitable information protection such data encryption data authentication intrusion detection etc paper investigating neural networks properties lowcost authentication method based neural networks proposed used authenticate images videos authentication method can detect whether images videos are modified maliciously firstly chapter introduces neural networks properties such parameter sensitivity random similarity diffusion property confusion property oneway property etc secondly chapter gives introduction neural network based protection methods thirdly image video authentication scheme based neural networks presented its performances including security robustness efficiency are analyzed finally conclusions are drawn some open issues field are presented
A survey of manifold learning and its applications for multimedia,Multimedia,manifold learning emerging research domain machine learning work we give introduction into manifold learning how it employed important application fields multimedia
"CONQUER: Contextual Query-aware Ranking for Video Corpus Moment
  Retrieval",Multimedia,paper tackles recently proposed video corpus moment retrieval task task essential because advanced video retrieval applications should enable users retrieve precise moment large video corpus we propose novel contextual queryaware rankingconquer model effective moment localization ranking conquer explores query context multimodal fusion representation learning two different steps first step derives fusion weights adaptive combination multimodal video content second step performs bidirectional attention tightly couple video query single joint representation moment localization query context fully engaged video representation learning feature fusion transformation resulting feature usercentered has larger capacity capturing multimodal signals specific query we conduct studies two datasets tvr closedworld tv episodes didemo openworld usergenerated videos investigate potential advantages fusing video query online joint representation moment retrieval
"A multi-level approach with visual information for encrypted H.265/HEVC
  videos",Multimedia,highefficiency video coding hevc encryption has been proposed encrypt syntax elements purpose video encryption achieve high video security best our knowledge almost all existing hevc encryption algorithms mainly encrypt whole video such user without permissions cannot obtain any viewable information however these encryption algorithms cannot meet needs customers who need part information but not full information video many cases such professional paid videos video meetings users would like observe some visible information encrypted video original video satisfy their requirements daily life aiming demand paper proposes multilevel encryption scheme composed lightweight encryption medium encryption heavyweight encryption where each encryption level can obtain different amount visual information it found both encrypting luma intraprediction model ipm scrambling syntax element dct coefficient sign can achieve performance distorted video which there still residual visual information while encrypting both them can implement intensity encryption one cannot gain any visual information experimental results meet our expectations appropriately indicating there different amount visual information each encryption level meanwhile users can flexibly choose encryption level according their various requirements
"Improved cross-validation for classifiers that make algorithmic choices
  to minimise runtime without compromising output correctness",Symbolic Computation,our topic use machine learning improve software making choices which do not compromise correctness output but do affect time taken produce such output we are particularly concerned computer algebra systems cass particular our experiments are selecting variable ordering use when performing cylindrical algebraic decomposition ndimensional real space respect signs set polynomials our prior work we explored different ml models could be used how identify suitable features input polynomials present paper we both repeat our prior experiments problems which have more variables thus exponentially more possible orderings examine metric which our ml classifiers targets natural metric computational runtime classifiers trained pick ordering which minimises however leads situation were models do not distinguish between any nonoptimal orderings whose runtimes may still vary dramatically paper we investigate modification crossvalidation algorithms classifiers so they do distinguish these cases leading improved results
Automatic Differentiation for Tensor Algebras,Symbolic Computation,kjolstad et al proposed tensor algebra compiler it takes expressions define tensor elementwise such fijabcd expleftsumk leftaikbjk cii dik right right generates corresponding compute kernel code machine learning especially deep learning it often necessary compute gradient loss function labcdlfabcd respect parameters abcd if tensor compilers are be applied field it necessary derive expressions derivatives elementwise defined tensors ie expressions daikpartial lpartial aik when mapping between function indices argument indices not special attention required function fij xi derivative loss dxipartial lpartial xisumj dfijxi sum necessary because index does not appear indices another example fixxii where matrix here we have dxijdeltaijdfixii kronecker delta necessary because derivative zero offdiagonal elements another indexing scheme used fijxexp xij here correct derivative dxksumi dfiki exp xk where range sum must be chosen appropriately publication we present algorithm can handle any case which indices argument are arbitrary linear combination indices function thus all above examples can be handled sums their ranges kronecker deltas are automatically inserted into derivatives necessary additionally indices are transformed if required last example algorithm outputs symbolic expression can be subsequently fed into tensor algebra compiler source code provided
Graphical Reasoning in Compact Closed Categories for Quantum Computation,Symbolic Computation,compact closed categories provide foundational formalism variety important domains including quantum computation these categories have natural visualisation form graphs we present formalism equational reasoning about such graphs develop into generic proof system fixed logical kernel equational reasoning about compact closed categories automating reasoning process motivated slow error prone nature manual graph manipulation salient feature our system it provides formal declarative account derived results can include ellipsesstyle notation we illustrate framework instantiating it graphical language quantum computation show how can be used perform symbolic computation
"Improved cross-validation for classifiers that make algorithmic choices
  to minimise runtime without compromising output correctness",Symbolic Computation,our topic use machine learning improve software making choices which do not compromise correctness output but do affect time taken produce such output we are particularly concerned computer algebra systems cass particular our experiments are selecting variable ordering use when performing cylindrical algebraic decomposition ndimensional real space respect signs set polynomials our prior work we explored different ml models could be used how identify suitable features input polynomials present paper we both repeat our prior experiments problems which have more variables thus exponentially more possible orderings examine metric which our ml classifiers targets natural metric computational runtime classifiers trained pick ordering which minimises however leads situation were models do not distinguish between any nonoptimal orderings whose runtimes may still vary dramatically paper we investigate modification crossvalidation algorithms classifiers so they do distinguish these cases leading improved results
"Improved cross-validation for classifiers that make algorithmic choices
  to minimise runtime without compromising output correctness",Symbolic Computation,our topic use machine learning improve software making choices which do not compromise correctness output but do affect time taken produce such output we are particularly concerned computer algebra systems cass particular our experiments are selecting variable ordering use when performing cylindrical algebraic decomposition ndimensional real space respect signs set polynomials our prior work we explored different ml models could be used how identify suitable features input polynomials present paper we both repeat our prior experiments problems which have more variables thus exponentially more possible orderings examine metric which our ml classifiers targets natural metric computational runtime classifiers trained pick ordering which minimises however leads situation were models do not distinguish between any nonoptimal orderings whose runtimes may still vary dramatically paper we investigate modification crossvalidation algorithms classifiers so they do distinguish these cases leading improved results
"DeepEfficiency - optimal efficiency inversion in higher dimensions at
  the LHC","Data Analysis, Statistics and Probability",we introduce new high dimensional algorithm efficiency corrected maximally monte carlo event generator independent fiducial measurements lhc beyond approach driven probabilistically using deep neural network eventbyevent basis trained using detector simulation even only pure phase space distributed events approach gives also glimpse into future high energy physics where experiments publish new type measurements radically multidimensional way
"Information Perspective to Probabilistic Modeling: Boltzmann Machines
  versus Born Machines","Data Analysis, Statistics and Probability",we compare contrast statistical physics quantum physics inspired approaches unsupervised generative modeling classical data two approaches represent probabilities observed data using energybased models quantum states respectivelyclassical quantum information patterns target datasets therefore provide principled guidelines structural design learning these two approaches taking restricted boltzmann machines rbm example we analyze information theoretical bounds two approaches we verify our reasonings comparing performance rbms various architectures standard mnist datasets
"Representing ill-known parts of a numerical model using a machine
  learning approach","Data Analysis, Statistics and Probability",numerical modeling earth system many processes remain unknown ill represented let us quote subgrid processes dependence unknown latent variables noninclusion complex dynamics numerical models but sometimes can be observed paper proposes methodology produce hybrid model combining physicalbased model forecasting wellknown processes neuralnet model trained observations forecasting remaining processes approach applied shallowwater model which forcing dissipative diffusive terms are assumed be unknown we show hybrid model able reproduce great accuracy unknown terms correlation close long term simulations it reproduces no significant difference mean state kinetic energy potential energy potential vorticity system lastly it able function new forcings were not encountered during training phase neural network
Evolutionary method for finding communities in bipartite networks,"Data Analysis, Statistics and Probability",important step unveiling relation between network structure dynamics defined networks detect communities numerous methods have been developed separately identify community structure different classes networks such unipartite networks bipartite networks directed networks we show both unipartite directed networks can be represented bipartite networks their modularity completely consistent bipartite networks detection modular structure which can be reformulated modularity maximization optimize bipartite modularity we develop modified adaptive genetic algorithm maga which shown be especially efficient community structure detection high efficiency maga based following three improvements we make first we introduce different measure informativeness locus instead standard deviation which can exactly determine which loci mutate measure bias between distribution locus over current population uniform distribution locus ie kullbackleibler divergence between them second we develop reassignment technique differentiating informative state locus has attained random state initial phase third we present modified mutation rule which incorporating related operation can guarantee convergence maga global optimum can speed up convergence process experimental results show maga outperforms existing methods terms modularity both bipartite unipartite networks
"Variational Semi-blind Sparse Deconvolution with Orthogonal Kernel Bases
  and its Application to MRFM","Data Analysis, Statistics and Probability",we present variational bayesian method joint image reconstruction point spread function psf estimation when psf imaging device only partially known solve semiblind deconvolution problem prior distributions are specified psf image joint image reconstruction psf estimation then performed within bayesian framework using variational algorithm estimate posterior distribution image prior distribution imposes explicit atomic measure corresponds image sparsity importantly proposed bayesian deconvolution algorithm does not require hand tuning simulation results clearly demonstrate semiblind deconvolution algorithm compares favorably previous markov chain monte carlo mcmc version myopic sparse reconstruction it significantly outperforms mismatched nonblind algorithms rely assumption perfect knowledge psf algorithm illustrated real data magnetic resonance force microscopy mrfm
LIDL: Local Intrinsic Dimension Estimation Using Approximate Likelihood,Machine Learning (Statistics),most existing methods estimating local intrinsic dimension data distribution do not scale well highdimensional data many them rely nonparametric nearest neighbors approach which suffers curse dimensionality we attempt address challenge proposing novel approach problem local intrinsic dimension estimation using approximate likelihood lidl our method relies arbitrary density estimation method its subroutine hence tries sidestep dimensionality challenge making use recent progress parametric neural methods likelihood estimation we carefully investigate empirical properties proposed method compare them our theoretical predictions show lidl yields competitive results standard benchmarks problem it scales thousands dimensions what more we anticipate approach improve further continuing advances density estimation literature
"Extreme Value Theory for Open Set Classification -- GPD and GEV
  Classifiers",Machine Learning (Statistics),classification tasks usually assume all possible classes are present during training phase restrictive if algorithm used over long time possibly encounters samples unknown classes recently introduced extreme value machine classifier motivated extreme value theory addresses problem achieves competitive performance specific cases we show algorithm can fail when geometries known unknown classes differ overcome problem we propose two new algorithms relying approximations extreme value theory we show effectiveness our classifiers simulations letter mnist data sets
Better scalability under potentially heavy-tailed gradients,Machine Learning (Statistics),we study scalable alternative robust gradient descent rgd techniques can be used when gradients can be heavytailed though will be unknown learner core technique simple instead trying robustly aggregate gradients each step which costly leads suboptimal dimension dependence risk bounds we choose candidate which does not diverge too far majority cheap stochastic subprocesses run single pass over partitioned data addition formal guarantees we also provide empirical analysis robustness perturbations experimental conditions under both subgaussian heavytailed data result procedure simple implement trivial parallelize which keeps formal strength rgd methods but scales much better large learning problems
"Robust Semi-supervised Least Squares Classification by Implicit
  Constraints",Machine Learning (Statistics),we introduce implicitly constrained least squares icls classifier novel semisupervised version least squares classifier classifier minimizes squared loss labeled data among set parameters implied all possible labelings unlabeled data unlike other discriminative semisupervised methods approach does not introduce explicit additional assumptions into objective function but leverages implicit assumptions already present choice supervised least squares classifier method can be formulated quadratic programming problem its solution can be found using simple gradient descent procedure we prove limited dimensional setting approach never leads performance worse than supervised classifier experimental results show also general multidimensional case performance improvements can be expected both terms squared loss intrinsic classifier well terms expected classification error
A Generative Modeling Approach to Limited Channel ECG Classification,Machine Learning (Statistics),processing temporal sequences central variety applications health care particular multichannel electrocardiogram ecg highly prevalent diagnostic modality relies robust sequence modeling while recurrent neural networks rnns have led significant advances automated diagnosis timeseries data they perform poorly when models are trained using limited set channels crucial limitation existing solutions they rely solely discriminative models which tend generalize poorly such scenarios order combat limitation we develop generative modeling approach limited channel ecg classification approach first uses seqseq model implicitly generate missing channel information then uses latent representation perform actual supervisory task decoupling enables use unsupervised data also provides highly robust metric spaces subsequent discriminative learning our experiments physionet dataset clearly evidence effectiveness our approach over standard rnns disease prediction
"A Deep Neural Network Deployment Based on Resistive Memory Accelerator
  Simulation",Hardware Architecture,objective study illustrate process training deep neural network dnn within resistive ram reram crossbarbased simulation environment using crosssim application programming interface api developed purpose crosssim api designed simulate neural networks while taking into account factors may affect accuracy solutions during training nonlinear noisy reram devices rerambased neural cores serve memory accelerators digital cores chip can significantly reduce energy consumption minimizing data transfers between processor sram dram crosssim employs lookup tables obtained experimentally derived datasets real fabricated reram devices digitally reproduce noisy weight updates neural network crosssim directory comprises eight device configurations operate different temperatures are made various materials study aims analyse results training neural network breast cancer wisconsin diagnostic dataset using crosssim plotting innercore weight updates average training validation loss investigate outcomes all devices
"Recent Advances in Scalable Energy-Efficient and Trustworthy Spiking
  Neural networks: from Algorithms to Technology",Hardware Architecture,neuromorphic computing particular spiking neural networks snns have become attractive alternative deep neural networks broad range signal processing applications processing static andor temporal inputs different sensory modalities including audio vision sensors paper we start description recent advances algorithmic optimization innovations efficiently train scale lowlatency energyefficient spiking neural networks snns complex machine learning applications we then discuss recent efforts algorithmarchitecture codesign explores inherent tradeoffs between achieving high energyefficiency low latency while still providing high accuracy trustworthiness we then describe underlying hardware has been developed leverage such algorithmic innovations efficient way particular we describe hybrid method integrate significant portions models computation within both memory components well sensor itself finally we discuss potential path forward research building deployable snn systems identifying key challenges algorithmhardwareapplication codesign space emphasis trustworthiness
"Leveraging Residue Number System for Designing High-Precision Analog
  Deep Neural Network Accelerators",Hardware Architecture,achieving high accuracy while maintaining good energy efficiency analog dnn accelerators challenging highprecision data converters are expensive paper we overcome challenge using residue number system rns compose highprecision operations multiple lowprecision operations enables us eliminate information loss caused limited precision adcs our study shows rns can achieve fp accuracy stateoftheart dnn inference using data converters only bit precision we propose using redundant rns achieve faulttolerant analog accelerator addition we show rns can reduce energy consumption data converters within analog accelerator several orders magnitude compared regular fixedpoint approach
"An IoT Endpoint System-on-Chip for Secure and Energy-Efficient
  Near-Sensor Analytics",Hardware Architecture,nearsensor data analytics promising direction iot endpoints it minimizes energy spent communication reduces network load but it also poses security concerns valuable data stored sent over network various stages analytics pipeline using encryption protect sensitive data boundary onchip analytics engine way address data security issues cope combined workload analytics encryption tight power envelope we propose fulmine systemonchip based tightlycoupled multicore cluster augmented specialized blocks computeintensive data processing encryption functions supporting software programmability regular computing tasks fulmine soc fabricated nm technology consumes less than mw average achieving efficiency up pjb encryption pjpx convolution up mipsmw software strong argument reallife flexible application our platform we show experimental results three secure analytics use cases secure autonomous aerial surveillance stateoftheart deep cnn consuming pj per equivalent risc op local cnnbased face detection secured remote recognition pjop seizure detection encrypted data collection eeg within pjop
BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge,Hardware Architecture,existing binary transformers are promising edge deployment due their compact model size low computational complexity considerable inference accuracy however deploying binary transformers faces challenges prior processors due inefficient execution quantized matrix multiplication qmm energy consumption overhead caused multiprecision activations tackle challenges above we first develop computation flow abstraction method binary transformers improve qmm execution efficiency optimizing computation order furthermore binarized energyefficient transformer accelerator namely beta proposed boost efficient deployment edge notably beta features configurable qmm engine accommodating diverse activation precisions binary transformers offering highparallelism highspeed qmms impressive energy efficiency experimental results evaluated zcu fpga show beta achieves average energy efficiency gopsw which higher than prior fpgabased accelerators showing betas good potential edge transformer acceleration
Unifying mirror descent and dual averaging,Optimization and Control,we introduce analyze new family firstorder optimization algorithms which generalizes unifies both mirror descent dual averaging within framework family we define new algorithms constrained optimization combines advantages mirror descent dual averaging our preliminary simulation study shows these new algorithms significantly outperform available methods some situations
"Convergence and Complexity Guarantee for Inexact First-order Riemannian
  Optimization Algorithms",Optimization and Control,we analyze inexact riemannian gradient descent rgd where riemannian gradients retractions are inexactly cheaply computed our focus understanding when inexact rgd converges what complexity general nonconvex constrained setting we answer these questions general framework tangential block majorizationminimization tbmm we establish tbmm converges epsilonstationary point within oepsilon iterations under mild assumption results still hold when subproblem solved inexactly each iteration provided total optimality gap bounded our general analysis applies wide range classical algorithms riemannian constraints including inexact rgd proximal gradient method stiefel manifolds we numerically validate tbmm shows improved performance over existing methods when applied various problems including nonnegative tensor decomposition riemannian constraints regularized nonnegative matrix factorization lowrank matrix recovery problems
Nonlinear Kalman Filtering with Divergence Minimization,Optimization and Control,we consider nonlinear kalman filtering problem using kullbackleibler kl alphadivergence measures optimization criteria unlike linear kalman filters nonlinear kalman filters do not have closed form gaussian posteriors because lack conjugacy due nonlinearity likelihood paper we propose novel algorithms optimize forward reverse forms kl divergence well alphadivergence which contains these two limiting cases unlike previous approaches our algorithms do not make approximations divergences being optimized but use monte carlo integration techniques derive unbiased algorithms direct optimization we assess performance radar sensor tracking options pricing problems showing general improvement over ukf ekf well competitive performance particle filtering
"Optimizing Planning Service Territories by Dividing Into Compact Several
  Sub-areas Using Binary K-means Clustering According Vehicle Constraints",Optimization and Control,vrp vehicle routing problem np hard problem it has attracted lot research interest contexts where vehicles have limited carrying capacity such volume weight but needed deliver items various locations initially before creating route each vehicle needs group delivery points are not exceeding their maximum capacity drivers tend deliver only certain areas clusterbased one approaches give basis generating tighter routes paper we propose new algorithms producing such clustersgroups do not exceed vehicles maximum capacity our basic assumptions are each vehicle originates depot delivers items customers returns depot also vehicles are homogeneous methods are able compact subareas each cluster computational results demonstrate effectiveness our new procedures which are able assist users plan service territories vehicle routes more efficiently
"Finite-Time Analysis of Asynchronous Stochastic Approximation and
  $Q$-Learning",Optimization and Control,we consider general asynchronous stochastic approximation sa scheme featuring weighted infinitynorm contractive operator prove bound its finitetime convergence rate single trajectory additionally we specialize result asynchronous qlearning resulting bound matches sharpest available bound synchronous qlearning improves over previous known bounds asynchronous qlearning
Blind system identification using kernel-based methods,Systems and Control,we propose new method blind system identification resorting gaussian regression framework we model impulse response unknown linear system realization gaussian process structure covariance matrix kernel such process given stable spline kernel which has been recently introduced system identification purposes depends unknown hyperparameter we assume input can be linearly described few parameters we estimate these parameters together kernel hyperparameter noise variance using empirical bayes approach related optimization problem efficiently solved novel iterative scheme based expectationmaximization method particular we show each iteration consists set simple update rules we show through some numerical experiments very promising performance proposed method
"Recursive Total Least-Squares Algorithm Based on Inverse Power Method
  and Dichotomous Coordinate-Descent Iterations",Systems and Control,we develop recursive total leastsquares rtls algorithm errorsinvariables system identification utilizing inverse power method dichotomous coordinatedescent dcd iterations proposed algorithm called dcdrtls outperforms previouslyproposed rtls algorithms which are based linesearch method reduced computational complexity we perform comprehensive analysis dcdrtls algorithm show it asymptotically unbiased well being stable mean we also find lower bound forgetting factor ensures meansquare stability algorithm calculate theoretical steadystate meansquare deviation msd we verify effectiveness proposed algorithm accuracy predicted steadystate msd via simulations
"Real-time Faulted Line Localization and PMU Placement in Power Systems
  through Convolutional Neural Networks",Systems and Control,diverse fault types fast reclosures complicated transient states after fault event make realtime fault location power grids challenging existing localization techniques area rely simplistic assumptions such static loads require much higher sampling rates total measurement availability paper proposes faulted line localization method based convolutional neural network cnn classifier using bus voltages unlike prior datadriven methods proposed classifier based features physical interpretations improve robustness location performance accuracy our cnn based localization tool demonstrably superior other machine learning classifiers literature further improve location performance joint phasor measurement units pmu placement strategy proposed validated against other methods significant aspect our methodology under very low observability buses algorithm still able localize faulted line small neighborhood high probability performance our scheme validated through simulations faults various types ieee bus bus power systems under varying uncertain conditions system observability measurement quality
Sample-Derived Disjunctive Rules for Secure Power System Operation,Systems and Control,machine learning techniques have been used past using monte carlo samples construct predictors dynamic stability power systems paper we move beyond task prediction propose comprehensive approach use predictors such decision trees dt within standard optimization framework pre postfault control purposes particular we present generalizable method embedding rules derived dts operation decisionmaking model we begin pointing out specific challenges entailed when moving prediction control framework we proceed introducing solution strategy based generalized disjunctive programming gdp well twostep search method identifying optimal hyperparameters balancing cost control accuracy we showcase how proposed approach constructs security proxies cover multiple contingencies while facing highdimensional uncertainty respect operating conditions use case study ieee bus system method shown achieve efficient system control marginal increase system price compared oracle model
"Identifying Topology of Power Distribution Networks Based on Smart Meter
  Data",Systems and Control,power distribution network network topology information essential efficient operation network information network connectivity not accurately available low voltage level due uninformed changes happen time time paper we propose novel datadriven approach identify underlying network topology including load phase connectivity time series energy measurements proposed method involves application principal component analysis pca its graphtheoretic interpretation infer topology smart meter energy measurements method demonstrated through simulation randomly generated networks also ieee recognized roy billinton distribution test system
"Graph Laplacians, Riemannian Manifolds and their Machine-Learning",Combinatorics,graph laplacians well related spectral inequalities cohomology provide foray into discrete analogues riemannian manifolds providing rich interplay between combinatorics geometry theoretical physics we apply some latest techniques data science such supervised unsupervised machinelearning topological data analysis wolfram database some finite graphs light studying these correspondences encouragingly we find neural classifiers regressors networks can perform high efficiently accuracy multitude tasks ranging recognizing graph ricciflatness predicting spectral gap detecting presence hamiltonian cycles etc
A Note on the Entropy/Influence Conjecture,Combinatorics,entropyinfluence conjecture raised friedgut kalai seeks relate two different measures concentration fourier coefficients boolean function roughly saying it claims if fourier spectrum smeared out then fourier coefficients are concentrated high levels note we generalize conjecture biased product measures discrete cube prove variant conjecture functions extremely low fourier weight high levels
On the Self Shuffle Language,Combinatorics,shuffle product ushuffle two words set all words which can be obtained interleaving motivated paper emphthe shuffle product new research directions restivo we investigate special case shuffle product work we consider shuffle word itself called emphself shuffle emphshuffle square showing first self shuffle language shuffle language are general different sets we prove language all words arising self shuffle some word context sensitive but not context free furthermore we show self shuffle shuffle uniquely determines
Decomposition Polyhedra of Piecewise Linear Functions,Combinatorics,paper we contribute frequently studied question how decompose continuous piecewise linear cpwl function into difference two convex cpwl functions every cpwl function has infinitely many such decompositions but applications optimization neural network theory it crucial find decompositions few linear pieces possible highly challenging problem we further demonstrate disproving recently proposed approach tran wang minimal representations tropical rational functions algebraic statistics make problem more tractable we propose fix underlying polyhedral complex determining possible locus nonlinearity under assumption we prove set decompositions forms polyhedron arises intersection two translated cones we prove irreducible decompositions correspond bounded faces polyhedron minimal solutions must be vertices we then identify cases unique minimal decomposition illustrate how our insights have consequences theory submodular functions finally we improve upon previous constructions neural networks given convex cpwl function apply our framework obtain results nonconvex case
The Vapnik-Chervonenkis dimension of cubes in $\mathbb{R}^d$,Combinatorics,vapnikchervonenkis vc dimension collection subsets set important combinatorial concept settings such discrete geometry machine learning paper we prove vc dimension family ddimensional cubes mathbb rd lfloordrfloor
Photometric light curves classification with machine learning,Instrumentation and Methods for Astrophysics,large synoptic survey telescope will complete its survey produce terabytes imaging data each night work massive onset data automated algorithms classify astronomical light curves are crucial here we present method automated classification photometric light curves range astronomical objects our approach based gradient boosting decision trees feature extraction selection augmentation solution was developed context photometric lsst astronomical time series classification challenge plasticc achieved one top results challenge
"A Bayesian method for the analysis of deterministic and stochastic time
  series",Instrumentation and Methods for Astrophysics,introduce general bayesian method modelling univariate time series data assumed be drawn continuous stochastic process method accommodates arbitrary temporal sampling takes into account measurement uncertainties arbitrary error models not just gaussian both time signal variables any model deterministic component variation signal time supported any model stochastic component signal time variables models illustrated here are constant sinusoidal models signal mean combined gaussian stochastic component well purely stochastic model ornsteinuhlenbeck process posterior probability distribution over model parameters determined via monte carlo sampling models are compared using crossvalidation likelihood which posterioraveraged likelihood different partitions data are combined principle more robust changes prior than evidence prioraveraged likelihood method demonstrated applying it light curves ultra cool dwarf stars claimed previous study show statistically significant variability reassessed here calculating crossvalidation likelihood various time series models including null hypothesis no variability beyond error bars light curves are confirmed being significantly variable one these seems be periodic two plausible periods identified another object best described ornsteinuhlenbeck process conclusion which obviously limited set models actually tested
"A Study on Classification in Imbalanced and Partially-Labelled Data
  Streams",Instrumentation and Methods for Astrophysics,domain radio astronomy currently facing significant computational challenges foremost amongst which are those posed development worlds largest radio telescope square kilometre array ska preliminary specifications instrument suggest final design will incorporate between individual metre receiving dishes which together can be expected produce data rate many tbs given such high data rate it becomes crucial consider how information will be processed stored maximise its scientific utility paper we consider one possible data processing scenario ska purposes allsky pulsar survey particular we treat selection promising signals ska processing pipeline data stream classification problem we consider feasibility classifying signals arrive via unlabelled heavily class imbalanced data stream using currently available algorithms frameworks our results indicate existing stream learners exhibit unacceptably low recall real astronomical data when used standard configuration however good false positive performance comparable accuracy static learners suggests they have definite potential online solution particular big data challenge
Genetic algorithms in astronomy and astrophysics,Instrumentation and Methods for Astrophysics,genetic algorithms gas emulate process biological evolution computational setting order generate good solutions difficult search optimisation problems gabased optimisers tend be extremely robust versatile compared most traditional techniques used solve optimisation problems review paper provides very brief introduction gas outlines their utility astronomy astrophysics
Machine Learning and the future of Supernova Cosmology,Instrumentation and Methods for Astrophysics,machine learning methods will play fundamental role our ability optimize science output next generation large scale surveys given peculiarities astronomical data it crucial algorithms are adapted data situation hand comment review recent efforts towards development automatic systems identify classify supernova goal enabling their use cosmological standard candles
Monte Carlo Simulation for Lasso-Type Problems by Estimator Augmentation,Methodology (Statistics),regularized linear regression under ell penalty such lasso has been shown be effective variable selection sparse modeling sampling distribution ellpenalized estimator hatbeta hard determine estimator defined optimization problem general can only be solved numerically many its components may be exactly zero let be subgradient ell norm coefficient vector beta evaluated hatbeta we find joint sampling distribution hatbeta together called augmented estimator much more tractable has closedform density under normal error distribution both lowdimensional pleq highdimensional pn settings given beta error variance sigma one may employ standard monte carlo methods such markov chain monte carlo importance sampling draw samples distribution augmented estimator calculate expectations respect sampling distribution hatbeta we develop few concrete monte carlo algorithms demonstrate numerical examples our approach may offer huge advantages great flexibility studying sampling distributions ellpenalized linear regression we also establish nonasymptotic bounds difference between true sampling distribution hatbeta its estimator obtained plugging estimated parameters which justifies validity monte carlo simulation estimated sampling distribution even when pgg nto infty
"Heterogeneous Distributed Lag Models to Estimate Personalized Effects of
  Maternal Exposures to Air Pollution",Methodology (Statistics),childrens health studies support association between maternal environmental exposures childrens birth outcomes common goal identify critical windows susceptibilityperiods during gestation increased association between maternal exposures future outcome timing critical windows magnitude associations are likely heterogeneous across different levels individual family neighborhood characteristics using administrative colorado birth cohort we estimate individualized relationship between weekly exposures fine particulate matter pm during gestation birth weight achieve goal we propose statistical learning method combining distributed lag models bayesian additive regression trees estimate critical windows individual level identify characteristics induce heterogeneity highdimensional set potential modifying factors we find evidence heterogeneity pmbirth weight relationship some motherchild dyads showing times larger decrease birth weight iqr increase exposure mu gm pm compared population average specifically we find increased susceptibility nonhispanic mothers who are either younger have higher body mass index lower educational attainment our case study first precision health study critical windows
"Hierarchical Non-Stationary Temporal Gaussian Processes With
  $L^1$-Regularization",Methodology (Statistics),paper concerned regularized extensions hierarchical nonstationary temporal gaussian processes nsgps which parameters eg lengthscale are modeled gps particular we consider two commonly used nsgp constructions which are based explicitly constructed nonstationary covariance functions stochastic differential equations respectively we extend these nsgps including lregularization processes order induce sparseness solve resulting regularized nsgp rnsgp regression problem we develop method based alternating direction method multipliers admm we also analyze its convergence properties theoretically we also evaluate performance proposed methods simulated realworld datasets
"The Importance of Being Correlated: Implications of Dependence in Joint
  Spectral Inference across Multiple Networks",Methodology (Statistics),spectral inference multiple networks rapidlydeveloping subfield graph statistics recent work has demonstrated joint simultaneous spectral embedding multiple independent networks can deliver more accurate estimation than individual spectral decompositions those same networks such inference procedures typically rely heavily independence assumptions across multiple network realizations even case little attention has been paid induced network correlation such joint embeddings here we present generalized omnibus embedding methodology provide detailed analysis embedding across both independent correlated networks latter which significantly extends reach such procedures we describe how omnibus embedding can itself induce correlation leading us distinguish between inherent correlation correlation arises naturally multisample network data induced correlation which artifice joint embedding methodology we show generalized omnibus embedding procedure flexible robust prove both consistency central limit theorem embedded points we examine how induced inherent correlation can impact inference network time series data we provide network analogues classical questions such effective sample size more generally correlated data further we show how appropriately calibrated generalized omnibus embedding can detect changes real biological networks previous embedding procedures could not discern confirming effect inherent induced correlation can be subtle transformative import theory practice
"A Statistical Approach to Set Classification by Feature Selection with
  Applications to Classification of Histopathology Images",Methodology (Statistics),set classification problems arise when classification tasks are based sets observations opposed individual observations set classification classification rule trained sets observations where each set labeled class information prediction class label performed also set observations data sets set classification appear example diagnostics disease based multiple cell nucleus images single tissue relevant statistical models set classification are introduced which motivate set classification framework based contextfree feature extraction understanding set observations empirical distribution we employ datadriven method choose those features which contain information location major variation particular method principal component analysis used extract features major variation multidimensional scaling used represent features vectorvalued points which conventional classifiers can be applied proposed set classification approaches achieve better classification results than competing methods number simulated data examples benefits our method are demonstrated analysis histopathology images cell nuclei related liver cancer
"Sparse Generalized Principal Component Analysis for Large-scale
  Applications beyond Gaussianity",Computation (Statistics),principal component analysis pca dimension reduction technique it produces inconsistent estimators when dimensionality moderate high which often problem modern largescale applications where algorithm scalability model interpretability are difficult achieve not mention prevalence missing values while existing sparse pca methods alleviate inconsistency they are constrained gaussian assumption classical pca fail address algorithm scalability issues we generalize sparse pca broad exponential family distributions under highdimensional setup builtin treatment missing values meanwhile we propose family iterative sparse generalized pca sgpca algorithms such despite nonconvexity nonsmoothness optimization task loss function decreases every iteration terms ease intuitive parameter tuning our sparsityinducing regularization far superior popular lasso furthermore promote overall scalability accelerated gradient integrated fast convergence while progressive screening technique gradually squeezes out nuisance dimensions largescale problem feasible optimization highdimensional simulation real data experiments demonstrate efficiency efficacy sgpca
"An accuracy-runtime trade-off comparison of scalable Gaussian process
  approximations for spatial data",Computation (Statistics),gaussian processes gps are flexible probabilistic nonparametric models widely employed various fields such spatial statistics time series analysis machine learning drawback gaussian processes their computational cost having mathcalon time mathcalon memory complexity which makes them prohibitive large datasets numerous approximation techniques have been proposed address limitation work we systematically compare accuracy different gaussian process approximations concerning marginal likelihood evaluation parameter estimation prediction taking into account time required achieve certain accuracy we analyze tradeoff between accuracy runtime multiple simulated largescale realworld datasets find vecchia approximations consistently emerge most accurate almost all experiments however certain realworld data sets lowrank inducing pointbased methods ie fullscale modified predictive process approximations can provide more accurate predictive distributions extrapolation
Kernel Sequential Monte Carlo,Computation (Statistics),we propose kernel sequential monte carlo ksmc framework sampling static target densities ksmc family sequential monte carlo algorithms are based building emulator models current particle system reproducing kernel hilbert space we here focus modelling nonlinear covariance structure gradients target emulators geometry adaptively updated subsequently used inform local proposals unlike adaptive markov chain monte carlo continuous adaptation does not compromise convergence sampler ksmc combines strengths sequental monte carlo kernel methods superior performance multimodal targets ability estimate model evidence compared markov chain monte carlo emulators ability represent targets exhibit high degrees nonlinearity ksmc does not require access target gradients it particularly applicable targets whose gradients are unknown prohibitively expensive we describe necessary tuning details demonstrate benefits proposed methodology series challenging synthetic realworld examples
"Efficient Bayesian analysis of multiple changepoint models with
  dependence across segments",Computation (Statistics),we consider bayesian analysis class multiple changepoint models while there are variety efficient ways analyse these models if parameters associated each segment are independent there are few general approaches models where parameters are dependent under assumption dependence markov we propose efficient online algorithm sampling approximation posterior distribution number position changepoints simulation study we show approximation introduced negligible we illustrate power our approach through fitting piecewise polynomial models data under model which allows either continuity discontinuity underlying curve each changepoint method competitive outperforms other methods inferring curves noisy data uniquely it allows inference locations discontinuities underlying curve
"Spatial best linear unbiased prediction: A computational mathematics
  approach for high dimensional massive datasets",Computation (Statistics),advent massive data sets much computational science engineering community has moved toward dataintensive approaches regression classification however these present significant challenges due increasing size complexity dimensionality problems particular covariance matrices many cases are numerically unstable linear algebra shows often such matrices cannot be inverted accurately finite precision computer common ad hoc approach stabilizing matrix application socalled nugget however can change model introduce error original solution it well known numerical analysis illconditioned matrices cannot be accurately inverted paper we develop multilevel computational method scales well number observations dimensions multilevel basis constructed adapted kdtree partitioning observations numerically unstable covariance matrices large condition numbers can be transformed into well conditioned multilevel ones without compromising accuracy moreover it shown multilevel prediction exactly solves best linear unbiased predictor blup generalized least squares gls model but numerically stable multilevel method tested numerically unstable problems up dimensions numerical results show speedups up times solving blup problem but same accuracy traditional iterative approach very illconditioned cases speedup infinite addition decay estimates multilevel covariance matrices are derived based high dimensional interpolation techniques field numerical analysis work lies intersection statistics uncertainty quantification high performance computing computational applied mathematics
"Encoding large scale cosmological structure with Generative Adversarial
  Networks",Cosmology and Nongalactic Astrophysics,recently type neural networks called generative adversarial networks gans has been proposed solution fast generation simulationlike datasets attempt bypass heavy computations expensive cosmological simulations run terms time computing power present work we build train gan look further into strengths limitations such approach we then propose novel method which we make use trained gan construct simple autoencoder ae first step towards building predictive model both gan ae are trained images issued two types nbody simulations namely simulations we find gan successfully generates new images are statistically consistent images it was trained we then show ae manages efficiently extract information simulation images satisfyingly inferring latent encoding gan generate image similar large scale structures
"Noise reduction for weak lensing mass mapping: An application of
  generative adversarial networks to Subaru Hyper Suprime-Cam first-year data",Cosmology and Nongalactic Astrophysics,we propose deeplearning approach based generative adversarial networks gans reduce noise weak lensing mass maps under realistic conditions we apply imagetoimage translation using conditional gans mass map obtained firstyear data subaru hyper suprimecam hsc survey we train conditional gans using mock hsc catalogues directly incorporate variety observational effects we study nongaussian information denoised maps using onepoint probability distribution functions pdfs also perform matching analysis positive peaks massive clusters ensemble learning technique our gans successfully applied reproduce pdfs lensing convergence about peaks denoised maps height greater than sigma have counterparts massive clusters within separation arcmin we show pdfs denoised maps are not compromised details multiplicative biases photometric redshift distributions nor shape measurement errors pdfs show stronger cosmological dependence compared noisy counterpart we apply our denoising method part firstyear hsc data show observed mass distribution statistically consistent prediction standard lambdacdm model
"The Cosmic Graph: Optimal Information Extraction from Large-Scale
  Structure using Catalogues",Cosmology and Nongalactic Astrophysics,we present implicit likelihood approach quantifying cosmological information over discrete catalogue data assembled graphs do so we explore cosmological parameter constraints using mock dark matter halo catalogues we employ information maximising neural networks imnns quantify fisher information extraction function graph representation we demonstrate high sensitivity modular graph structure underlying cosmology noisefree limit show graph neural network summaries automatically combine mass clustering information through comparisons traditional statistics demonstrate networks can still extract information when catalogues are subject noisy survey cuts illustrate how nonlinear imnn summaries can be used asymptotically optimal compressed statistics bayesian simulationbased inference we reduce area joint omegam sigma parameter constraints small sim object halo catalogues factor over twopoint correlation function demonstrate networks automatically combine mass clustering information work utilises new imnn implementation over graph data jax which can take advantage either numerical autodifferentiability we also show graph imnns successfully compress simulations away fiducial model which network fitted indicating promising alternative npoint statistics catalogue simulationbased analyses
Fast cosmic web simulations with generative adversarial networks,Cosmology and Nongalactic Astrophysics,dark matter universe evolves through gravity form complex network halos filaments sheets voids known cosmic web computational models underlying physical processes such classical nbody simulations are extremely resource intensive they track action gravity expanding universe using billions particles tracers cosmic matter distribution therefore upcoming cosmology experiments will face computational bottleneck may limit exploitation their full scientific potential address challenge we demonstrate application machine learning technique called generative adversarial networks gan learn models can efficiently generate new physically realistic realizations cosmic web our training set small representative sample image snapshots nbody simulations size mpc we show gangenerated samples are qualitatively quantitatively very similar originals larger boxes size mpc it very difficult distinguish them visually agreement power spectrum pk most range between important advantage generating cosmic web realizations gan considerable gains terms computation time each new sample generated gan takes fraction second compared many hours needed traditional nbody techniques we anticipate use generative models such gans will therefore play important role providing extremely fast precise simulations cosmic web era large cosmological surveys such euclid large synoptic survey telescope lsst
Learning the Evolution of the Universe in N-body Simulations,Cosmology and Nongalactic Astrophysics,understanding physics large cosmological surveys down small nonlinear scales will significantly improve our knowledge universe large nbody simulations have been built obtain predictions nonlinear regime however nbody simulations are computationally expensive generate large amount data putting burdens storage these data are snapshots simulated universe different times fine sampling necessary accurately save its whole history we employ deep neural network model predict nonlinear nbody simulation intermediate time step given two widely separated snapshots our results outperform cubic hermite interpolation benchmark method interpolating nbody simulations work can greatly reduce storage requirement allow us reconstruct cosmic history far fewer snapshots universe
Representation Learning for Attributed Multiplex Heterogeneous Network,Social and Information Networks,network embedding graph embedding has been widely used many realworld applications however existing methods mainly focus networks singletyped nodesedges cannot scale well handle large networks many realworld networks consist billions nodes edges multiple types each node associated different attributes paper we formalize problem embedding learning attributed multiplex heterogeneous network propose unified framework address problem framework supports both transductive inductive learning we also give theoretical analysis proposed framework showing its connection previous works proving its better expressiveness we conduct systematical evaluations proposed framework four different genres challenging datasets amazon youtube twitter alibaba experimental results demonstrate learned embeddings proposed framework we can achieve statistically significant improvements eg lift scores ttest over previous stateoftheart methods link prediction framework has also been successfully deployed recommendation system worldwide leading ecommerce company alibaba group results offline ab tests product recommendation further confirm effectiveness efficiency framework practice
"Multi-officer Routing for Patrolling High Risk Areas Jointly Learned
  from Check-ins, Crime and Incident Response Data",Social and Information Networks,wellcrafted police patrol route design vital providing community safety security society previous works have largely focused predicting crime events historical crime data usage largescale mobility data collected locationbased social network checkins point interests poi data designing effective police patrol largely understudied given there are multiple police officers being duty reallife situation makes problem more complex solve paper we formulate dynamic crime patrol planning problem multiple police officers using checkins crime incident response data poi information we propose joint learning nonrandom optimisation method representation possible solutions where multiple police officers patrol high crime risk areas simultaneously first rather than low crime risk areas later metaheuristic genetic algorithm ga cuckoo search cs are implemented find optimal routes performance proposed solution verified compared several stateofart methods using realworld datasets
Exact Inference with Latent Variables in an Arbitrary Domain,Social and Information Networks,we analyze necessary sufficient conditions exact inference latent model latent models each entity associated latent variable following some probability distribution challenging question we try solve can we perform exact inference without observing latent variables even without knowing what domain latent variables we show exact inference can be achieved using semidefinite programming sdp approach without knowing either latent variables their domain our analysis predicts experimental correctness sdp high accuracy showing suitability our focus karushkuhntucker kkt conditions spectrum properly defined matrix byproduct our analysis we also provide concentration inequalities dependence latent variables both bounded moment generating functions well spectra matrices best our knowledge these results are novel could be useful many other problems
Modeling Event Propagation via Graph Biased Temporal Point Process,Social and Information Networks,temporal point process widely used sequential data modeling paper we focus problem modeling sequential event propagation graph such retweeting social network users news transmitting between websites etc given collection event propagation sequences conventional point process model consider only event history ie embed event history into vector not latent graph structure we propose graph biased temporal point process gbtpp leveraging structural information graph representation learning where direct influence between nodes indirect influence event history modeled respectively moreover learned node embedding vector also integrated into embedded event history side information experiments synthetic dataset two realworld datasets show efficacy our model compared conventional methods stateoftheart
Predicting affinity ties in a surname network,Social and Information Networks,administrative registers last names santiago chile we create surname affinity network encodes socioeconomic data network multirelational graph nodes representing surnames edges representing prevalence interactions between surnames socioeconomic decile we model prediction links knowledge base completion problem find sharing neighbors highly predictive formation new links importantly we distinguish between grounded neighbors neighbors embedding space find latter more predictive tie formation paper discusses implications finding explaining high levels elite endogamy santiago
Risk factor aggregation and stress testing,Risk Management (Quantitative Finance),stress testing refers application adverse financial macroeconomic scenarios portfolio purpose financial macroeconomic risk factors are linked asset returns typically via factor model we expand range risk factors adapting dimensionreduction techniques unsupervised learning namely pca autoencoders results aggregated risk factors encompassing global factor factors representing broad geographical regions factors specific cyclical defensive industries adapted pca autoencoders provide interpretation latent factors methodology also valuable other areas where dimensionreduction explainability are crucial
"Every Corporation Owns Its Image: Corporate Credit Ratings via
  Convolutional Neural Networks",Risk Management (Quantitative Finance),credit rating analysis credit risks associated corporation which reflect level riskiness reliability investing there have emerged many studies implement machine learning techniques deal corporate credit rating however ability these models limited enormous amounts data financial statement reports work we analyze performance traditional machine learning models predicting corporate credit rating utilizing powerful convolutional neural networks enormous financial data we propose novel endtoend method corporate credit ratings via convolutional neural networks ccrcnn brevity proposed model each corporation transformed into image based image cnn can capture complex feature interactions data which are difficult be revealed previous machine learning models extensive experiments conducted chinese publiclisted corporate rating dataset which we build prove ccrcnn outperforms stateoftheart methods consistently
Application of Deep Neural Networks to assess corporate Credit Rating,Risk Management (Quantitative Finance),recent literature implements machine learning techniques assess corporate credit rating based financial statement reports work we analyze performance four neural network architectures mlp cnn cnnd lstm predicting corporate credit rating issued standard poors we analyze companies energy financial healthcare sectors us goal analysis improve application machine learning algorithms credit assessment end we focus three questions first we investigate if algorithms perform better when using selected subset features if it better allow algorithms select features themselves second temporal aspect inherent financial data important results obtained machine learning algorithm third there particular neural network architecture consistently outperforms others respect input features sectors holdout set we create several case studies answer these questions analyze results using anova multiple comparison testing procedure
"Loss-based Bayesian Sequential Prediction of Value at Risk with a
  Long-Memory and Non-linear Realized Volatility Model",Risk Management (Quantitative Finance),long memory nonlinear realized volatility model class proposed direct value risk var forecasting model referred rnnhar extends heterogeneous autoregressive har model framework known efficiently capturing long memory realized measures integrating recurrent neural network rnn handle nonlinear dynamics lossbased generalized bayesian inference sequential monte carlo employed model estimation sequential prediction rnn har empirical analysis conducted using daily closing prices realized measures across market indices proposed models one step ahead var forecasting performance compared against basic har model its extensions results demonstrate proposed rnnhar model consistently outperforms all other models considered study
Explainable AI in Credit Risk Management,Risk Management (Quantitative Finance),artificial intelligence ai has created single biggest technology revolution world has ever seen finance sector it provides great opportunities enhance customer experience democratize financial services ensure consumer protection significantly improve risk management while it easier than ever run stateoftheart machine learning models designing implementing systems support realworld finance applications have been challenging large part because they lack transparency explainability which are important factors establishing reliable technology research topic specific focus applications credit risk management paper we implement two advanced posthoc model agnostic explainability techniques called local interpretable model agnostic explanations lime shapley additive explanations shap machine learning mlbased credit scoring models applied openaccess data set offered usbased pp lending platform lending club specifically we use lime explain instances locally shap get both local global explanations we discuss results detail present multiple comparison scenarios using various kernels available explaining graphs generated using shap values we also discuss practical challenges associated implementation these stateofart explainabale ai xai methods document them future reference we have made effort document every technical aspect research while same time providing general summary conclusions
Uniform Approximation and Bracketing Properties of VC classes,Probability,we show sets family finite vc dimension can be uniformly approximated within given error finite partition immediate corollaries include fact vc classes have finite bracketing numbers satisfy uniform laws averages under strong dependence exhibit uniform mixing our results are based recent work concerning uniform laws averages vc classes under ergodic sampling
A diffusion approach to Stein's method on Riemannian manifolds,Probability,we detail approach develop steins method bounding integral metrics probability measures defined riemannian manifold mathbf our approach exploits relationship between generator diffusion mathbf target invariant measure its characterising stein operator we consider pair such diffusions different starting points through analysis distance process between pair derive stein factors which bound solution stein equation its derivatives stein factors contain curvaturedependent terms reduce those currently available mathbb rm moreover imply bounds mathbb rm remain valid when mathbf flat manifold
"Universality for the global spectrum of random inner-product kernel
  matrices in the polynomial regime",Probability,we consider certain large random matrices called random innerproduct kernel matrices which are essentially given nonlinear function applied entrywise samplecovariance matrix fxtx where mathbbrd times random normalized such way typically has orderone arguments we work polynomial regime where asymp dell some ell not just linear regime where ell earlier work various sphere standard gaussian vectors when ell integer linear regime ell particularly wellstudied bulk eigenvalues such matrices behave simple way they are asymptotically given free convolution semicircular marvcenkopastur distributions relative weights given expanding hermite basis paper we show phenomenon universal holding soon has iid entries all finite moments case noninteger ell marvcenkopastur term disappears its weight free convolution vanishes spectrum just semicircular
Asymptotics of Discrete Schrödinger Bridges via Chaos Decomposition,Probability,consider problem matching two independent iid samples size two distributions mathbbrd arbitrary continuous cost function optimal assignment problem looks matching minimizes total cost we consider instead paper problem where each matching endowed gibbs probability weight proportional exponential negative total cost matching viewing each matching joint distribution atoms we then take convex combination respect above gibbs probability measure we show resulting random joint distribution converges nrightarrow infty solution variational problem introduced follmer called schrodinger problem we also derive first two error terms orders respectively gives us central limit theorems integrated test functions including cost transport second order gaussian chaos limits when limiting gaussian variance zero proofs are based novel chaos decomposition discrete schrodinger bridge polynomial functions pair empirical distributions first second order taylor approximations space measures achieved extending hoeffding decomposition classical theory ustatistics
"A Short Note on Concentration Inequalities for Random Vectors with
  SubGaussian Norm",Probability,note we derive concentration inequalities random vectors subgaussian norm generalization both subgaussian random vectors norm bounded random vectors which are tight up logarithmic factors
Uncovering Sociological Effect Heterogeneity using Machine Learning,Other Statistics,individuals do not respond uniformly treatments events interventions sociologists routinely partition samples into subgroups explore how effects treatments vary covariates like race gender socioeconomic status so doing analysts determine key subpopulations based theoretical priors datadriven discoveries are also routine yet analyses which sociologists typically go about them are problematic seldom move us beyond our expectations biases explore new meaningful subgroups emerging machine learning methods allow researchers explore sources variation they may not have previously considered envisaged paper we use causal trees recursively partition sample uncover sources treatment effect heterogeneity we use honest estimation splitting sample into training sample grow tree estimation sample estimate leafspecific effects assessing central topic social inequality literature college effects wages we compare what we learn conventional approaches exploring variation effects causal trees given our use observational data we use leafspecific matching sensitivity analyses address confounding offer interpretations effects based observed unobserved heterogeneity we encourage researchers follow similar practices their work variation sociological effects
Model Selection in Undirected Graphical Models with the Elastic Net,Other Statistics,structure learning random fields has attracted considerable attention due its difficulty importance areas such remote sensing computational biology natural language processing protein networks social network analysis we consider problem estimating probabilistic graph structure associated gaussian markov random field gmrf ising model potts model extending previous work regularized neighborhood estimation include elastic net ll penalty additionally we show numerical evidence edge density plays role graph recovery process finally we introduce novel method augmenting neighborhood estimation leveraging pairwise neighborhood union estimates
"A machine learning methodology for real-time forecasting of the
  2019-2020 COVID-19 outbreak using Internet searches, news alerts, and
  estimates from mechanistic models",Other Statistics,we present timely novel methodology combines disease estimates mechanistic models digital traces via interpretable machinelearning methodologies reliably forecast covid activity chinese provinces realtime specifically our method able produce stable accurate forecasts days ahead current time uses inputs official health reports chinese center disease control prevention china cdc covidrelated internet search activity baidu news media activity reported media cloud daily forecasts covid activity gleam agentbased mechanistic model our machinelearning methodology uses clustering technique enables exploitation geospatial synchronicities covid activity across chinese provinces data augmentation technique deal small number historical disease activity observations characteristic emerging outbreaks our models predictive power outperforms collection baseline models out chinese provinces could be easily extended other geographies currently affected covid outbreak help decision makers
The Fuzzy ROC,Other Statistics,fuzzy roc extends receiver operating curve roc visualization situation where some data points falling indeterminacy region are not classified it addresses two challenges definition sensitivity specificity bounds under indeterminacy visual summarization large number possibilities arising different choices indeterminacy zones
Uncovering Sociological Effect Heterogeneity using Machine Learning,Other Statistics,individuals do not respond uniformly treatments events interventions sociologists routinely partition samples into subgroups explore how effects treatments vary covariates like race gender socioeconomic status so doing analysts determine key subpopulations based theoretical priors datadriven discoveries are also routine yet analyses which sociologists typically go about them are problematic seldom move us beyond our expectations biases explore new meaningful subgroups emerging machine learning methods allow researchers explore sources variation they may not have previously considered envisaged paper we use causal trees recursively partition sample uncover sources treatment effect heterogeneity we use honest estimation splitting sample into training sample grow tree estimation sample estimate leafspecific effects assessing central topic social inequality literature college effects wages we compare what we learn conventional approaches exploring variation effects causal trees given our use observational data we use leafspecific matching sensitivity analyses address confounding offer interpretations effects based observed unobserved heterogeneity we encourage researchers follow similar practices their work variation sociological effects
"Eternal Sunshine of the Mechanical Mind: The Irreconcilability of
  Machine Learning and the Right to be Forgotten",General Literature,we keep rapidly advancing toward era where artificial intelligence constant normative experience most us we must also be aware what vision progress entail first approximating neural connections activities computer circuits then creating more more sophisticated versions crude approximation we are now facing age come where modern deep learningbased artificial intelligence systems can rightly be called thinking machines they are sometimes even lauded their emergent behavior blackbox approaches but we create more powerful electronic brains billions neural connections parameters can we guarantee these mammoths built artificial neurons will be able forget data we store them if they are some level like brain can right be forgotten still be protected while dealing these ais essential gap between machine learning rtbf explored article premonition farreaching conclusions if gap not bridged reconciled any time soon core argument deep learning models due their structure size cannot be expected forget delete data it would be expected tabular database they should be treated more like mechanical brain albeit still development
"Navigating Diverse Data Science Learning: Critical Reflections Towards
  Future Practice",General Literature,data science currently popular field science attracting expertise very diverse backgrounds current learning practices need acknowledge adapt it paper summarises some experiences relating such learning approaches teaching postgraduate data science module draws some learned lessons are relevance others teaching data science
"Epistemology of Modeling and Simulation: How can we gain Knowledge from
  Simulations?",General Literature,epistemology branch philosophy deals gaining knowledge it closely related ontology branch deals questions like what real what do we know it provides these components when using modeling simulation we usually imply we are doing so either apply knowledge particular when we are using them training teaching we want gain new knowledge example when doing analysis conducting virtual experiments paper looks history science give context better cope question how we can gain knowledge simulation it addresses aspects computability general underlying mathematics applies findings validation verification development federations simulations are understood computable executable hypotheses validation can be understood hypothesis testing theory building mathematical framework allows furthermore addressing some challenges when developing federations potential introduction contradictions when composing different theories they are represented federated simulation systems
"Eternal Sunshine of the Mechanical Mind: The Irreconcilability of
  Machine Learning and the Right to be Forgotten",General Literature,we keep rapidly advancing toward era where artificial intelligence constant normative experience most us we must also be aware what vision progress entail first approximating neural connections activities computer circuits then creating more more sophisticated versions crude approximation we are now facing age come where modern deep learningbased artificial intelligence systems can rightly be called thinking machines they are sometimes even lauded their emergent behavior blackbox approaches but we create more powerful electronic brains billions neural connections parameters can we guarantee these mammoths built artificial neurons will be able forget data we store them if they are some level like brain can right be forgotten still be protected while dealing these ais essential gap between machine learning rtbf explored article premonition farreaching conclusions if gap not bridged reconciled any time soon core argument deep learning models due their structure size cannot be expected forget delete data it would be expected tabular database they should be treated more like mechanical brain albeit still development
"Eternal Sunshine of the Mechanical Mind: The Irreconcilability of
  Machine Learning and the Right to be Forgotten",General Literature,we keep rapidly advancing toward era where artificial intelligence constant normative experience most us we must also be aware what vision progress entail first approximating neural connections activities computer circuits then creating more more sophisticated versions crude approximation we are now facing age come where modern deep learningbased artificial intelligence systems can rightly be called thinking machines they are sometimes even lauded their emergent behavior blackbox approaches but we create more powerful electronic brains billions neural connections parameters can we guarantee these mammoths built artificial neurons will be able forget data we store them if they are some level like brain can right be forgotten still be protected while dealing these ais essential gap between machine learning rtbf explored article premonition farreaching conclusions if gap not bridged reconciled any time soon core argument deep learning models due their structure size cannot be expected forget delete data it would be expected tabular database they should be treated more like mechanical brain albeit still development
"Hierarchical robust aggregation of sales forecasts at aggregated levels
  in e-commerce, based on exponential smoothing and Holt's linear trend method",Applications (Statistics),we revisit interest classical statistical techniques sales forecasting like exponential smoothing extensions thereof holts linear trend method we do so considering ensemble forecasts given several instances these classical techniques tuned different sets parameters forming convex combinations elements ensemble forecasts over time robust sequential manner machinelearning theory behind called robust online aggregation prediction expert advice prediction individual sequences see cesabianchi lugosi we apply methodology hierarchical data set sales provided ecommerce company cdiscount output forecasts levels subsubfamilies subfamilies families items sold various forecasting horizons up weekahead performance achieved better than what would be obtained optimally tuning classical techniques train set using their forecasts test set performance also good intrinsic point view terms mean absolute percentage error while getting these better forecasts sales levels subsubfamilies subfamilies families interesting per se we also suggest use them additional features when forecasting demand item level
Two-step interpretable modeling of Intensive Care Acquired Infections,Applications (Statistics),we present novel methodology integrating high resolution longitudinal data dynamic prediction capabilities survival models aim twofold improve predictive power while maintaining interpretability models go beyond black box paradigm artificial neural networks we propose parsimonious robust semiparametric approach ie landmarking competing risks model combines routinely collected lowresolution data predictive features extracted convolutional neural network was trained high resolution timedependent information we then use saliency maps analyze explain extra predictive power model illustrate our methodology we focus healthcareassociated infections patients admitted intensive care unit
"Estimating heterogeneous survival treatment effect in observational data
  using machine learning",Applications (Statistics),methods estimating heterogeneous treatment effect observational data have largely focused continuous binary outcomes have been relatively less vetted survival outcomes using flexible machine learning methods counterfactual framework promising approach address challenges due complex individual characteristics which treatments need be tailored evaluate operating characteristics recent survival machine learning methods estimation treatment effect heterogeneity inform better practice we carry out comprehensive simulation study presenting wide range settings describing confounded heterogeneous survival treatment effects varying degrees covariate overlap our results suggest nonparametric bayesian additive regression trees within framework accelerated failure time model aftbartnp consistently yields best performance terms bias precision expected regret moreover credible interval estimators aftbartnp provide close nominal frequentist coverage individual survival treatment effect when covariate overlap least moderate including nonparametrically estimated propensity score additional fixed covariate aftbartnp model formulation can further improve its efficiency frequentist coverage finally we demonstrate application flexible causal machine learning estimators through comprehensive case study examining heterogeneous survival effects two radiotherapy approaches localized highrisk prostate cancer
"Scalable Modeling of Spatiotemporal Data using the Variational
  Autoencoder: an Application in Glaucoma",Applications (Statistics),big spatial data becomes increasingly prevalent classical spatiotemporal st methods often do not scale well while methods have been developed account highdimensional spatial objects setting where there are exceedingly large samples spatial observations has had less attention variational autoencoder vae unsupervised generative model based deep learning approximate bayesian inference fills void using latent variable specification inferred jointly across large number samples manuscript we compare performance vae more classical st method when analyzing longitudinal visual fields large cohort patients prospective glaucoma study through simulation case study we demonstrate vae scalable method analyzing st data when goal obtain accurate predictions code implement vae can be found github httpsgithubcomberchuckvaest
"Transposable regularized covariance models with an application to
  missing data imputation",Applications (Statistics),missing data estimation important challenge highdimensional data arranged form matrix typically data matrix transposable meaning either rows columns both can be treated features model transposable data we present modification matrixvariate normal meanrestricted matrixvariate normal which rows columns each have separate mean vector covariance matrix placing additive penalties inverse covariance matrices rows columns these socalled transposable regularized covariance models allow maximum likelihood estimation mean nonsingular covariance matrices using these models we formulate emtype algorithms missing data imputation both multivariate transposable frameworks we present theoretical results exploiting structure our transposable models allow these models imputation methods be applied highdimensional data simulations results microarray data netflix data show these imputation techniques often outperform existing methods offer greater degree flexibility
On a correlational clustering of integers,Number Theory,correlation clustering concept machine learning ultimate goal such clustering find partition minimal conflicts paper we investigate correlation clustering integers based upon greatest common divisor
On a correlational clustering of integers,Number Theory,correlation clustering concept machine learning ultimate goal such clustering find partition minimal conflicts paper we investigate correlation clustering integers based upon greatest common divisor
On a correlational clustering of integers,Number Theory,correlation clustering concept machine learning ultimate goal such clustering find partition minimal conflicts paper we investigate correlation clustering integers based upon greatest common divisor
On a correlational clustering of integers,Number Theory,correlation clustering concept machine learning ultimate goal such clustering find partition minimal conflicts paper we investigate correlation clustering integers based upon greatest common divisor
On a correlational clustering of integers,Number Theory,correlation clustering concept machine learning ultimate goal such clustering find partition minimal conflicts paper we investigate correlation clustering integers based upon greatest common divisor
"Emotional Video to Audio Transformation Using Deep Recurrent Neural
  Networks and a Neuro-Fuzzy System",Sound,generating music emotion similar input video very relevant issue nowadays video content creators automatic movie directors benefit maintaining their viewers engaged which can be facilitated producing novel material eliciting stronger emotions them moreover theres currently demand more empathetic computers aid humans applications such augmenting perception ability visually andor hearing impaired people current approaches overlook videos emotional characteristics music generation step only consider static images instead videos are unable generate novel music require high level human effort skills study we propose novel hybrid deep neural network uses adaptive neurofuzzy inference system predict videos emotion its visual features deep long shortterm memory recurrent neural network generate its corresponding audio signals similar emotional inkling former able appropriately model emotions due its fuzzy properties latter able model data dynamic time properties well due availability previous hidden state information novelty our proposed method lies extraction visual emotional features order transform them into audio signals corresponding emotional aspects users quantitative experiments show low mean absolute errors lindsey deap datasets respectively similar global features spectrograms indicates our model able appropriately perform domain transformation between visual audio features based experimental results our model can effectively generate audio matches scene eliciting similar emotion viewer both datasets music generated our model also chosen more often
Collaborative Learning for Language and Speaker Recognition,Sound,paper presents unified model perform language speaker recognition simultaneously altogether model based multitask recurrent neural network where output one task fed input other leading collaborative learning framework can improve both language speaker recognition borrowing information each other our experiments demonstrated multitask model outperforms taskspecific models both tasks
Query-based Deep Improvisation,Sound,paper we explore techniques generating new music using variational autoencoder vae neural network was trained corpus specific style instead randomly sampling latent states network produce free improvisation we generate new music querying network musical input style different training corpus allows us produce new musical output longerterm structure blends aspects query style network order control level blending we add noisy channel between vae encoder decoder using bitallocation algorithm communication ratedistortion theory our experiments provide new insight into relations between representational structural information latent states query signal suggesting their possible use composition purposes
"PSCodec: A Series of High-Fidelity Low-bitrate Neural Speech Codecs
  Leveraging Prompt Encoders",Sound,neural speech codecs have recently emerged focal point fields speech compression generation despite progress achieving highquality speech reconstruction under lowbitrate scenarios remains significant challenge paper we propose pscodec series neural speech codecs based prompt encoders comprising pscodecbase pscodecdrlict pscodeccasan which are capable delivering highperformance speech reconstruction low bandwidths specifically we first introduce pscodecbase which leverages pretrained speaker verification modelbased prompt encoder vppenc learnable melspectrogrambased prompt encoder melpenc effectively disentangle integrate voiceprint melrelated features utterances further enhance feature utilization efficiency we propose pscodecdrlict incorporating structural similarity ssim based disentangled representation loss drl incremental continuous training ict strategy while pscodecdrlict demonstrates impressive performance its reliance extensive hyperparameter tuning multistage training makes it somewhat laborintensive circumvent these limitations we propose pscodeccasan utilizing advanced cascaded attention network casan enhance representational capacity entire system extensive experiments show our proposed pscodecbase pscodecdrlict pscodeccasan all significantly outperform several stateoftheart neural codecs exhibiting substantial improvements both speech reconstruction quality speaker similarity under lowbitrate conditions
"Emotion Recognition from Speech based on Relevant Feature and Majority
  Voting",Sound,paper proposes approach detect emotion human speech employing majority voting technique over several machine learning techniques contribution work two folds firstly it selects those features speech which most promising classification secondly it uses majority voting technique selects exact class emotion here majority voting technique has been applied over neural network nn decision tree dt support vector machine svm knearest neighbor knn input vector nn dt svm knn consists various acoustic prosodic features like pitch melfrequency cepstral coefficients etc speech signal many feature have been extracted only promising features have been selected consider feature promising fast correlation based feature selection fcbf fisher score algorithms have been used only those features are selected which are highly ranked both them proposed approach has been tested berlin dataset emotional speech electromagnetic articulography ema dataset experimental result shows majority voting technique attains better accuracy over individual machine learning techniques employment proposed approach can effectively recognize emotion human beings case social robot intelligent chat client callcenter company etc
"Recommendation Engine for Lower Interest Borrowing on Peer to Peer
  Lending (P2PL) Platform",General Finance (Quantitative Finance),online peer peer lending ppl systems connect lenders borrowers directly thereby making it convenient borrow lend money without intermediaries such banks many recommendation systems have been developed lenders achieve higher interest rates avoid defaulting loans however there has not been much research developing recommendation systems help borrowers make wise decisions ppl platforms borrowers can either apply bidding loans where interest rate determined lenders bidding loan traditional loans where ppl platform determines interest rate different borrower grades determining credit worthiness borrowers get different interest rates via these two mechanisms hence it essential determine which type loans borrowers should apply paper we build recommendation system recommends any new borrower type loan they should apply using our recommendation system any borrower can achieve lowered interest rates higher likelihood getting funded
Indian Economy and Nighttime Lights,General Finance (Quantitative Finance),forecasting economic growth india has been traditionally uncertain exercise indicators factors affecting economic structures variables required model captures situation correctly point concern although forecast should be specific country we are looking however countries do have interlinkages among them time series can be more volatile sometimes certain variables are unavailable it harder predict developing economies compared stable developed nations however it very important have accurate forecasts economic growth successful policy formations one hypothesized indicators nighttime lights here we aim look relationship between gdp nighttime lights specifically we look dmsp viirs dataset we are finding relationship between various measures economy
"Applying Dynamic Training-Subset Selection Methods Using Genetic
  Programming for Forecasting Implied Volatility",General Finance (Quantitative Finance),volatility key variable option pricing trading hedging strategies purpose paper improve accuracy forecasting implied volatility using extension genetic programming gp means dynamic trainingsubset selection methods these methods manipulate training data order improve out sample patterns fitting when applied static subset selection method using single training data sample gp could generate forecasting models which are not adapted some out sample fitness cases order improve predictive accuracy generated gp patterns dynamic subset selection methods are introduced gp algorithm allowing regular change training sample during evolution four dynamic trainingsubset selection methods are proposed based random sequential adaptive subset selection latest approach uses adaptive subset weight measuring sample difficulty according fitness cases errors using real data sp index options these techniques are compared static subset selection method based mse total percentage non fitted observations results show dynamic approach improves forecasting performance generated gp models specially those obtained adaptive random training subset selection method applied whole set training samples
Data Science in Economics,General Finance (Quantitative Finance),paper provides state art data science economics through novel taxonomy applications methods advances data science are investigated data science advances are investigated three individual classes deep learning models ensemble models hybrid models application domains include stock market marketing ecommerce corporate banking cryptocurrency prisma method systematic literature review methodology used ensure quality survey findings revealed trends are advancement hybrid models more than reviewed articles applied hybrid model other hand it found based rmse accuracy metric hybrid models had higher prediction accuracy than other algorithms while it expected trends go toward advancements deep learning models
Earnings Prediction with Deep Learning,General Finance (Quantitative Finance),financial sector reliable forecast future financial performance company great importance investors investment decisions paper we compare longterm shortterm memory lstm networks temporal convolution network tcns prediction future earnings per share eps experimental analysis based quarterly financial reporting data daily stock market returns broad sample us firms we find both lstms outperform naive persistent model up more accurate predictions while tcns achieve improvement both types networks are least accurate analysts exceed them up lstm tcn
"Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and
  Influence!",History and Overview (Mathematics),wordle popular online word game offered new york times nytimescom currently there are some million players english version worldwide players have attempts guess daily word target word after each attempt player receives colorcoded information about correctness position each letter guess after either successful completion puzzle final unsuccessful attempt software can assess players luck skill using information theory can display data first second sixth guesses random sample all players recently discovered latter data presented format can easily be copied pasted into spreadsheet compiled data wordle players first guesses may august inferred some interesting information about wordle players every day about players solve puzzle one attempt because odds guessing one possible target words random implies players cheat obtaining target word outside playing game least players have favorite starting word cycle through several even though players should be aware target words are never repeated most players appear remain loyal their starting word even after its appearance target word august about players abruptly changed their starting word presumably based crossword puzzle clue wordle players can be influenced study goes beyond social media postings surveys google trends provide solid quantitative evidence about cheating wordle
Notes on a Path to AI Assistance in Mathematical Reasoning,History and Overview (Mathematics),these informal notes are based academies science engineering mathematics workshop ai assist mathematical reasoning june goal think through path which we might arrive ai useful research mathematician
"From Good to Great: Improving Math Reasoning with Tool-Augmented
  Interleaf Prompting",History and Overview (Mathematics),paper investigates performance large language models llms toolaugmented llms tackling complex mathematical reasoning tasks we introduce imptip improving math reasoning toolaugmented interleaf prompting framework combines strengths both llms toolaugmented llms imptip follows good great concept collecting multiple potential solutions both llms their toolaugmented counterparts same math problem then selecting regenerating most accurate answer after crosschecking these solutions via toolaugmented interleaf prompting framework incorporates two key aspects selfprompt toolaugmented interleaf prompting tip former allows llms autonomously refine improve initial prompt related tool usage while latter enables llms derive final answer dynamically analyzing problem crosschecking potential solutions revising previous reasoning hints interleaved manner experimental analysis shows imptip achieves enhanced mathematical capabilities outperforms traditional llms toolaugmented llms accuracy reasoning diversity math reasoning tasks instance imptip can improve toolaugmented chatgpt gsmkhard
"Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and
  Influence!",History and Overview (Mathematics),wordle popular online word game offered new york times nytimescom currently there are some million players english version worldwide players have attempts guess daily word target word after each attempt player receives colorcoded information about correctness position each letter guess after either successful completion puzzle final unsuccessful attempt software can assess players luck skill using information theory can display data first second sixth guesses random sample all players recently discovered latter data presented format can easily be copied pasted into spreadsheet compiled data wordle players first guesses may august inferred some interesting information about wordle players every day about players solve puzzle one attempt because odds guessing one possible target words random implies players cheat obtaining target word outside playing game least players have favorite starting word cycle through several even though players should be aware target words are never repeated most players appear remain loyal their starting word even after its appearance target word august about players abruptly changed their starting word presumably based crossword puzzle clue wordle players can be influenced study goes beyond social media postings surveys google trends provide solid quantitative evidence about cheating wordle
Intransitively winning chess players positions,History and Overview (Mathematics),positions chess players intransitive rockpaperscissors relations are considered namely position white preferable it should be chosen if choice possible position black position black preferable position white position white preferable position black but position black preferable position white intransitivity winningness positions chess players considered be consequence complexity chess environment contrast simpler games transitive positions only space relations between winningness positions chess players noneuclidean zermelovon neumann theorem complemented statements about possibility vs impossibility building pure winning strategies based assumption transitivity positions chess players questions about possibility intransitive positions players other positional games are raised
Analysis Co-Sparse Coding for Energy Disaggregation,Signal Processing,energy disaggregation task segregating aggregate energy entire building logged smartmeter into energy consumed individual appliances single channel only channel being smartmeter blind source different electrical appliances separation problem recent times dictionary learning based approaches have shown promise addressing disaggregation problem usual technique learn dictionary every device use learnt dictionaries basis blind source separation during disaggregation dictionary learning synthesis formulation work we propose analysis approach advantage our proposed approach requirement training volume drastically reduces compared stateoftheart techniques means we require fewer instrumented homes fewer days instrumentation per home either case drastically reduces sensing cost results two benchmark datasets show our method produces same level disaggregation accuracy stateoftheart methods but only fraction training data
"On the suitability of generalized regression neural networks for GNSS
  position time series prediction for geodetic applications in geodesy and
  geophysics",Signal Processing,paper generalized regression neural network used predict gnss position time series using igs hour final solution data bad hamburg permanent gnss station germany it shown larger training network higher accuracy regardless time span time series order analyze performance neural network various conditions permanent stations are used different countries namely spain france romania poland russian federation united kingdom czech republic sweden ukraine italy finland slovak republic cyprus greece performance analysis divided into two parts continuous datawithout gapsand discontinuous oneshaving intervals gaps no data available three measure error are presented namely symmetric mean absolute percentage error standard deviation mean absolute errors it shown discontinuous data position can be predicted accuracy up centimeters while continuous data positions present higher prediction accuracy high centimeters order compare results machine learning algorithm traditional statistical approaches theta method used which wellestablished highaccuracy time series prediction comparison shows generalized regression neural network machine learning algorithm presents better accuracy than theta method possibly up times addition it approximately times faster
Semi-automated Annotation of Signal Events in Clinical EEG Data,Signal Processing,be effective state art machine learning technology needs large amounts annotated data there are numerous compelling applications healthcare can benefit high performance automated decision support systems provided deep learning technology but they lack comprehensive data resources required apply sophisticated machine learning models further economic reasons it very difficult justify creation large annotated corpora these applications hence automated annotation techniques become increasingly important study we investigated effectiveness using active learning algorithm automatically annotate large eeg corpus algorithm designed annotate six types eeg events two model training schemes namely thresholdbased volumebased are evaluated thresholdbased scheme threshold confidence scores optimized initial training iteration whereas volumebased scheme only certain amount data preserved after each iteration recognition performance improved absolute system capable automatically annotating previously unlabeled data given interpretation clinical eeg data exceedingly difficult task study provides some evidence proposed method viable alternative expensive manual annotation
Deep unfolding of the weighted MMSE beamforming algorithm,Signal Processing,downlink beamforming key technology cellular networks however computing transmit beamformer maximizes weighted sum rate subject power constraint nphard problem result iterative algorithms converge local optimum are used practice among them weighted minimum mean square error wmmse algorithm has gained popularity but its computational complexity consequent latency has motivated need lowercomplexity approximations expense performance motivated recent success deep unfolding tradeoff between complexity performance we propose novel application deep unfolding wmmse algorithm miso downlink channel main idea consists mapping fixed number iterations wmmse algorithm into trainable neural network layers whose architecture reflects structure original algorithm respect traditional endtoend learning deep unfolding naturally incorporates expert knowledge benefits immediate wellgrounded architecture selection fewer trainable parameters better explainability however formulation wmmse algorithm described shi et al not amenable be unfolded due matrix inversion eigendecomposition bisection search performed each iteration therefore we present alternative formulation circumvents these operations resorting projected gradient descent means simulations we show most settings unfolded wmmse outperforms performs equally wmmse fixed number iterations advantage lower computational load
Interference Classification Using Deep Neural Networks,Signal Processing,recent success implementing supervised learning classify modulation types suggests other problems akin modulation classification would eventually benefit implementation one these problems classifying interference type added signalofinterest also known interference classification paper we propose interference classification method using deep neural network we generate five distinct types interfering signals then use both powerspectral density psd cyclic spectrum received signal input features network computer experiments reveal using received signal psd outperforms using its cyclic spectrum terms accuracy addition same experiments show feedforward networks yield better accuracy than classic methods proposed classifier aids subsequent stage receiver chain choosing appropriate mitigation algorithm also can coexist modulationclassification methods further improve classifier accuracy
Choquet integral in decision analysis - lessons from the axiomatization,Economics (Quantitative Finance),choquet integral powerful aggregation operator which lists many wellknown models its special cases we look these special cases provide their axiomatic analysis cases where axiomatization has been previously given literature we connect existing results framework we have developed next we turn question learning which especially important practical applications model so far learning choquet integral has been mostly confined learning capacity such approach requires making powerful assumption all dimensions eg criteria are evaluated same scale which rarely justified practice too often categorical data given arbitrary numerical labels eg ahp numerical data considered cardinally ordinally commensurate sometimes after simple normalization such approaches clearly lack scientific rigour yet they are commonly seen all kinds applications we discuss pros cons making such assumption look consequences which axiomatization uniqueness results have learning problems finally we review some applications choquet integral decision analysis apart mcda which main area interest our results we also discuss how model can be interpreted social choice context we look detail statedependent utility show how comonotonicity central previous axiomatizations actually implies stateindependency choquet integral model we also discuss conditions required have meaningful statedependent utility representation show novelty our results compared previous methods building statedependent models
"Divisive-agglomerative algorithm and complexity of automatic
  classification problems",Economics (Quantitative Finance),algorithm solution automatic classification ac brevity problem set forth paper ac problem it required find one several artitions starting given pattern matrix dissimilarity similarity matrix
Choquet integral in decision analysis - lessons from the axiomatization,Economics (Quantitative Finance),choquet integral powerful aggregation operator which lists many wellknown models its special cases we look these special cases provide their axiomatic analysis cases where axiomatization has been previously given literature we connect existing results framework we have developed next we turn question learning which especially important practical applications model so far learning choquet integral has been mostly confined learning capacity such approach requires making powerful assumption all dimensions eg criteria are evaluated same scale which rarely justified practice too often categorical data given arbitrary numerical labels eg ahp numerical data considered cardinally ordinally commensurate sometimes after simple normalization such approaches clearly lack scientific rigour yet they are commonly seen all kinds applications we discuss pros cons making such assumption look consequences which axiomatization uniqueness results have learning problems finally we review some applications choquet integral decision analysis apart mcda which main area interest our results we also discuss how model can be interpreted social choice context we look detail statedependent utility show how comonotonicity central previous axiomatizations actually implies stateindependency choquet integral model we also discuss conditions required have meaningful statedependent utility representation show novelty our results compared previous methods building statedependent models
Choquet integral in decision analysis - lessons from the axiomatization,Economics (Quantitative Finance),choquet integral powerful aggregation operator which lists many wellknown models its special cases we look these special cases provide their axiomatic analysis cases where axiomatization has been previously given literature we connect existing results framework we have developed next we turn question learning which especially important practical applications model so far learning choquet integral has been mostly confined learning capacity such approach requires making powerful assumption all dimensions eg criteria are evaluated same scale which rarely justified practice too often categorical data given arbitrary numerical labels eg ahp numerical data considered cardinally ordinally commensurate sometimes after simple normalization such approaches clearly lack scientific rigour yet they are commonly seen all kinds applications we discuss pros cons making such assumption look consequences which axiomatization uniqueness results have learning problems finally we review some applications choquet integral decision analysis apart mcda which main area interest our results we also discuss how model can be interpreted social choice context we look detail statedependent utility show how comonotonicity central previous axiomatizations actually implies stateindependency choquet integral model we also discuss conditions required have meaningful statedependent utility representation show novelty our results compared previous methods building statedependent models
Choquet integral in decision analysis - lessons from the axiomatization,Economics (Quantitative Finance),choquet integral powerful aggregation operator which lists many wellknown models its special cases we look these special cases provide their axiomatic analysis cases where axiomatization has been previously given literature we connect existing results framework we have developed next we turn question learning which especially important practical applications model so far learning choquet integral has been mostly confined learning capacity such approach requires making powerful assumption all dimensions eg criteria are evaluated same scale which rarely justified practice too often categorical data given arbitrary numerical labels eg ahp numerical data considered cardinally ordinally commensurate sometimes after simple normalization such approaches clearly lack scientific rigour yet they are commonly seen all kinds applications we discuss pros cons making such assumption look consequences which axiomatization uniqueness results have learning problems finally we review some applications choquet integral decision analysis apart mcda which main area interest our results we also discuss how model can be interpreted social choice context we look detail statedependent utility show how comonotonicity central previous axiomatizations actually implies stateindependency choquet integral model we also discuss conditions required have meaningful statedependent utility representation show novelty our results compared previous methods building statedependent models
In-memory factorization of holographic perceptual representations,Emerging Technologies,disentanglement constituent factors sensory signal central perception cognition hence critical task future artificial intelligence systems paper we present compute engine capable efficiently factorizing holographic perceptual representations exploiting computationinsuperposition capability braininspired hyperdimensional computing intrinsic stochasticity associated analog inmemory computing based nanoscale memristive devices such iterative inmemory factorizer shown solve least five orders magnitude larger problems cannot be solved otherwise while also significantly lowering computational time space complexity we present largescale experimental demonstration factorizer employing two inmemory compute chips based phasechange memristive devices dominant matrixvector multiply operations are executed thus reducing computational time complexity merely number iterations moreover we experimentally demonstrate ability factorize visual perceptual representations reliably efficiently
Quantum materials for energy-efficient neuromorphic computing,Emerging Technologies,neuromorphic computing approaches become increasingly important we address future needs efficiently processing massive amounts data unique attributes quantum materials can help address these needs enabling new energyefficient device concepts implement neuromorphic ideas hardware level particular strong correlations give rise highly nonlinear responses such conductive phase transitions can be harnessed short longterm plasticity similarly magnetization dynamics are strongly nonlinear can be utilized data classification paper discusses select examples these approaches provides perspective current opportunities challenges assembling quantummaterialbased devices neuromorphic functionalities into larger emergent complex network systems
Unsupervised Learning in Neuromemristive Systems,Emerging Technologies,neuromemristive systems nmss currently represent most promising platform achieve energy efficient neuroinspired computation however since research field less than decade old there are still countless algorithms design paradigms be explored within these systems one particular domain remains be fully investigated within nmss unsupervised learning work we explore design nms unsupervised clustering which critical element several machine learning algorithms using simple memristor crossbar architecture learning rule we are able achieve performance which par matlabs kmeans clustering
"Impact of Free-carrier Nonlinearities on Silicon Microring-based
  Reservoir Computing",Emerging Technologies,we quantify impact thermooptic freecarrier effects timedelay reservoir computing using silicon microring resonator we identify pump power frequency detuning ranges nmse less than narma task depending time constants two considered effects
Neuron inspired data encoding memristive multi-level memory cell,Emerging Technologies,mapping neuroinspired algorithms sensor backplanes onchip hardware require shifting signal processing digital analog domain demanding memory technologies beyond conventional cmos binary storage units using memristors building analog data storage one promising approaches amongst emerging nonvolatile memory technologies recently memristive multilevel memory mlm cell storing discrete analog values has been developed which memory system implemented combining memristors voltage divider configuration given example memory cell subcells memristor each was programmed store ternary bits which overall achieved discrete voltage levels however further use proposed memory cell analog signal processing circuits data encoder required generate control voltages programming memristors store discrete analog values paper we present design performance analysis data encoder generates write pattern signals level memristive memory
"AppStreamer: Reducing Storage Requirements of Mobile Games through
  Predictive Streaming",Operating Systems,storage has become constrained resource smartphones gaming popular activity mobile devices explosive growth number games coupled their growing size contributes storage crunch even where storage plentiful it takes long time download install heavy app before it can be launched paper presents appstreamer novel technique reducing storage requirements startup delay mobile games heavy mobile apps general appstreamer based intuition most apps do not need entirety its files images audio video clips etc any one time appstreamer can therefore keep only small part files device akin cache download remainder cloud storage server nearby edge server when it predicts app will need them near future appstreamer continuously predicts file blocks near future user uses app fetches them storage server before user sees stall due missing resources we implement appstreamer android file system layer ensures apps require no source code modification approach generalizes across apps we evaluate appstreamer using two popular games dead effect firstperson shooter fire emblem heroes turnbased strategy roleplaying game through user study users respectively find appstreamer provides same quality user experience baseline where all files are stored device appstreamer cuts down storage requirement dead effect fire emblem heroes
"Design and Implementation of Modified Fuzzy based CPU Scheduling
  Algorithm",Operating Systems,cpu scheduling base multiprogramming scheduling process which decides order task set multiple tasks are ready execute there are number cpu scheduling algorithms available but it very difficult task decide which one better paper discusses design implementation modified fuzzy based cpu scheduling algorithm paper present new set fuzzy rules it demonstrates scheduling done new priority improves average waiting time average turnaround time
"AppStreamer: Reducing Storage Requirements of Mobile Games through
  Predictive Streaming",Operating Systems,storage has become constrained resource smartphones gaming popular activity mobile devices explosive growth number games coupled their growing size contributes storage crunch even where storage plentiful it takes long time download install heavy app before it can be launched paper presents appstreamer novel technique reducing storage requirements startup delay mobile games heavy mobile apps general appstreamer based intuition most apps do not need entirety its files images audio video clips etc any one time appstreamer can therefore keep only small part files device akin cache download remainder cloud storage server nearby edge server when it predicts app will need them near future appstreamer continuously predicts file blocks near future user uses app fetches them storage server before user sees stall due missing resources we implement appstreamer android file system layer ensures apps require no source code modification approach generalizes across apps we evaluate appstreamer using two popular games dead effect firstperson shooter fire emblem heroes turnbased strategy roleplaying game through user study users respectively find appstreamer provides same quality user experience baseline where all files are stored device appstreamer cuts down storage requirement dead effect fire emblem heroes
"AppStreamer: Reducing Storage Requirements of Mobile Games through
  Predictive Streaming",Operating Systems,storage has become constrained resource smartphones gaming popular activity mobile devices explosive growth number games coupled their growing size contributes storage crunch even where storage plentiful it takes long time download install heavy app before it can be launched paper presents appstreamer novel technique reducing storage requirements startup delay mobile games heavy mobile apps general appstreamer based intuition most apps do not need entirety its files images audio video clips etc any one time appstreamer can therefore keep only small part files device akin cache download remainder cloud storage server nearby edge server when it predicts app will need them near future appstreamer continuously predicts file blocks near future user uses app fetches them storage server before user sees stall due missing resources we implement appstreamer android file system layer ensures apps require no source code modification approach generalizes across apps we evaluate appstreamer using two popular games dead effect firstperson shooter fire emblem heroes turnbased strategy roleplaying game through user study users respectively find appstreamer provides same quality user experience baseline where all files are stored device appstreamer cuts down storage requirement dead effect fire emblem heroes
"Design and Implementation of Modified Fuzzy based CPU Scheduling
  Algorithm",Operating Systems,cpu scheduling base multiprogramming scheduling process which decides order task set multiple tasks are ready execute there are number cpu scheduling algorithms available but it very difficult task decide which one better paper discusses design implementation modified fuzzy based cpu scheduling algorithm paper present new set fuzzy rules it demonstrates scheduling done new priority improves average waiting time average turnaround time
"Uncertainty-aware performance assessment of optical imaging modalities
  with invertible neural networks",Medical Physics,purpose optical imaging evolving key technique advanced sensing operating room recent research has shown machine learning algorithms can be used address inverse problem converting pixelwise multispectral reflectance measurements underlying tissue parameters such oxygenation assessment specific hardware used conjunction such algorithms however has not properly addressed possibility problem may be illposed methods we present novel approach assessment optical imaging modalities which sensitive different types uncertainties may occur when inferring tissue parameters based concept invertible neural networks our framework goes beyond point estimates maps each multispectral measurement full posterior probability distribution which capable representing ambiguity solution via multiple modes performance metrics hardware setup can then be computed characteristics posteriors results application assessment framework specific use case camera selection physiological parameter estimation yields following insights estimation tissue oxygenation multispectral images wellposed problem while blood volume fraction may not be recovered without ambiguity general ambiguity may be reduced increasing number spectral bands camera conclusion our method could help optimize optical camera design applicationspecific manner
Machine Learning in Magnetic Resonance Imaging: Image Reconstruction,Medical Physics,magnetic resonance imaging mri plays vital role diagnosis management monitoring many diseases however it inherently slow imaging technique over last years parallel imaging temporal encoding compressed sensing have enabled substantial speedups acquisition mri data accurately recovering missing lines kspace data however clinical uptake vastly accelerated acquisitions has been limited particular compressed sensing due timeconsuming nature reconstructions unnatural looking images following success machine learning wide range imaging tasks there has been recent explosion use machine learning field mri image reconstruction wide range approaches have been proposed which can be applied kspace andor imagespace promising results have been demonstrated range methods enabling natural looking images rapid computation review article we summarize current machine learning approaches used mri reconstruction discuss their drawbacks clinical applications current trends
"A Surface-Based Federated Chow Test Model for Integrating APOE Status,
  Tau Deposition Measure, and Hippocampal Surface Morphometry",Medical Physics,background alzheimers disease ad most common type agerelated dementia affecting million people aged older according cdc data it commonly agreed discovering effective ad diagnosis biomarker could have enormous public health benefits potentially preventing delaying up dementia cases tau neurofibrillary tangles are primary driver downstream neurodegeneration subsequent cognitive impairment ad resulting structural deformations such hippocampal atrophy can be observed magnetic resonance imaging mri scans objective build surfacebased model detect differences between apoe subgroups patterns tau deposition hippocampal atrophy use extracted surfacebased features predict cognitive decline methods using data obtained different institutions we develop surfacebased federated chow test model study synergistic effects apoe previously reported significant risk factor ad tau hippocampal surface morphometry results we illustrate apoespecific morphometry features correlate ad progression better predict future ad conversion than other mri biomarkers example strong association between atrophy abnormal tau was identified hippocampal subregion cornu ammonis ca subfield subiculum homozygote cohort conclusion our model allows identifying mri biomarkers ad cognitive decline prediction may uncover corner neural mechanism influence apoe tau deposition hippocampal morphology
"Probabilistic feature extraction, dose statistic prediction and dose
  mimicking for automated radiation therapy treatment planning",Medical Physics,purpose we propose general framework quantifying predictive uncertainties doserelated quantities leveraging information dose mimicking problem context automated radiation therapy treatment planning methods threestep pipeline comprising feature extraction dose statistic prediction dose mimicking employed particular features are produced convolutional variational autoencoder used inputs previously developed nonparametric bayesian statistical method estimating multivariate predictive distribution collection predefined dose statistics specially developed objective functions are then used construct probabilistic dose mimicking problem based produced distributions creating deliverable treatment plans results numerical experiments are performed using dataset retrospective treatment plans prostate cancer patients we show features extracted variational autoencoder capture geometric information substantial relevance dose statistic prediction problem are related dose statistics more regularized fashion than handcrafted features estimated predictive distributions are reasonable outperforms noninputdependent benchmark method deliverable plans produced probabilistic dose mimicking agree better their clinical counterparts than nonprobabilistic formulation conclusions we demonstrate prediction doserelated quantities may be extended include uncertainty estimation such probabilistic information may be leveraged dose mimicking problem treatment plans produced proposed pipeline resemble their original counterparts well illustrating merits holistic approach automated planning based probabilistic modeling
"Fast, Precise Myelin Water Quantification using DESS MRI and Kernel
  Learning",Medical Physics,purpose investigate feasibility myelin water content quantification using fast dualecho steadystate dess scans machine learning kernels methods we optimized combinations steadystate ss scans precisely estimating fastrelaxing signal fraction ff twocompartment signal model subject scan time constraint we estimated ff optimized dess acquisition using recently developed method rapid parameter estimation via regression kernels perk we compared dess perk ff estimates conventional myelin water fraction mwf estimates longer multiecho spinecho mese acquisition simulation vivo ex vivo studies results simulations demonstrate dess perk ff estimators mese mwf estimators achieve comparable error levels vivo ex vivo experiments demonstrate mese mwf dess perk ff estimates are quantitatively comparable measures wm myelin water content our knowledge these experiments are first demonstrate myelin water images ss acquisition are quantitatively similar conventional mese mwf images conclusion combinations fast dess scans can be designed enable precise ff estimation perk wellsuited ff estimation dess perk ff mese mwf estimates are quantitatively similar measures wm myelin water content
Improving Limited Angle CT Reconstruction with a Robust GAN Prior,Image and Video Processing,limited angle ct reconstruction underdetermined linear inverse problem requires appropriate regularization techniques be solved work we study how pretrained generative adversarial networks gans can be used clean noisy highly artifact laden reconstructions conventional techniques effectively projecting onto inferred image manifold particular we use robust version popularly used gan prior inverse problems based recent technique called corruption mimicking significantly improves reconstruction quality proposed approach operates image space directly result which it does not need be trained require access measurement model scanner agnostic can work over wide range sensing scenarios
"Application of Structural Similarity Analysis of Visually Salient Areas
  and Hierarchical Clustering in the Screening of Similar Wireless Capsule
  Endoscopic Images",Image and Video Processing,small intestinal capsule endoscopy mainstream method inspecting small intestinal lesionsbut single small intestinal capsule endoscopy will produce images majority which are similar have no diagnostic value it takes hours doctors identify lesions these images timeconsuming increase probability misdiagnosis missed diagnosis since doctors are likely experience visual fatigue while focusing large number similar images extended period timein order solve these problems we proposed similar wireless capsule endoscope wce image screening method based structural similarity analysis hierarchical clustering visually salient subimage blocks similarity clustering images was automatically identified hierarchical clustering based huesaturationvalue hsv spatial color characteristics imagesand keyframe images were extracted based structural similarity visually salient subimage blocks order accurately identify screen out similar small intestinal capsule endoscopic images subsequently proposed method was applied capsule endoscope imaging workstation after screening out similar images complete data gathered type omom small intestinal capsule endoscope cases covering common types small intestinal lesions we obtained lesion recall average similar image reduction ratio similar images screened out average play time omom image workstation was minutes which greatly reduced time spent doctors viewing images
Unsupervised Anomaly Detection for X-Ray Images,Image and Video Processing,obtaining labels medical image data requires scarce expensive experts moreover due ambiguous symptoms single images rarely suffice correctly diagnose medical condition instead it often requires take additional background information such patients medical history test results into account hence instead focusing uninterpretable blackbox systems delivering uncertain final diagnosis endtoendfashion we investigate how unsupervised methods trained images without anomalies can be used assist doctors evaluating xray images hands our method increases efficiency making diagnosis reduces risk missing important regions therefore we adopt stateoftheart approaches unsupervised learning detect anomalies show how outputs these methods can be explained reduce effect noise which often can be mistaken anomaly we introduce powerful preprocessing pipeline we provide extensive evaluation different approaches demonstrate empirically even without labels it possible achieve satisfying results realworld dataset xray images hands we also evaluate importance preprocessing one our main findings without it most our approaches perform not better than random foster reproducibility accelerate research we make our code publicly available httpsgithubcomvalentynxray
Lightening Anything in Medical Images,Image and Video Processing,development medical imaging techniques has made significant contribution clinical decisionmaking however existence suboptimal imaging quality indicated irregular illumination imbalanced intensity presents significant obstacles automating disease screening analysis diagnosis existing approaches natural image enhancement are mostly trained numerous paired images presenting challenges data collection training costs all while lacking ability generalize effectively here we introduce pioneering trainingfree diffusion model universal medical image enhancement named unimie unimie demonstrates its unsupervised enhancement capabilities across various medical image modalities without need any finetuning it accomplishes relying solely single pretrained model imagenet we conduct comprehensive evaluation imaging modalities over medical types demonstrating better qualities robustness accuracy than other modalityspecific datainefficient models delivering highquality enhancement corresponding accuracy downstream tasks across wide range tasks unimie exhibits considerable potential accelerate advancement diagnostic tools customized treatment plans
Brain MRI Tumor Segmentation with Adversarial Networks,Image and Video Processing,deep learning promising approach either automate simplify several tasks healthcare domain work we introduce segancat approach brain tumor segmentation magnetic resonance images mri based adversarial networks particular we extend segan successfully applied same task previous work two respects we used different model input ii we employed modified loss function train model we tested our approach two large datasets made available brain tumor image segmentation benchmark brats first we trained tested some segmentation models assuming availability all major mri contrast modalities ie tweighted weighted contrastenhanced tweighted tflair however these four modalities are not always all available each patient we also trained tested four segmentation models take input mris acquired only single contrast modality finally we proposed apply transfer learning across different contrast modalities improve performance these singlemodality models our results are promising show not segancat able outperform segan when all four modalities are available but also transfer learning can actually lead better performances when only single modality available
"CNN-MoE based framework for classification of respiratory anomalies and
  lung disease detection",Audio and Speech Processing,paper presents explores robust deep learning framework auscultation analysis aims classify anomalies respiratory cycles detect disease respiratory sound recordings framework begins frontend feature extraction transforms input sound into spectrogram representation then backend deep learning network used classify spectrogram features into categories respiratory anomaly cycles diseases experiments conducted over icbhi benchmark dataset respiratory sounds confirm three main contributions towards respiratorysound analysis firstly we carry out extensive exploration effect spectrogram type spectraltime resolution overlappednonoverlapped windows data augmentation final prediction accuracy leads us propose novel deep learning system built proposed framework which outperforms current stateoftheart methods finally we apply teacherstudent scheme achieve tradeoff between model performance model complexity which additionally helps increase potential proposed framework building realtime applications
"Guided Generative Adversarial Neural Network for Representation Learning
  and High Fidelity Audio Generation using Fewer Labelled Audio Data",Audio and Speech Processing,recent improvements generative adversarial neural networks gans have shown their ability generate higher quality samples well learn good representations transfer learning most representation learning methods based gans learn representations ignoring their postuse scenario which can lead increased generalisation ability however model can become redundant if it intended specific task example assume we have vast unlabelled audio dataset we want learn representation dataset so it can be used improve emotion recognition performance small labelled audio dataset during representation learning training if model does not know post emotion recognition task it can completely ignore emotionrelated characteristics learnt representation fundamental challenge any unsupervised representation learning model paper we aim address challenge proposing novel gan framework guided generative neural network ggan which guides gan focus learning desired representations generating superior quality samples audio data leveraging fewer labelled samples experimental results show using very small amount labelled data guidance ggan learns significantly better representations
A Demand-Driven Perspective on Generative Audio AI,Audio and Speech Processing,achieve successful deployment ai research it crucial understand demands industry paper we present results survey conducted professional audio engineers order determine research priorities define various research tasks we also summarize current challenges audio quality controllability based survey our analysis emphasizes availability datasets currently main bottleneck achieving highquality audio generation finally we suggest potential solutions some revealed issues empirical evidence
"Alzheimer's Dementia Recognition through Spontaneous Speech: The ADReSS
  Challenge",Audio and Speech Processing,adress challenge interspeech defines shared task through which different approaches automated recognition alzheimers dementia based spontaneous speech can be compared adress provides researchers benchmark speech dataset which has been acoustically preprocessed balanced terms age gender defining two cognitive assessment tasks namely alzheimers speech classification task neuropsychological score regression task alzheimers speech classification task adress challenge participants create models classifying speech dementia healthy control speech neuropsychological score regression task participants create models predict minimental state examination scores paper describes adress challenge detail presents baseline both tasks including feature extraction procedures results classification regression models adress aims provide speech language alzheimers research community platform comprehensive methodological comparisons will hopefully contribute addressing lack standardisation currently affects field shed light avenues future research clinical applicability
"Focal Loss based Residual Convolutional Neural Network for Speech
  Emotion Recognition",Audio and Speech Processing,paper proposes residual convolutional neural network resnet based speech features trained under focal loss recognize emotion speech speech features such spectrogram melfrequency cepstral coefficients mfccs have shown ability characterize emotion better than just plain text further focal loss first used onestage object detectors has shown ability focus training process more towards hardexamples downweight loss assigned wellclassified examples thus preventing model being overwhelmed easily classifiable examples
Limiting fitness distributions in evolutionary dynamics,Populations and Evolution,darwinian evolution can be modeled general terms flow space fitness ie reproductive rate distributions diffusion approximation tsimring et al have showed flow admits fitness wave solutions gaussianshape fitness distributions moving towards higher fitness values constant speed here we show more generally evolving fitness distributions are attracted oneparameter family distributions fixed parabolic relationship between skewness kurtosis unlike fitness waves statistical pattern encompasses both positive negative aka purifying selection not restricted rapidly adapting populations moreover we find mean fitness population under selection preexisting variation powerlaw function time observed microbiological evolution experiments but variance fitness wave theory conceptual level our results can be viewed resolution dynamic insufficiency fishers fundamental theorem natural selection our predictions are good agreement numerical simulations
Methods to Estimate Cryptic Sequence Complexity,Populations and Evolution,complexity signature quality interest artificial life systems alongside other dimensions assessment it common quantify genome sites contribute fitness complexity measure however limitations sensitivity fitness assays models implicit replication criteria involving rich biotic interactions introduce possibility difficulttodetect cryptic adaptive sites which contribute small fitness effects below threshold individual detectability involve epistatic redundancies here we propose three knockoutbased assay procedures designed quantify cryptic adaptive sites within digital genomes we report initial tests these methods simple genome model explicitly configured site fitness effects these limited tests estimation results reflect ground truth cryptic sequence complexities well presented work provides initial steps toward development new methods software tools improve resolution rigor tractability complexity analyses across alife systems particularly those requiring expensive situ assessments organism fitness
"Analysis of the COVID-19 pandemic by SIR model and machine learning
  technics for forecasting",Populations and Evolution,work trial which we propose sir model machine learning tools analyze coronavirus pandemic real world based public data citedatahub we estimate main key pandemic parameters make predictions inflection point possible ending time real world specifically senegal coronavirus disease world health organization rapidly spread out whole china then whole world under optimistic estimation pandemic some countries will end soon while most part countries world us italy etc hit antipandemic will be no later than end april
"A Modified PINN Approach for Identifiable Compartmental Models in
  Epidemiology with Applications to COVID-19",Populations and Evolution,variety approaches using compartmental models have been used study covid pandemic usage machine learning methods these models has had particularly notable success we present here approach toward analyzing accessible data covids us development using variation physics informed neural networks pinn which capable using knowledge model aid learning we illustrate challenges using standard pinn approach then how appropriate novel modifications loss function network can perform well even our case incomplete information aspects identifiability model parameters are also assessed well methods denoising available data using wavelet transform finally we discuss capability neural network methodology work models varying parameter values well concrete application estimating how effectively cases are being tested population providing ranking us states means their respective testing
Non-bifurcating phylogenetic tree inference via the adaptive LASSO,Populations and Evolution,phylogenetic tree inference using deep dna sequencing reshaping our understanding rapidly evolving systems such withinhost battle between viruses immune system densely sampled phylogenetic trees can contain special features including sampled ancestors which we sequence genotype along its direct descendants polytomies which multiple descendants arise simultaneously these features are apparent after identifying zerolength branches tree however current maximumlikelihood based approaches are not capable revealing such zerolength branches paper we find these zerolength branches introducing adaptivelassotype regularization estimators phylogenetics deriving their properties showing regularization be practically useful approach phylogenetics
"Leave-one-out least squares Monte Carlo algorithm for pricing Bermudan
  options",Computational Finance,least squares monte carlo lsm algorithm proposed longstaff schwartz widely used pricing bermudan options lsm estimator contains undesirable lookahead bias conventional technique avoiding it requires additional simulation paths we present leaveoneout lsm loolsm algorithm eliminate lookahead bias without doubling simulations we also show lookahead bias asymptotically proportional regressorstopaths ratio our findings are demonstrated several option examples which lsm algorithm overvalues options loolsm method can be extended other regressionbased algorithms improve lsm method
"mlOSP: Towards a Unified Implementation of Regression Monte Carlo
  Algorithms",Computational Finance,we introduce mlosp computational template machine learning optimal stopping problems template implemented statistical environment publicly available via github repository mlosp presents unified numerical implementation regression monte carlo rmc approaches optimal stopping providing stateoftheart opensource reproducible transparent platform highlighting its modular nature we present multiple novel variants rmc algorithms especially terms constructing simulation designs training regressors well terms machine learning regression modules furthermore mlosp nests most existing rmc schemes allowing consistent verifiable benchmarking extant algorithms article contains extensive code snippets figures serves vignette underlying software package
"SuperDeConFuse: A Supervised Deep Convolutional Transform based Fusion
  Framework for Financial Trading Systems",Computational Finance,work proposes supervised multichannel timeseries learning framework financial stock trading although many deep learning models have recently been proposed domain most them treat stock trading timeseries data image data whereas its true nature timeseries data since stock trading systems are multichannel data many existing techniques treating them timeseries data are not suggestive any technique effectively fusion information carried multiple channels contribute towards both these shortcomings we propose endtoend supervised learning framework inspired previously established unsupervised convolution transform learning framework our approach consists processing data channels through separate convolution layers then fusing outputs series fullyconnected layers finally applying softmax classification layer peculiarity our framework superdeconfuse sdcf we remove nonlinear activation located between multichannel convolution layers fullyconnected layers well one located between latter output layer we compensate removal introducing suitable regularization aforementioned layer outputs filters during training phase specifically we apply logarithm determinant regularization layer filters break symmetry force diversity learnt transforms whereas we enforce nonnegativity constraint layer outputs mitigate issue dead neurons results effective learning richer set features filters respect standard convolutional neural network numerical experiments confirm proposed model yields considerably better results than stateoftheart deep learning techniques realworld problem stock trading
Statistical Learning of Value-at-Risk and Expected Shortfall,Computational Finance,we propose nonasymptotic convergence analysis twostep approach learn conditional valueatrisk var conditional expected shortfall es using rademacher bounds nonparametric setup allowing heavytails financial loss our approach var extended problem learning once multiple vars corresponding different quantile levels results efficient learning schemes based neural network quantile leastsquares regressions posteriori monte carlo procedure introduced estimate distances groundtruth var es illustrated numerical experiments studentt toy model financial case study where objective learn dynamic initial margin
Extensions of the Deep Galerkin Method,Computational Finance,we extend deep galerkin method dgm introduced sirignano spiliopoulos solve number partial differential equations pdes arise context optimal stochastic control mean field games first we consider pdes where function constrained be positive integrate unity case fokkerplanck equations our approach involves reparameterizing solution exponential neural network appropriately normalized ensure both requirements are satisfied then gives rise nonlinear partial integrodifferential equation pide where integral appearing equation handled novel application importance sampling secondly we tackle number hamiltonjacobibellman hjb equations appear stochastic optimal control problems key contribution these equations are approached their unsimplified primal form which includes optimization problem part equation we extend dgm algorithm solve value function optimal control simultaneously characterizing both deep neural networks training networks performed taking alternating stochastic gradient descent steps two functions technique inspired policy improvement algorithms pia
"Analog ensemble data assimilation and a method for constructing analogs
  with variational autoencoders",Computational Physics,it proposed use analogs forecast mean generate ensemble perturbations use ensemble optimal interpolation enoi ensemble variational envar methods new method constructing analogs using variational autoencoders vaes machine learning method proposed resulting analog methods using analogs catalog anenoi using constructed analogs canenoi are tested context multiscale lorenz model standard enoi ensemble square root filter comparison use analogs modestlysized catalog shown improve performance enoi limited marginal improvements resulting increases catalog size method using constructed analogs canenoi found perform well full ensemble square root filter be robust over wide range tuning parameters
"Autonomous Materials Discovery Driven by Gaussian Process Regression
  with Inhomogeneous Measurement Noise and Anisotropic Kernels",Computational Physics,majority experimental disciplines face challenge exploring large highdimensional parameter spaces search new scientific discoveries materials science no exception wide variety synthesis processing environmental conditions influence material properties gives rise particularly vast parameter spaces recent advances have led increase efficiency materials discovery increasingly automating exploration processes methods autonomous experimentation have become more sophisticated recently allowing multidimensional parameter spaces be explored efficiently minimal human intervention thereby liberating scientists focus interpretations bigpicture decisions gaussian process regression gpr techniques have emerged method choice steering many classes experiments we have recently demonstrated positive impact gprdriven decisionmaking algorithms autonomously steering experiments synchrotron beamline however due complexity experiments gpr often cannot be used its most basic form but rather has be tuned account special requirements experiments two requirements seem be particular importance namely inhomogeneous measurement noise input dependent noniid anisotropic kernel functions which are two concepts we tackle paper our synthetic experimental tests demonstrate importance both concepts experiments materials science benefits result including them autonomous decisionmaking process
Reducing hyperparameter dependence by external timescale tailoring,Computational Physics,task specific hyperparameter tuning reservoir computing open issue particular relevance hardware implemented reservoirs we investigate influence directly including externally controllable task specific timescales performance hyperparameter sensitivity reservoir computing approaches we show need hyperparameter optimisation can be reduced if timescales reservoir are tailored specific task our results are mainly relevant temporal tasks requiring memory past inputs example chaotic timeseries prediciton we consider various methods including task specific timescales reservoir computing approach demonstrate universality our message looking both timemultiplexed spatially multiplexed reservoir computing
"Integration of adversarial autoencoders with residual dense
  convolutional networks for estimation of non-Gaussian hydraulic
  conductivities",Computational Physics,inverse modeling estimation nongaussian hydraulic conductivity fields subsurface flow solute transport models remains challenging problem mainly due nongaussian property nonlinear physics fact many repeated evaluations forward model are often required study we develop convolutional adversarial autoencoder caae parameterize nongaussian conductivity fields heterogeneous conductivity within each facies using lowdimensional latent representation addition deep residual dense convolutional network drdcn proposed surrogate modeling forward models highdimensional highlycomplex mappings two networks are both based multilevel residual learning architecture called residualinresidual dense block multilevel residual learning strategy dense connection structure ease training deep networks enabling us efficiently build deeper networks have essentially increased capacity approximating mappings very highcomplexity ccae drdcn networks are incorporated into iterative ensemble smoother formulate inversion framework numerical experiments performed using solute transport models illustrate performance integrated method obtained results indicate caae robust parameterization method nongaussian conductivity fields different heterogeneity patterns drdcn able obtain accurate approximations forward models highdimensional highlycomplex mappings using relatively limited training data caae drdcn methods together significantly reduce computation time required achieve accurate inversion results
"A deep neural network for molecular wave functions in quasi-atomic
  minimal basis representation",Computational Physics,emergence machine learning methods quantum chemistry provides new methods revisit old problem can predictive accuracy electronic structure calculations be decoupled their numerical bottlenecks previous attempts answer question have among other methods given rise semiempirical quantum chemistry minimal basis representation we present adaptation recently proposed schnet orbitals schnorb deep convolutional neural network model nature commun electronic wave functions optimised quasiatomic minimal basis representation five organic molecules ranging heavy atoms model accurately predicts molecular orbital energies wavefunctions provides access derived properties chemical bonding analysis particularly larger molecules model outperforms original atomicorbitalbased schnorb method terms accuracy scaling we conclude discussing future potential approach quantum chemical workflows
Implementation of Lenia as a Reaction-Diffusion System,Cellular Automata and Lattice Gases,relationship between reactiondiffusion rd systems characterized continuous spatiotemporal states cellular automata ca marked discrete spatiotemporal states remains poorly understood paper delves into relationship through examination recently developed ca known lenia we demonstrate asymptotic lenia variant lenia can be comprehensively described differential equations unlike original lenia it independent timestep ticks further we establish formulation mathematically equivalent generalization kernelbased turing model kt model stemming these insights we establish asymptotic lenia can be replicated rd system composed solely diffusion spatially local reaction terms resulting simulated asymptotic lenia based rd system rd lenia however our rd lenia cannot be construed chemical system since reaction term fails satisfy massaction kinetics
Evolution of Spots and Stripes in Cellular Automata,Cellular Automata and Lattice Gases,cellular automata are computers similar turing machines main difference turing machines use onedimensional tape whereas cellular automata use twodimensional grid bestknown cellular automaton game life which universal computer it belongs family cellular automata members playing game life generally involves engineering assembling device composed various parts are combined achieve specific intended result instead engineering cellular automata we propose evolving cellular automata evolution applies mutation selection population organisms if mutation increases fitness organism it may have many descendants displacing less fit organisms unlike engineering evolution does not work towards imagined goal evolution works towards increasing fitness no expectations about specific form final result mutation selection fitness yield structures appear be more organic lifelike than engineered structures our experiments patterns resulting evolving cellular automata look much like spots leopards stripes tigers
Lenia - Biology of Artificial Life,Cellular Automata and Lattice Gases,we report new system artificial life called lenia latin lenis smooth twodimensional cellular automaton continuous spacetimestate generalized local rule computer simulations show lenia supports great diversity complex autonomous patterns lifeforms bearing resemblance realworld microscopic organisms more than species families have been identified many discovered via interactive evolutionary computation they differ other cellular automata patterns being geometric metameric fuzzy resilient adaptive rulegeneric we present basic observations system regarding properties spacetime basic settings we provide broad survey lifeforms categorize them into hierarchical taxonomy map their distribution parameter hyperspace we describe their morphological structures behavioral dynamics propose possible mechanisms their selfpropulsion selforganization plasticity finally we discuss how study lenia would be related biology artificial life artificial intelligence
Implementation of Lenia as a Reaction-Diffusion System,Cellular Automata and Lattice Gases,relationship between reactiondiffusion rd systems characterized continuous spatiotemporal states cellular automata ca marked discrete spatiotemporal states remains poorly understood paper delves into relationship through examination recently developed ca known lenia we demonstrate asymptotic lenia variant lenia can be comprehensively described differential equations unlike original lenia it independent timestep ticks further we establish formulation mathematically equivalent generalization kernelbased turing model kt model stemming these insights we establish asymptotic lenia can be replicated rd system composed solely diffusion spatially local reaction terms resulting simulated asymptotic lenia based rd system rd lenia however our rd lenia cannot be construed chemical system since reaction term fails satisfy massaction kinetics
The conduciveness of CA-rule graphs,Cellular Automata and Lattice Gases,given two subsets nodes directed graph conduciveness graph ratio representing how many edges outgoing nodes are incoming nodes when graphs nodes stand possible solutions certain problems combinatorial optimization choosing its edges appropriately has been shown lead conduciveness properties provide useful insight into performance algorithms solve those problems here we study conduciveness carule graphs graphs whose node set set all ca rules given cells number possible states neighborhood size we consider several different edge sets interconnecting these nodes both deterministic random ones derive analytical expressions resulting graphs conduciveness toward rules having fixed number nonquiescent entries we demonstrate one random edge sets characterized allowing nodes be sparsely interconnected across any hamming distance between corresponding rules has potential providing reasonable conduciveness toward desired rules we conjecture may lie bottom best strategies known date discovering complex rules solve specific problems all evolutionary nature
"Equivariant geometric learning for digital rock physics: estimating
  formation factor and effective permeability tensors from Morse graph",Geophysics,we present seequivariant graph neural network gnn approach directly predicting formation factor effective permeability microct images fft solvers are established compute both formation factor effective permeability while topology geometry pore space are represented persistencebased morse graph together they constitute database training validating testing neural networks while graph euclidean convolutional approaches both employ neural networks generate lowdimensional latent space represent features microstructures forward predictions se equivariant neural network found generate more accurate predictions especially when training data limited numerical experiments have also shown new se approach leads predictions fulfill material frame indifference whereas predictions classical convolutional neural networks cnn may suffer spurious dependence coordinate system training data comparisons among predictions inferred training cnn those graph convolutional neural networks gnn without equivariant constraint indicate equivariant graph neural network seems perform better than cnn gnn without enforcing equivariant constraints
"Machine learning for graph-based representations of three-dimensional
  discrete fracture networks",Geophysics,structural topological information play key role modeling flow transport through fractured rock subsurface discrete fracture network dfn computational suites such dfnworks are designed simulate flow transport such porous media flow transport calculations reveal small backbone fractures exists where most flow transport occurs restricting flowing fracture network backbone provides significant reduction networks effective size however particle tracking simulations needed determine reduction are computationally intensive such methods may be impractical large systems robust uncertainty quantification fracture networks where thousands forward simulations are needed bound system behavior paper we develop alternative network reduction approach characterizing transport dfns combining graph theoretical machine learning methods we consider graph representation where nodes signify fractures edges denote their intersections using random forest support vector machines we rapidly identify subnetwork captures flow patterns full dfn based primarily node centrality features graph our supervised learning techniques train particletracking backbone paths found dfnworks but run negligible time compared those simulations we find our predictions can reduce network approximately its original size while still generating breakthrough curves consistent those original network
Pi theorem formulation of flood mapping,Geophysics,rapid delineation flash flood extents critical mobilize emergency resources manage evacuations thereby saving lives property machine learning ml approaches enable rapid flood delineation reduced computational demand compared conventional highresolution flood models however existing ml approaches are limited lack generalization neverbeforeseen conditions here we propose framework improve ml model generalization based dimensionless multiscale features capture similarity flooding process across regions dimensionless features are constrained buckingham pi theorem used logistic regression model probabilistic determination flood risk features were calculated different scales varying accumulation thresholds stream delineation modeled flood maps compared well results hydraulic models are basis federal emergency management agency fema flood hazard maps dimensionless features outperformed dimensional features some largest gains auc occurring when model was trained one region tested another dimensionless multiscale features ml flood modeling have potential improve generalization enabling mapping unmapped areas across broader spectrum landscapes climates events
"Enhanced prediction accuracy with uncertainty quantification in
  monitoring CO2 sequestration using convolutional neural networks",Geophysics,monitoring changes inside reservoir real time crucial success co injection longterm storage machine learning ml wellsuited realtime co monitoring because its computational efficiency however most existing applications ml yield only one prediction ie expectation given input which may not properly reflect distribution testing data if it has shift respect training data simultaneous quantile regression sqr method can estimate entire conditional distribution target variable neural network via pinball loss here we incorporate technique into seismic inversion purposes co monitoring uncertainty map then calculated pixel pixel particular prediction interval around median we also propose novel dataaugmentation method sampling uncertainty further improve prediction accuracy developed methodology tested synthetic kimberlina data which are created department energy based co capture sequestration ccs project california results prove proposed network can estimate subsurface velocity rapidly sufficient resolution furthermore computed uncertainty quantifies prediction accuracy method remains robust even if testing data are distorted due problems field data acquisition another test demonstrates effectiveness developed dataaugmentation method increasing spatial resolution estimated velocity field reducing prediction error
"Predicting the Accuracy of Early-est Earthquake Magnitude Estimates with
  an LSTM Neural Network: A Preliminary Analysis",Geophysics,report presents preliminary analysis lstm neural network designed predict accuracy magnitude estimates computed earlyest during first minutes after earthquake occurs
"Signatures in Shape Analysis: an Efficient Approach to Motion
  Identification",Differential Geometry,signatures provide succinct description certain features paths reparametrization invariant way we propose method classifying shapes based signatures compare it current approaches based srv transform dynamic programming
"Convergence of Laplacian Eigenmaps and its Rate for Submanifolds with
  Singularities",Differential Geometry,paper we give spectral approximation result laplacian submanifolds euclidean spaces singularities epsilonneighborhood graph constructed random points submanifold our convergence rate eigenvalue laplacian oleftleftlog nnrightmright where denote dimension manifold sample size respectively
Ricci Curvature and the Manifold Learning Problem,Differential Geometry,consider sample points taken iid submanifold sigma euclidean space we show there way estimate ricci curvature sigma respect induced metric sample our method grounded notions carre du champ diffusion semigroups theory empirical processes local principal component analysis
"Signatures in Shape Analysis: an Efficient Approach to Motion
  Identification",Differential Geometry,signatures provide succinct description certain features paths reparametrization invariant way we propose method classifying shapes based signatures compare it current approaches based srv transform dynamic programming
"Approximate Joint Diagonalization and Geometric Mean of Symmetric
  Positive Definite Matrices",Differential Geometry,we explore connection between two problems have arisen independently signal processing related fields estimation geometric mean set symmetric positive definite spd matrices their approximate joint diagonalization ajd today there considerable interest estimating geometric mean spd matrix set manifold spd matrices endowed fisher information metric resulting mean has several important invariance properties has proven very useful diverse engineering applications such biomedical image data processing while two spd matrices mean has algebraic closed form solution set more than two spd matrices it can only be estimated iterative algorithms however none existing iterative algorithms feature same time fast convergence low computational complexity per iteration guarantee convergence reason recently other definitions geometric mean based symmetric divergence measures such bhattacharyya divergence have been considered resulting means although possibly useful practice do not satisfy all desirable invariance properties paper we consider geometric means covariance matrices estimated highdimensional timeseries assuming data generated according instantaneous mixing model which very common signal processing we show these circumstances we can approximate fisher information geometric mean employing efficient ajd algorithm our approximation general much closer fisher information geometric mean compared its competitors verifies many invariance properties furthermore convergence guaranteed computational complexity low convergence rate quadratic accuracy new geometric mean approximation demonstrated means simulations
"Machine-Learning Dessins d'Enfants: Explorations via Modular and
  Seiberg-Witten Curves",High Energy Physics - Theory,we apply machinelearning study dessins denfants specifically we investigate class dessins which reside intersection investigations modular subgroups seibergwitten curves extremal elliptic surfaces deep feedforward neural network simple structure standard activation functions without prior knowledge underlying mathematics established imposed onto classification extension degree over rationals known be difficult problem classifications reached accuracy standard error relatively quickly seibergwitten curves those rational coefficients are also tabulated
"Scale-invariant Feature Extraction of Neural Network and Renormalization
  Group Flow",High Energy Physics - Theory,theoretical understanding how deep neural network dnn extracts features input images still unclear but it widely believed extraction performed hierarchically through process coarsegraining it reminds us basic concept renormalization group rg statistical physics order explore possible relations between dnn rg we use restricted boltzmann machine rbm applied ising model construct flow model parameters particular temperature generated rbm we show unsupervised rbm trained spin configurations various temperatures generates flow along which temperature approaches critical value tc behavior opposite typical rg flow ising model analyzing various properties weight matrices trained rbm we discuss why it flows towards tc how rbm learns extract features spin configurations
"Quiver Mutations, Seiberg Duality and Machine Learning",High Energy Physics - Theory,we initiate study applications machine learning seiberg duality focusing case quiver gauge theories problem also interest mathematics context cluster algebras within general theme seiberg duality we define explore variety interesting questions broadly divided into binary determination whether pair theories picked series duality classes are dual each other well multiclass determination duality class which given theory belongs we study how performance machine learning depends several variables including number classes mutation type finite infinite addition we evaluate relative advantages naive bayes classifiers versus convolutional neural networks finally we also investigate how results are affected inclusion additional data such ranks gaugeflavor groups certain variables motivated existence underlying diophantine equations all questions considered high accuracy confidence can be achieved
"Machine-Learning Dessins d'Enfants: Explorations via Modular and
  Seiberg-Witten Curves",High Energy Physics - Theory,we apply machinelearning study dessins denfants specifically we investigate class dessins which reside intersection investigations modular subgroups seibergwitten curves extremal elliptic surfaces deep feedforward neural network simple structure standard activation functions without prior knowledge underlying mathematics established imposed onto classification extension degree over rationals known be difficult problem classifications reached accuracy standard error relatively quickly seibergwitten curves those rational coefficients are also tabulated
Deep-Learning the Landscape,High Energy Physics - Theory,we propose paradigm deeplearn everexpanding databases which have emerged mathematical physics particle phenomenology diverse statistics string vacua combinatorial algebraic geometry concrete examples we establish multilayer neural networks both classifiers predictors train them host available data ranging calabiyau manifolds vector bundles quiver representations gauge theories we find even relatively simple neural network can learn many significant quantities astounding accuracy matter minutes can also predict hithertofore unencountered results paradigm should prove valuable tool various investigations landscapes physics well pure mathematics
"A Second Order Cumulant Spectrum Test That a Stochastic Process is
  Strictly Stationary and a Step Toward a Test for Graph Signal Strict
  Stationarity",Statistical Finance,article develops statistical test null hypothesis strict stationarity discrete time stochastic process frequency domain when null hypothesis true second order cumulant spectrum zero all discrete fourier frequency pairs principal domain test uses window averaged sample estimate second order cumulant spectrum build test statistic asymptotic complex standard normal distribution we derive test statistic study properties test demonstrate its application using cs gamma ray decay data future areas research include testing strict stationarity graph signals applications learning convolutional neural networks graphs denoising inpainting
Machine Learning Algorithms for Financial Asset Price Forecasting,Statistical Finance,research paper explores performance machine learning ml algorithms techniques can be used financial asset price forecasting prediction forecasting asset prices returns remains one most challenging exciting problems quantitative finance practitioners alike massive increase data generated captured recent years presents opportunity leverage machine learning algorithms study directly compares contrasts stateoftheart implementations modern machine learning algorithms high performance computing hpc infrastructures versus traditional highly popular capital asset pricing model capm us equities data implemented machine learning models trained time series data entire stock universe addition exogenous macroeconomic variables significantly outperform capm outofsample oos test data
Data-driven Hedging of Stock Index Options via Deep Learning,Statistical Finance,we develop deep learning models learn hedge ratio sp index options directly options data we compare different combinations features show feedforward neural network model time maturity blackscholes delta sentiment variable vix calls index return puts input features performs best outofsample test model significantly outperforms standard hedging practice uses blackscholes delta recent datadriven model our results demonstrate importance market sentiment hedging efficiency factor previously ignored developing hedging strategies
Forecasting with Deep Learning: S&P 500 index,Statistical Finance,stock price prediction has been focus large amount research but acceptable solution has so far escaped academics recent advances deep learning have motivated researchers apply neural networks stock prediction paper we propose convolutionbased neural network model predicting future value sp index proposed model capable predicting nextday direction index based previous values index experiments show our model outperforms number benchmarks achieving accuracy rate over
Machine Learning approach for Credit Scoring,Statistical Finance,work we build stack machine learning models aimed composing stateoftheart credit rating default prediction system obtaining excellent outofsample performances our approach excursion through most recent ml ai concepts starting natural language processes nlp applied economic sectors textual descriptions using embedding autoencoders ae going through classification defaultable firms base wide range economic features using gradient boosting machines gbm calibrating their probabilities paying due attention treatment unbalanced samples finally we assign credit ratings through genetic algorithms differential evolution de model interpretability achieved implementing recent techniques such shap lime which explain predictions locally features space
"Cancer-inspired Genomics Mapper Model for the Generation of Synthetic
  DNA Sequences with Desired Genomics Signatures",Genomics,genome data are crucial modern medicine offering significant potential diagnosis treatment thanks technological advancements many millions healthy diseased genomes have already been sequenced however obtaining most suitable data specific study specifically validation studies remains challenging respect scale access therefore silico genomics sequence generators have been proposed possible solution however current generators produce inferior data using mostly shallow stochastic connections detected limited computational complexity training data means they do not take appropriate biological relations constraints originally caused observed connections into consideration address issue we propose cancerinspired genomics mapper model cgmm combines genetic algorithm ga deep learning dl methods tackle challenge cgmm mimics processes generate genetic variations mutations transform readily available control genomes into genomes desired phenotypes we demonstrate cgmm can generate synthetic genomes selected phenotypes such ancestry cancer are indistinguishable real genomes such phenotypes based unsupervised clustering our results show cgmm outperforms four current stateoftheart genomics generators two different tasks suggesting cgmm will be suitable wide range purposes genomic medicine especially muchneeded validation studies
"Supporting supervised learning in fungal Biosynthetic Gene Cluster
  discovery: new benchmark datasets",Genomics,fungal biosynthetic gene clusters bgcs secondary metabolites are clusters genes capable producing natural products compounds play important role production wide variety bioactive compounds including antibiotics pharmaceuticals identifying bgcs can lead discovery novel natural products benefit human health previous work has been focused developing automatic tools support bgc discovery plants fungi bacteria datadriven methods well probabilistic supervised learning methods have been explored identifying bgcs most methods applied identify fungal bgcs were datadriven presented limited scope supervised learning methods have been shown perform well identifying bgcs bacteria could be well suited perform same task fungi but labeled data instances are needed perform supervised learning openly accessible bgc databases contain only very small portion previously curated fungal bgcs making new fungal bgc datasets available could motivate development supervised learning methods fungal bgcs potentially improve prediction performance compared datadriven methods work we propose new publicly available fungal bgc datasets support bgc discovery task using supervised learning these datasets are prepared perform binary classification predict candidate bgc regions fungal genomes addition we analyse performance well supported supervised learning tool developed predict bgcs
"Identifying cancer subtypes in glioblastoma by combining genomic,
  transcriptomic and epigenomic data",Genomics,we present nonparametric bayesian method disease subtype discovery multidimensional cancer data our method can simultaneously analyse wide range data types allowing both agreement disagreement between their underlying clustering structure it includes feature selection infers most likely number disease subtypes given data we apply method glioblastoma samples cancer genome atlas which there are gene expression copy number variation methylation microrna data we identify distinct consensus subtypes study their prognostic value death new tumour events progression recurrence consensus subtypes are prognostic tumour recurrence logrank pvalue times after correction multiple hypothesis tests driven principally methylation data logrank pvalue times but effect strengthened other data types demonstrating value integrating multiple data types particular note subtype patients characterised very low levels methylation subtype has very low rates tumour recurrence no new events years follow up we also identify small gene expression subtype patients shows particularly poor survival outcomes additionally we note consensus subtype showly highly distinctive data signature suggest it therefore biologically distinct subtype glioblastoma code available httpssitesgooglecomsitemultipledatafusion
"Interpretable Convolutional Neural Networks for Effective Translation
  Initiation Site Prediction",Genomics,thanks rapidly evolving sequencing techniques amount genomic data our disposal growing increasingly large determining gene structure fundamental requirement effectively interpret gene function regulation important part determination process identification translation initiation sites paper we propose novel approach automatic prediction translation initiation sites leveraging convolutional neural networks allow automatic feature extraction our experimental results demonstrate we are able improve stateoftheart approaches decrease false positive rate decrease error rate chosen datasets furthermore indepth analysis decisionmaking process used our predictive model shows our neural network implicitly learns biologically relevant features scratch without any prior knowledge about problem hand such kozak consensus sequence influence stop start codons sequence presence donor splice site patterns summary our findings yield better understanding internal reasoning convolutional neural network when applying such neural network genomic data
"Network-regularized Sparse Logistic Regression Models for Clinical Risk
  Prediction and Biomarker Discovery",Genomics,molecular profiling data eg gene expression has been used clinical risk prediction biomarker discovery however it necessary integrate other prior knowledge like biological pathways gene interaction networks improve predictive ability biological interpretability biomarkers here we first introduce general regularized logistic regression lr framework regularized term lambda bmw etabmwtbmmbmw which can reduce different penalties including lasso elastic net networkregularized terms different bmm framework can be easily solved unified manner cyclic coordinate descent algorithm which can avoid inverse matrix operation accelerate computing speed however if those estimated bmwi bmwj have opposite signs then traditional networkregularized penalty may not perform well address it we introduce novel networkregularized sparse lr model new penalty lambda bmw etabmwtbmmbmw consider difference between absolute values coefficients we develop two efficient algorithms solve it finally we test our methods compare them related ones using simulated real data show their efficiency
"Inferring agent objectives at different scales of a complex adaptive
  system",Trading and Market Microstructure,we introduce framework study effective objectives different time scales financial market microstructure financial market can be regarded complex adaptive system where purposeful agents collectively simultaneously create perceive their environment they interact it it has been suggested multiple agent classes operate system nontrivial hierarchy topdown bottomup causation classes different effective models governing each level we conjecture agent classes may fact operate different time scales thus act differently response same perceived market state given scalespecific temporal state trajectories action sequences estimated aggregate market behaviour we use inverse reinforcement learning compute effective reward function aggregate agent class each scale allowing us assess relative attractiveness feature vectors across different scales differences reward functions feature vectors may indicate different objectives market participants which could assist finding scale boundary agent classes has implications learning algorithms operating domain
Financial Trading as a Game: A Deep Reinforcement Learning Approach,Trading and Market Microstructure,automatic program generates constant profit financial market lucrative every market practitioner recent advance deep reinforcement learning provides framework toward endtoend training such trading agent paper we propose markov decision process mdp model suitable financial trading task solve it stateoftheart deep recurrent qnetwork drqn algorithm we propose several modifications existing learning algorithm make it more suitable under financial trading setting namely we employ substantially small replay memory only few hundreds size compared ones used modern deep reinforcement learning algorithms often millions size we develop action augmentation technique mitigate need random exploration providing extra feedback signals all actions agent enables us use greedy policy over course learning shows strong empirical performance compared more commonly used epsilongreedy exploration however technique specific financial trading under few market assumptions we sample longer sequence recurrent neural network training side product mechanism we can now train agent every steps greatly reduces training time since overall computation down factor we combine all above into complete online learning algorithm validate our approach spot foreign exchange market
Option Hedging with Risk Averse Reinforcement Learning,Trading and Market Microstructure,paper we show how riskaverse reinforcement learning can be used hedge options we apply stateoftheart riskaverse algorithm trust region volatility optimization trvo vanilla option hedging environment considering realistic factors such discrete time transaction costs realism makes problem twofold agent must both minimize volatility contain transaction costs these tasks usually being competition we use algorithm train sheaf agents each characterized different risk aversion so be able span efficient frontier volatilitypl space results show derived hedging strategy not only outperforms black scholes delta hedge but also extremely robust flexible it can efficiently hedge options different characteristics work markets different behaviors than what was used training
"Trader-Company Method: A Metaheuristic for Interpretable Stock Price
  Prediction",Trading and Market Microstructure,investors try predict returns financial assets make successful investment many quantitative analysts have used machine learningbased methods find unknown profitable market rules large amounts market data however there are several challenges financial markets hindering practical applications machine learningbased models first financial markets there no single model can consistently make accurate prediction because traders markets quickly adapt newly available information instead there are number ephemeral partially correct models called alpha factors second since financial markets are highly uncertain ensuring interpretability prediction models quite important make reliable trading strategies overcome these challenges we propose tradercompany method novel evolutionary model mimics roles financial institute traders belonging it our method predicts future stock returns aggregating suggestions multiple weak learners called traders trader holds collection simple mathematical formulae each which represents candidate alpha factor would be interpretable realworld investors aggregation algorithm called company maintains multiple traders randomly generating new traders retraining them companies can efficiently find financially meaningful formulae whilst avoiding overfitting transient state market we show effectiveness our method conducting experiments real market data
"Inferring agent objectives at different scales of a complex adaptive
  system",Trading and Market Microstructure,we introduce framework study effective objectives different time scales financial market microstructure financial market can be regarded complex adaptive system where purposeful agents collectively simultaneously create perceive their environment they interact it it has been suggested multiple agent classes operate system nontrivial hierarchy topdown bottomup causation classes different effective models governing each level we conjecture agent classes may fact operate different time scales thus act differently response same perceived market state given scalespecific temporal state trajectories action sequences estimated aggregate market behaviour we use inverse reinforcement learning compute effective reward function aggregate agent class each scale allowing us assess relative attractiveness feature vectors across different scales differences reward functions feature vectors may indicate different objectives market participants which could assist finding scale boundary agent classes has implications learning algorithms operating domain
Decisions over Sequences,Economic Theory,paper introduces class objects called decision rules map infinite sequences alternatives decision space these objects can be used model situations where decision maker encounters alternatives sequence such receiving recommendations within class decision rules we study natural subclasses stopping uniform stopping rules our main result establishes equivalence these two subclasses decision rules next we introduce notion computability decision rules using turing machines show computable rules can be implemented using simpler computational device finite automaton we further show computability choice rules important subclass decision rules implied their continuity respect natural topology finally we introduce some natural heuristics framework provide their behavioral characterization
Cheap Talking Algorithms,Economic Theory,we simulate behaviour two independent reinforcement learning algorithms playing crawford sobel game strategic information transmission we adopt memoryless algorithms capture learning static game where large population interacts anonymously we show sender receiver converge nash equilibrium play level informativeness senders cheap talk decreases bias increases intermediate level bias it matches level predicted pareto optimal equilibrium second best one conclusions are robust alternative specifications learning hyperparameters game
"Learning Macroeconomic Policies based on Microfoundations: A Stackelberg
  Mean Field Game Approach",Economic Theory,lucas critique emphasizes importance considering microfoundations how microagents ie households respond policy changes macroeconomic policymaking however due vast scale complex dynamics among microagents predicting microfoundations challenging consequently paper introduces stackelberg mean field game smfg approach models macroeconomic policymaking based microfoundations government leader microagents dynamic followers approach treats largescale microagents population optimize macroeconomic policies learning dynamic response micropopulation our experimental results indicate smfg approach outperforms realworld macroeconomic policies existing aibased economic methods enabling learned macroeconomic policy achieve highest performance while guiding largescale microagents toward maximal social welfare additionally when extended realworld scenarios households do not adopt smfg policy experience lower utility wealth than adopters thereby increasing attractiveness our policy summary paper contributes field ai economics offering effective tool modeling solving macroeconomic policymaking issues
Decisions over Sequences,Economic Theory,paper introduces class objects called decision rules map infinite sequences alternatives decision space these objects can be used model situations where decision maker encounters alternatives sequence such receiving recommendations within class decision rules we study natural subclasses stopping uniform stopping rules our main result establishes equivalence these two subclasses decision rules next we introduce notion computability decision rules using turing machines show computable rules can be implemented using simpler computational device finite automaton we further show computability choice rules important subclass decision rules implied their continuity respect natural topology finally we introduce some natural heuristics framework provide their behavioral characterization
"Fair Shares: Feasibility, Domination and Incentives",Economic Theory,we consider fair allocation set indivisible goods equallyentitled agents no monetary transfers every agent has valuation vi some given class valuation functions share function maps pair vin value interpretation if allocation agents fails give agent bundle value least equal svin serves evidence allocation not fair towards such interpretation make sense we would like share be feasible meaning any valuations class there allocation gives every agent least her share maximin share was natural candidate feasible share additive valuations however kurokawa procaccia wang show it not feasible we initiate systematic study family feasible shares we say share emphself maximizing if truthtelling maximizes implied guarantee we show every feasible share dominated some selfmaximizing feasible share we seek identify those selfmaximizing feasible shares are polynomial time computable offer highest share values we show smdominating feasible share one dominates every selfmaximizing sm feasible share does not exist additive valuations beyond consequently we relax domination property domination up multiplicative factor rho called rhodominating additive valuations we present shares are feasible selfmaximizing polynomialtime computable agents we present such share fracnndominating two agents we present such share epsilondominating moreover these shares we present polytime algorithms compute allocations give every agent least her share
PIMKL: Pathway Induced Multiple Kernel Learning,Molecular Networks,reliable identification molecular biomarkers essential accurate patient stratification while stateoftheart machine learning approaches sample classification continue push boundaries terms performance most these methods are not able integrate different data types lack generalization power limiting their application clinical setting furthermore many methods behave black boxes we have very little understanding about mechanisms lead prediction while opaqueness concerning machine behaviour might not be problem deterministic domains health care providing explanations about molecular factors phenotypes are driving classification crucial build trust performance predictive system we propose pathway induced multiple kernel learning pimkl novel methodology reliably classify samples can also help gain insights into molecular mechanisms underlie classification pimkl exploits prior knowledge form molecular interaction network annotated gene sets optimizing mixture pathwayinduced kernels using multiple kernel learning mkl algorithm approach has demonstrated excellent performance different machine learning applications after optimizing combination kernels prediction specific phenotype model provides stable molecular signature can be interpreted light ingested prior knowledge can be used transfer learning tasks
Towards Scalable Modeling of Biology in Event-B,Molecular Networks,biology offers many examples largescale complex concurrent systems many processes take place parallel compete resources influence each others behavior scalable modeling biological systems continues be very active field research paper we introduce new approach based eventb statebased formal method refinement its central ingredient allowing us check model consistency stepbystep automated way our approach based functions leads elegant concise modeling method we demonstrate approach constructing what our knowledge largest ever built eventb model describing erbb signaling pathway key evolutionary pathway significant role development many types cancer eventb model erbb pathway describes molecular reactions through events
"Network-principled deep generative models for designing drug
  combinations as graph sets",Molecular Networks,combination therapy has shown improve therapeutic efficacy while reducing side effects importantly it has become indispensable strategy overcome resistance antibiotics antimicrobials anticancer drugs facing enormous chemical space unclear design principles smallmolecule combinations computational drugcombination design has not seen generative models meet its potential accelerate resistanceovercoming drug combination discovery we have developed first deep generative model drug combination design jointly embedding graphstructured domain knowledge iteratively training reinforcement learningbased chemical graphset designer first we have developed hierarchical variational graph autoencoders hvgae trained endtoend jointly embed genegene genedisease diseasedisease networks novel attentional pooling introduced here learning diseaserepresentations associated genes representations second targeting diseases learned representations we have recast drugcombination design problem graphset generation developed deep learningbased model novel rewards specifically besides chemical validity rewards we have introduced novel generative adversarial award being generalized sliced wasserstein chemically diverse molecules distributions similar known drugs we have also designed network principlebased reward drug combinations numerical results indicate compared graph embedding methods hvgae learns more informative generalizable disease representations case studies four diseases show networkprincipled drug combinations tend have low toxicity generated drug combinations collectively cover disease module similar fdaapproved drug combinations could potentially suggest novel systemspharmacology strategies
"Supervised, semi-supervised and unsupervised inference of gene
  regulatory networks",Molecular Networks,inference gene regulatory network expression data challenging task many methods have been developed purpose but comprehensive evaluation covers unsupervised semisupervised supervised methods provides guidelines their practical application lacking we performed extensive evaluation inference methods simulated expression data results reveal very low prediction accuracies unsupervised techniques notable exception zscore method knockout data all other cases supervised approach achieved highest accuracies even semisupervised setting small numbers only positive samples outperformed unsupervised techniques
"Faster graphical model identification of tandem mass spectra using
  peptide word lattices",Molecular Networks,liquid chromatography coupled tandem mass spectrometry also known shotgun proteomics widelyused highthroughput technology identifying proteins complex biological samples analysis tens thousands fragmentation spectra produced typical shotgun proteomics experiment begins assigning each observed spectrum peptide hypothesized be responsible generating spectrum typically done searching each spectrum against database peptides we have recently described machine learning methoddynamic bayesian network rapid identification peptides dripthat not only achieves stateoftheart spectrum identification performance variety datasets but also provides trainable model capable returning valuable auxiliary information regarding specific peptidespectrum matches work we present two significant improvements drip first we describe how use word lattices which are widely used natural language processing significantly speed up drips computations our knowledge all existing shotgun proteomics search engines compute independent scores between given observed spectrum each possible candidate peptide database key idea word lattice represent set candidate peptides single data structure thereby allowing sharing redundant computations among different candidates we demonstrate using lattices conjunction drip leads speedups order tens across yeast worm data sets second we introduce variant drip uses discriminative training framework performing maximum mutual entropy estimation rather than maximum likelihood estimation modification improves drips statistical power enabling us increase number identified spectrum false discovery rate yeast worm data sets
Prediction of Infinite Words with Automata,Formal Languages and Automata Theory,classic problem sequence prediction predictor receives sequence values emitter tries guess next value before it appears predictor masters emitter if there point after which all predictors guesses are correct paper we consider case which predictor automaton emitted values are drawn finite set ie emitted sequence infinite word we examine predictive capabilities finite automata pushdown automata stack automata generalization pushdown automata multihead finite automata we relate our predicting automata purely periodic words ultimately periodic words multilinear words describing novel prediction algorithms mastering these sequences
Automata for Hyperlanguages,Formal Languages and Automata Theory,hyperproperties lift conventional trace properties set execution traces set sets execution traces hyperproperties have been shown be powerful formalism expressing reasoning about informationflow security policies important properties cyberphysical systems such sensitivity robustness well consistency conditions distributed computing such linearizability although there extensive body work automatabased representation trace properties we currently lack such characterization hyperproperties we introduce hyperautomata em hyperlanguages which are languages over sets words essentially hyperautomata allow running multiple quantified words over automaton we propose specific type hyperautomata called nondeterministic finite hyperautomata nfh which accept regular hyperlanguages we demonstrate ability regular hyperlanguages express hyperproperties finite traces we then explore fundamental properties nfh show their closure under boolean operations we show while nonemptiness undecidable general it decidable several fragments nfh we further show decidability membership problem finite sets regular languages nfh well containment problem several fragments nfh finally we introduce learning algorithms based angluins lstar algorithm fragments nfh which quantification either strictly universal strictly existential
On Learning Nominal Automata with Binders,Formal Languages and Automata Theory,we investigate learning algorithm context nominal automata extension classical automata alphabets featuring names class automata captures nominal regular languages analogously classical language theory nominal automata have been shown characterise nominal regular expressions binders these formalisms are amenable abstract modelling resourceaware computations we propose learning algorithm nominal regular languages binders our algorithm generalises angluins algorithm respect nominal regular languages binders we show correctness study theoretical complexity our algorithm
Learning of Structurally Unambiguous Probabilistic Grammars,Formal Languages and Automata Theory,problem identifying probabilistic context free grammar has two aspects first determining grammars topology rules grammar second estimating probabilistic weights each rule given hardness results learning contextfree grammars general probabilistic grammars particular most literature has concentrated second problem work we address first problem we restrict attention structurally unambiguous weighted contextfree grammars suwcfg provide query learning algorithm structurally unambiguous probabilistic contextfree grammars supcfg we show suwcfg can be represented using colinear multiplicity tree automata cmta provide polynomial learning algorithm learns cmtas we show learned cmta can be converted into probabilistic grammar thus providing complete algorithm learning structurally unambiguous probabilistic context free grammar both grammar topology probabilistic weights using structured membership queries structured equivalence queries we demonstrate usefulness our algorithm learning pcfgs over genomic data
Query Learning Algorithm for Residual Symbolic Finite Automata,Formal Languages and Automata Theory,we propose query learning algorithm residual symbolic finite automata rsfas symbolic finite automata sfas are finite automata whose transitions are labeled predicates over boolean algebra which big collection characters leading same transition may be represented single predicate residual finite automata rfas are special type nondeterministic finite automata which can be exponentially smaller than minimum deterministic finite automata have favorable property learning algorithms rsfas have both properties sfas rfas can have more succinct representation transitions fewer states than rfas deterministic sfas accepting same language implementation our algorithm efficiently learns rsfas over huge alphabet outperforms existing learning algorithm deterministic sfas result also shows benefit nondeterminism efficiency even larger learning sfas than nonsymbolic automata
"On a link between kernel mean maps and Fraunhofer diffraction, with an
  application to super-resolution beyond the diffraction limit",Optics,we establish link between fourier optics recent construction machine learning community termed kernel mean map using fraunhofer approximation it identifies kernel squared fourier transform aperture allows us use results about invertibility kernel mean map provide statement about invertibility fraunhofer diffraction showing imaging processes arbitrarily small apertures can principle be invertible ie do not lose information provided objects be imaged satisfy generic condition real world experiment shows we can superresolve beyond rayleigh limit
Time-lapse image classification using a diffractive neural network,Optics,diffractive deep neural networks dnns define alloptical computing framework comprised spatially engineered passive surfaces collectively process optical input information modulating amplitude andor phase propagating light diffractive optical networks complete their computational tasks speed light propagation through thin diffractive volume without any external computing power while exploiting massive parallelism optics diffractive networks were demonstrated achieve alloptical classification objects perform universal linear transformations here we demonstrate first time timelapse image classification scheme using diffractive network significantly advancing its classification accuracy generalization performance complex input objects using lateral movements input objects andor diffractive network relative each other different context such relative movements objects andor camera are routinely being used image superresolution applications inspired their success we designed timelapse diffractive network benefit complementary information content created controlled random lateral shifts we numerically explored design space performance limits timelapse diffractive networks revealing blind testing accuracy optical classification objects cifar dataset constitutes highest inference accuracy achieved so far using single diffractive network cifar dataset timelapse diffractive networks will be broadly useful spatiotemporal analysis input signals using alloptical processors
"Monadic Pavlovian associative learning in a backpropagation-free
  photonic network",Optics,over century ago ivan pavlov classic experiment demonstrated how dogs can learn associate ringing bell food thereby causing ring result salivation today it rare find use pavlovian type associative learning artificial intelligence ai applications even though other learning concepts particular backpropagation artificial neural networks anns have flourished however training using backpropagation method conventional anns especially form modern deep neural networks dnns computationally energy intensive here we experimentally demonstrate form backpropagationfree learning using single monadic associative hardware element we realize integrated photonic platform using phasechange materials combined onchip cascaded directional couplers we then develop scaledup circuit network using our monadic pavlovian photonic hardware delivers distinct machinelearning framework based singleelement associations importantly using backpropagationfree architectures address general learning tasks our approach reduces computational burden imposed learning conventional neural network approaches thereby increasing speed whilst also offering higher bandwidth inherent our photonic implementation
"Optically-triggered deterministic spiking regimes in nanostructure
  resonant tunnelling diode-photodetectors",Optics,work reports nanostructure resonant tunnelling diodephotodetector rtdpd device demonstrates its operation controllable opticallytriggered excitable spike generator top contact layer device designed nanopillar structure nm diameter restrain injection current yielding therefore lower energy operation spike generation we demonstrate experimentally deterministic optical triggering controllable repeatable neuronlike spike patterns nanostructure rtdpds moreover we show devices ability deliver spiking responses when biased both regions adjacent negative differential conductance ndc region socalled peak valley points currentvoltage iv characteristic work also demonstrates experimentally key neuronlike dynamical features nanostructure rtdpd such welldefined threshold input optical intensity spike firing well presence spike firing refractory time optoelectronic chipscale character proposed system together deterministic repeatable well controllable nature opticallyelicited spiking responses render nanostructure rtdpd element highly promising solution highspeed energyefficient optoelectronic artificial spiking neurons novel lightenabled neuromorphic computing hardware
Deep Learning Reconstruction of Ultra-Short Pulses,Optics,ultrashort laser pulses femtosecond attosecond pulse duration are shortest systematic events humans can create characterization amplitude phase these pulses key ingredient ultrafast science eg exploring chemical reactions electronic phase transitions here we propose demonstrate numerically experimentally first deep neural network technique reconstruct ultrashort optical pulses we anticipate approach will extend range ultrashort laser pulses can be characterized eg enabling diagnose very weak attosecond pulses
"Uncovering wall-shear stress dynamics from neural-network enhanced fluid
  flow measurements",Fluid Dynamics,friction drag turbulent fluid moving past inside object plays crucial role domains diverse transportation public utility infrastructure energy technology human health direct measure shearinduced friction forces accurate prediction wallshear stress can contribute sustainability conservation resources carbon neutrality civil aviation well enhanced medical treatment vascular diseases cancer despite such importance our modern society we still lack adequate experimental methods capture instantaneous wallshear stress dynamics contribution we present holistic approach derives velocity wallshear stress fields impressive spatial temporal resolution flow measurements using deep optical flow estimator physical knowledge validity physical correctness derived flow quantities demonstrated synthetic realworld experimental data covering range relevant fluid flows
Local manifold learning and its link to domain-based physics knowledge,Fluid Dynamics,many reacting flow systems thermochemical statespace known assumed evolve close lowdimensional manifold ldm various approaches are available obtain those manifolds subsequently express original highdimensional space fewer parameterizing variables principal component analysis pca one dimensionality reduction methods can be used obtain ldms pca does not make prior assumptions about parameterizing variables retrieves them empirically training data paper we show pca applied local clusters data local pca capable detecting intrinsic parameterization thermochemical statespace we first demonstrate utilizing three common combustion models varying complexity burkeschumann model chemical equilibrium model homogeneous reactor parameterization these models known priori which allows benchmarking local pca approach we further extend application local pca more challenging case turbulent nonpremixed nheptaneair jet flame which parameterization no longer obvious our results suggest meaningful parameterization can be obtained also more complex datasets we show local pca finds variables can be linked local stoichiometry reaction progress soot formation processes
"AutoTurb: Using Large Language Models for Automatic Algebraic Model
  Discovery of Turbulence Closure",Fluid Dynamics,symbolic regression sr methods have been extensively investigated explore explicit algebraic reynolds stress models earsm turbulence closure reynoldsaveraged navierstokes rans equations deduced earsm can be readily implemented existing computational fluid dynamic cfd codes promotes identification physically interpretable turbulence models existing sr methods such genetic programming sparse regression artificial neural networks require userdefined functional operators library candidates complex optimization algorithms work novel framework using llms automatically discover algebraic expressions correcting rsm proposed direct observation reynolds stress indirect output cfd simulation are both involved training process guarantee data consistency avoid numerical stiffness constraints functional complexity convergence are supplementally imposed objective function account tremendous flexibility llms evolutionary search employed global optimization proposed method performed separated flow over periodic hills re generalizability discovered model verified set turbulent separated flow configurations different reynolds numbers geometries it demonstrated corrective rans can improve prediction both reynolds stress mean velocity fields compared algebraic models discovered other works discovered model performs better accuracy generalization capability proposed approach provides promising paradigm using llms improve turbulence modeling given class flows
A Physics-Informed Neural Network to Model Port Channels,Fluid Dynamics,we describe physicsinformed neural network pinn simulates flow induced astronomical tide synthetic port channel dimensions based santos sao vicente bertioga estuarine system pinn models aim combine knowledge physical systems datadriven machine learning models done training neural network minimize residuals governing equations sample points work our flow governed navierstokes equations some approximations there are two main novelties paper first we design our model assume flow periodic time which not feasible conventional simulation methods second we evaluate benefit resampling function evaluation points during training which has near zero computational cost has been verified improve final model especially small batch sizes finally we discuss some limitations approximations used navierstokes equations regarding modeling turbulence how it interacts pinns
Assessment of machine learning methods for state-to-state approaches,Fluid Dynamics,it well known numerical simulations highspeed reacting flows framework statetostate formulations are most detailed but also often prohibitively computationally expensive work we start investigate possibilities offered use machine learning methods statetostate approaches alleviate such burden regard several tasks have been identified firstly we assessed potential stateoftheart datadriven regression models based machine learning predict relaxation source terms which appear righthand side statetostate euler system equations onedimensional reacting flow nn binary mixture behind plane shock wave it found appropriately choosing regressor opportunely tuning its hyperparameters it possible achieve accurate predictions compared fullscale statetostate simulation significantly shorter times secondly we investigated different strategies speedup our inhouse statetostate solver coupling it bestperforming pretrained machine learning algorithm embedding machine learning methods into ordinary differential equations solvers may offer speedup several orders magnitude but some care should be paid how where such coupling realized performances are found be strongly dependent mutual nature interfaced codes finally we aimed inferring full solution statetostate euler system equations means deep neural network completely bypassing use statetostate solver while relying only data promising results suggest deep neural networks appear be viable technology also these tasks
Graphical law beneath each written natural language,General Physics,we study twenty four written natural languages we draw log scale number words starting letter vs rank letter both normalised we find all graphs are similar type graphs are tantalisingly closer curves reduced magnetisation vs reduced temperature magnetic materials we make weak conjecture curve magnetisation underlies written natural language
Emergence in artificial life,General Physics,even when concepts similar emergence have been used since antiquity we lack agreed definition however emergence has been identified one main features complex systems most would agree statement life complex thus understanding emergence complexity should benefit study living systems it can be said life emerges interactions complex molecules but how useful understand living systems artificial life alife has been developed recent decades study life using synthetic approach build it understand it alife systems are not so complex be them soft simulations hard robots wet protocells then we can aim first understanding emergence alife then using knowledge biology argue understand emergence life it becomes useful use information framework general sense define emergence information not present one scale but present another scale perspective avoids problems studying emergence materialist framework can be also useful study selforganization complexity
Graphical law beneath each written natural language,General Physics,we study twenty four written natural languages we draw log scale number words starting letter vs rank letter both normalised we find all graphs are similar type graphs are tantalisingly closer curves reduced magnetisation vs reduced temperature magnetic materials we make weak conjecture curve magnetisation underlies written natural language
Graphical law beneath each written natural language,General Physics,we study twenty four written natural languages we draw log scale number words starting letter vs rank letter both normalised we find all graphs are similar type graphs are tantalisingly closer curves reduced magnetisation vs reduced temperature magnetic materials we make weak conjecture curve magnetisation underlies written natural language
Emergence in artificial life,General Physics,even when concepts similar emergence have been used since antiquity we lack agreed definition however emergence has been identified one main features complex systems most would agree statement life complex thus understanding emergence complexity should benefit study living systems it can be said life emerges interactions complex molecules but how useful understand living systems artificial life alife has been developed recent decades study life using synthetic approach build it understand it alife systems are not so complex be them soft simulations hard robots wet protocells then we can aim first understanding emergence alife then using knowledge biology argue understand emergence life it becomes useful use information framework general sense define emergence information not present one scale but present another scale perspective avoids problems studying emergence materialist framework can be also useful study selforganization complexity
"Hyperparameter Tuning for Causal Inference with Double Machine Learning:
  A Simulation Study",Econometrics,proper hyperparameter tuning essential achieving optimal performance modern machine learning ml methods predictive tasks while there extensive literature tuning ml learners prediction there only little guidance available tuning ml learners causal machine learning how select among different ml learners paper we empirically assess relationship between predictive performance ml methods resulting causal estimation based double machine learning dml approach chernozhukov et al dml relies estimating socalled nuisance parameters treating them supervised learning problems using them plugin estimates solve causal parameter we conduct extensive simulation study using data atlantic causal inference data challenge we provide empirical insights role hyperparameter tuning other practical decisions causal estimation dml first we assess importance data splitting schemes tuning ml learners within double machine learning second we investigate how choice ml methods hyperparameters including recent automl frameworks impacts estimation performance causal parameter interest third we assess what extent choice particular causal model characterized incorporated parametric assumptions can be based predictive performance metrics
Adaptive Combinatorial Allocation,Econometrics,we consider settings where allocation has be chosen repeatedly returns are unknown but can be learned decisions are subject constraints our model covers twosided onesided matching even complex constraints we propose approach based thompson sampling our main result priorindependent finitesample bound expected regret algorithm although number allocations grows exponentially number participants bound does not depend number we illustrate performance our algorithm using data refugee resettlement united states
"Algorithmic Collusion in Cournot Duopoly Market: Evidence from
  Experimental Economics",Econometrics,algorithmic collusion emerging concept current artificial intelligence age whether algorithmic collusion creditable threat remains argument paper we propose algorithm which can extort its human rival collude cournot duopoly competing market experiments we show algorithm can successfully extorted its human rival gets higher profit long run meanwhile human rival will fully collude algorithm result social welfare declines rapidly stably both theory experiment our work confirms algorithmic collusion can be creditable threat application we hope frameworks algorithm design well experiment environment illustrated work can be incubator test bed researchers policymakers handle emerging algorithmic collusion
"Forecasting in Big Data Environments: an Adaptable and Automated
  Shrinkage Estimation of Neural Networks (AAShNet)",Econometrics,paper considers improved forecasting possibly nonlinear dynamic settings highdimension predictors big data environments overcome curse dimensionality manage data model complexity we examine shrinkage estimation backpropagation algorithm deep neural net skiplayer connections we expressly include both linear nonlinear components highdimensional learning approach including both sparsity smoothness penalties allowing highdimensionality nonlinearity be accommodated one step approach selects significant predictors well topology neural network we estimate optimal values shrinkage hyperparameters incorporating gradientbased optimization technique resulting robust predictions improved reproducibility latter has been issue some approaches statistically interpretable unravels some network structure commonly left black box additional advantage nonlinear part tends get pruned if underlying process linear application forecasting equity returns proposed approach captures nonlinear dynamics between equities enhance forecast performance it offers appreciable improvement over current univariate multivariate models rmse actual portfolio performance
Weighted-average quantile regression,Econometrics,paper we introduce weightedaverage quantile regression framework int qyxupsiudu xbeta where dependent variable vector covariates qyx quantile function conditional distribution given psi weighting function beta vector parameters we argue framework interest many applied settings develop estimator vector parameters beta we show our estimator sqrt tconsistent asymptotically normal mean zero easily estimable covariance matrix where size available sample we demonstrate usefulness our estimator applying it two empirical settings first setting we focus financial data study factor structures expected shortfalls industry portfolios second setting we focus wage data study inequality social welfare dependence commonly used individual characteristics
The persistence landscape and some of its properties,Algebraic Topology,persistence landscapes map persistence diagrams into function space which may often be taken be banach space even hilbert space latter case it feature map there associated kernel main advantage summary it allows one apply tools statistics machine learning furthermore mapping persistence diagrams persistence landscapes stable invertible we introduce weighted version persistence landscape define oneparameter family poissonweighted persistence landscape kernels may be useful learning we also demonstrate some additional properties persistence landscape first persistence landscape may be viewed tropical rational function second many cases it possible exactly reconstruct all component persistence diagrams average persistence landscape it follows persistence landscape kernel characteristic certain generic empirical measures finally persistence landscape distance may be arbitrarily small compared interleaving distance
"Fast Topological Signal Identification and Persistent Cohomological
  Cycle Matching",Algebraic Topology,within context topological data analysis problems identifying topological significance matching signals across datasets are important useful inferential tasks many applications limitation existing solutions these problems however computational speed paper we harness stateoftheart persistent homology computation studying problem determining topological prevalence cycle matching using cohomological approach which increases their feasibility applicability wider variety applications contexts we demonstrate wide range reallife largescale complex datasets we extend existing notions topological prevalence cycle matching include general nonmorse filtrations provides most general flexible stateoftheart adaptation topological signal identification persistent cycle matching which performs comparisons orders ten thousands sampled points matter minutes standard institutional hpc cpu facilities
A New Non-archimedean Metric on Persistent Homology,Algebraic Topology,article we define new nonarchimedean metric structure called cophenetic metric persistent homology classes all degrees we then show zeroth persistent homology together cophenetic metric hierarchical clustering algorithms number different metrics do deliver statistically verifiable commensurate topological information based experimental results we obtained different datasets we also observe resulting clusters coming cophenetic distance do shine terms different evaluation measures such silhouette score rand index moreover since cophenetic metric defined all homology degrees one can now display interrelations persistent homology classes all degrees via rooted trees
"Fast Topological Signal Identification and Persistent Cohomological
  Cycle Matching",Algebraic Topology,within context topological data analysis problems identifying topological significance matching signals across datasets are important useful inferential tasks many applications limitation existing solutions these problems however computational speed paper we harness stateoftheart persistent homology computation studying problem determining topological prevalence cycle matching using cohomological approach which increases their feasibility applicability wider variety applications contexts we demonstrate wide range reallife largescale complex datasets we extend existing notions topological prevalence cycle matching include general nonmorse filtrations provides most general flexible stateoftheart adaptation topological signal identification persistent cycle matching which performs comparisons orders ten thousands sampled points matter minutes standard institutional hpc cpu facilities
"Fast Topological Signal Identification and Persistent Cohomological
  Cycle Matching",Algebraic Topology,within context topological data analysis problems identifying topological significance matching signals across datasets are important useful inferential tasks many applications limitation existing solutions these problems however computational speed paper we harness stateoftheart persistent homology computation studying problem determining topological prevalence cycle matching using cohomological approach which increases their feasibility applicability wider variety applications contexts we demonstrate wide range reallife largescale complex datasets we extend existing notions topological prevalence cycle matching include general nonmorse filtrations provides most general flexible stateoftheart adaptation topological signal identification persistent cycle matching which performs comparisons orders ten thousands sampled points matter minutes standard institutional hpc cpu facilities
Solving Optimization Problems by the Public Goods Game,Physics and Society,we introduce method based public goods game solving optimization tasks particular we focus traveling salesman problem ie nphard problem whose search space exponentially grows increasing number cities proposed method considers population whose agents are provided random solution given problem doing so agents interact playing public goods game using fitness their solution currency game notably agents better solutions provide higher contributions while those lower ones tend imitate solution richer agents increasing their fitness numerical simulations show proposed method allows compute exact solutions suboptimal ones considered search spaces result beyond propose new heuristic combinatorial optimization problems our work aims highlight potentiality evolutionary game theory beyond its current horizons
"Frequency patterns of semantic change: Corpus-based evidence of a
  near-critical dynamics in language change",Physics and Society,it generally believed when linguistic item acquires new meaning its overall frequency use language rises time sshaped growth curve yet claim has only been supported limited number case studies paper we provide first corpusbased quantitative confirmation genericity scurve language change moreover we uncover another generic pattern latency phase variable duration preceding sgrowth during which frequency use semantically expanding word remains low more less constant we also propose usagebased model language change supported cognitive considerations which predicts both phases latency fast sgrowth take place driving mechanism stochastic dynamics random walk space frequency use underlying deterministic dynamics highlights role control parameter strength cognitive impetus governing onset change which tunes system vicinity saddlenode bifurcation neighborhood critical point latency phase corresponds diffusion time over critical region sgrowth fast convergence follows duration two phases computed specific first passage times random walk process leading distributions fit well ones extracted our dataset we argue our results are not specific studied corpus but apply semantic change general
"Network structure, metadata and the prediction of missing nodes and
  annotations",Physics and Society,empirical validation community detection methods often based available annotations nodes serve putative indicators largescale network structure most often suitability annotations topological descriptors itself not assessed without it not possible ultimately distinguish between actual shortcomings community detection algorithms one hand incompleteness inaccuracy structured nature data annotations themselves other work we present principled method access both aspects simultaneously we construct joint generative model data metadata nonparametric bayesian framework infer its parameters annotated datasets we assess quality metadata not according its direct alignment network communities but rather its capacity predict placement edges network we also show how feature can be used predict connections missing nodes when only metadata available well missing metadata investigating wide range datasets we show while there are seldom exact agreements between metadata tokens inferred data groups metadata often informative network structure nevertheless can improve prediction missing nodes shows method uncovers meaningful patterns both data metadata without requiring expecting perfect agreement between two
The predictability of letters in written english,Physics and Society,we show predictability letters written english texts depends strongly their position word first letters are usually least easy predict agrees intuitive notion words are well defined subunits written languages much weaker correlations across these units than within them it implies average entropy letter deep inside word roughly times smaller than entropy first letter
"How social feedback processing in the brain shapes collective opinion
  processes in the era of social media",Physics and Society,what are mechanisms which groups certain opinions gain public voice force others holding different view into silence how does social media play into drawing recent neuroscientific insights into processing social feedback we develop theoretical model allows address these questions model captures phenomena described spiral silence theory public opinion provides mechanismbased foundation it allows way more general insight into how different group structures relate different regimes collective opinion expression even strong majorities can be forced into silence if minority acts cohesive whole proposed framework social feedback theory sft highlights need sociological theorising understand societallevel implications findings social cognitive neuroscience
Cataloging Accreted Stars within Gaia DR2 using Deep Learning,Astrophysics of Galaxies,goal study present development machine learning based approach utilizes phase space alone separate gaia dr stars into two categories those accreted onto milky way those are situ traditional selection methods have been used identify accreted stars typically rely full velocity metallicity information both which significantly reduces number classifiable stars approach advocated here applicable much larger portion gaia dr method known transfer learning shown be effective through extensive testing set mock gaia catalogs are based fire cosmological zoomin hydrodynamic simulations milky waymass galaxies machine first trained simulated data using only kinematics inputs then further trained crossmatched gaiarave data set which improves sensitivity properties real milky way result catalog identifies around accreted stars within gaia dr catalog can yield empirical insights into merger history milky way could be used infer properties dark matter distribution
Unsupervised Domain Adaptation for Constraining Star Formation Histories,Astrophysics of Galaxies,prevalent paradigm machine learning today use past observations predict future ones what if however we are interested knowing past given present situation indeed one astronomers must contend often understand formation our universe we must derive time evolution visible mass content galaxies however observe complete star life one would need wait one billion years overcome difficulty astrophysicists leverage supercomputers evolve simulated models galaxies till current age universe thus establishing mapping between observed radiation star formation histories sfhs such groundtruth sfhs are lacking actual galaxy observations where they are usually inferred often poor confidence spectral energy distributions seds using bayesian fitting methods investigation we discuss ability unsupervised domain adaptation derive accurate sfhs galaxies simulated data necessary first step developing technique can ultimately be applied observational data
Cataloging Accreted Stars within Gaia DR2 using Deep Learning,Astrophysics of Galaxies,goal study present development machine learning based approach utilizes phase space alone separate gaia dr stars into two categories those accreted onto milky way those are situ traditional selection methods have been used identify accreted stars typically rely full velocity metallicity information both which significantly reduces number classifiable stars approach advocated here applicable much larger portion gaia dr method known transfer learning shown be effective through extensive testing set mock gaia catalogs are based fire cosmological zoomin hydrodynamic simulations milky waymass galaxies machine first trained simulated data using only kinematics inputs then further trained crossmatched gaiarave data set which improves sensitivity properties real milky way result catalog identifies around accreted stars within gaia dr catalog can yield empirical insights into merger history milky way could be used infer properties dark matter distribution
Cataloging Accreted Stars within Gaia DR2 using Deep Learning,Astrophysics of Galaxies,goal study present development machine learning based approach utilizes phase space alone separate gaia dr stars into two categories those accreted onto milky way those are situ traditional selection methods have been used identify accreted stars typically rely full velocity metallicity information both which significantly reduces number classifiable stars approach advocated here applicable much larger portion gaia dr method known transfer learning shown be effective through extensive testing set mock gaia catalogs are based fire cosmological zoomin hydrodynamic simulations milky waymass galaxies machine first trained simulated data using only kinematics inputs then further trained crossmatched gaiarave data set which improves sensitivity properties real milky way result catalog identifies around accreted stars within gaia dr catalog can yield empirical insights into merger history milky way could be used infer properties dark matter distribution
Unsupervised Domain Adaptation for Constraining Star Formation Histories,Astrophysics of Galaxies,prevalent paradigm machine learning today use past observations predict future ones what if however we are interested knowing past given present situation indeed one astronomers must contend often understand formation our universe we must derive time evolution visible mass content galaxies however observe complete star life one would need wait one billion years overcome difficulty astrophysicists leverage supercomputers evolve simulated models galaxies till current age universe thus establishing mapping between observed radiation star formation histories sfhs such groundtruth sfhs are lacking actual galaxy observations where they are usually inferred often poor confidence spectral energy distributions seds using bayesian fitting methods investigation we discuss ability unsupervised domain adaptation derive accurate sfhs galaxies simulated data necessary first step developing technique can ultimately be applied observational data
"Two-dimensional total absorption spectroscopy with conditional
  generative adversarial networks",Nuclear Experiment,we explore use machine learning techniques remove response large volume gammaray detectors experimental spectra segmented gammaray total absorption spectrometers tas allow simultaneous measurement individual gammaray energy egamma total excitation energy ex analysis tas detector data complicated fact ex egamma quantities are correlated therefore techniques simply unfold using ex egamma response functions independently are not accurate work we investigate use conditional generative adversarial networks cgans simultaneously unfold ex egamma data tas detectors specifically we employ textttpixpix cgan generative modeling technique based recent advances deep learning treat rawmatrix matrix unfolding imagetoimage translation problem we present results simulated experimental matrices singlegamma doublegamma decay cascades our model demonstrates characterization capabilities within detector resolution limits upwards simulated test cases
"Two-dimensional total absorption spectroscopy with conditional
  generative adversarial networks",Nuclear Experiment,we explore use machine learning techniques remove response large volume gammaray detectors experimental spectra segmented gammaray total absorption spectrometers tas allow simultaneous measurement individual gammaray energy egamma total excitation energy ex analysis tas detector data complicated fact ex egamma quantities are correlated therefore techniques simply unfold using ex egamma response functions independently are not accurate work we investigate use conditional generative adversarial networks cgans simultaneously unfold ex egamma data tas detectors specifically we employ textttpixpix cgan generative modeling technique based recent advances deep learning treat rawmatrix matrix unfolding imagetoimage translation problem we present results simulated experimental matrices singlegamma doublegamma decay cascades our model demonstrates characterization capabilities within detector resolution limits upwards simulated test cases
"Two-dimensional total absorption spectroscopy with conditional
  generative adversarial networks",Nuclear Experiment,we explore use machine learning techniques remove response large volume gammaray detectors experimental spectra segmented gammaray total absorption spectrometers tas allow simultaneous measurement individual gammaray energy egamma total excitation energy ex analysis tas detector data complicated fact ex egamma quantities are correlated therefore techniques simply unfold using ex egamma response functions independently are not accurate work we investigate use conditional generative adversarial networks cgans simultaneously unfold ex egamma data tas detectors specifically we employ textttpixpix cgan generative modeling technique based recent advances deep learning treat rawmatrix matrix unfolding imagetoimage translation problem we present results simulated experimental matrices singlegamma doublegamma decay cascades our model demonstrates characterization capabilities within detector resolution limits upwards simulated test cases
"Two-dimensional total absorption spectroscopy with conditional
  generative adversarial networks",Nuclear Experiment,we explore use machine learning techniques remove response large volume gammaray detectors experimental spectra segmented gammaray total absorption spectrometers tas allow simultaneous measurement individual gammaray energy egamma total excitation energy ex analysis tas detector data complicated fact ex egamma quantities are correlated therefore techniques simply unfold using ex egamma response functions independently are not accurate work we investigate use conditional generative adversarial networks cgans simultaneously unfold ex egamma data tas detectors specifically we employ textttpixpix cgan generative modeling technique based recent advances deep learning treat rawmatrix matrix unfolding imagetoimage translation problem we present results simulated experimental matrices singlegamma doublegamma decay cascades our model demonstrates characterization capabilities within detector resolution limits upwards simulated test cases
"Two-dimensional total absorption spectroscopy with conditional
  generative adversarial networks",Nuclear Experiment,we explore use machine learning techniques remove response large volume gammaray detectors experimental spectra segmented gammaray total absorption spectrometers tas allow simultaneous measurement individual gammaray energy egamma total excitation energy ex analysis tas detector data complicated fact ex egamma quantities are correlated therefore techniques simply unfold using ex egamma response functions independently are not accurate work we investigate use conditional generative adversarial networks cgans simultaneously unfold ex egamma data tas detectors specifically we employ textttpixpix cgan generative modeling technique based recent advances deep learning treat rawmatrix matrix unfolding imagetoimage translation problem we present results simulated experimental matrices singlegamma doublegamma decay cascades our model demonstrates characterization capabilities within detector resolution limits upwards simulated test cases
"A physics-informed search for metric solutions to Ricci flow, their
  embeddings, and visualisation",General Relativity and Quantum Cosmology,neural networks pdes embedded their loss functions physicsinformed neural networks are employed function approximators find solutions ricci flow curvature based evolution riemannian metrics general method developed applied real torus validity solution verified comparing time evolution scalar curvature found using standard pde solver which decreases constant value whole manifold we also consider certain solitonic solutions ricci flow equation two real dimensions we create visualisations flow utilising embedding into mathbbr snapshots highly accurate numerical evolution toroidal metric over time are reported we provide guidelines applications methodology problem determining ricci flat calabiyau metrics context string theory long standing problem complex geometry
"Learning Bayesian posteriors with neural networks for gravitational-wave
  inference",General Relativity and Quantum Cosmology,we seek achieve holy grail bayesian inference gravitationalwave astronomy using deeplearning techniques instantly produce posterior pthetad source parameters theta given detector data do so we train deep neural network take input signal noise data set drawn astrophysical sourceparameter prior sampling distribution detector noise output parametrized approximation corresponding posterior we rely compact representation data based reducedorder modeling which we generate efficiently using separate neuralnetwork waveform interpolant chua galley vallisneri phys rev lett our scheme has broad relevance gravitationalwave applications such lowlatency parameter estimation characterizing science returns future experiments source code trained networks are available online httpsgithubcomvallistruebayes
"Denoising Gravitational Waves using Deep Learning with Recurrent
  Denoising Autoencoders",General Relativity and Quantum Cosmology,gravitational wave astronomy rapidly growing field modern astrophysics observations being made frequently ligo detectors gravitational wave signals are often extremely weak data detectors such ligo contaminated nongaussian nonstationary noise often containing transient disturbances which can obscure real signals traditional denoising methods such principal component analysis dictionary learning are not optimal dealing nongaussian noise especially low signaltonoise ratio gravitational wave signals furthermore these methods are computationally expensive large datasets overcome these issues we apply stateoftheart signal processing techniques based recent groundbreaking advancements deep learning denoise gravitational wave signals embedded either gaussian noise real ligo noise we introduce smtdae staired multitimestep denoising autoencoder based sequencetosequence bidirectional longshorttermmemory recurrent neural networks we demonstrate advantages using our unsupervised deep learning approach show after training only using simulated gaussian noise smtdae achieves superior recovery performance gravitational wave signals embedded real nongaussian ligo noise
"Deep Transfer Learning: A new deep learning glitch classification method
  for advanced LIGO",General Relativity and Quantum Cosmology,exquisite sensitivity advanced ligo detectors has enabled detection multiple gravitational wave signals sophisticated design these detectors mitigates effect most types noise however advanced ligo data streams are contaminated numerous artifacts known glitches nongaussian noise transients complex morphologies given their high rate occurrence glitches can lead false coincident detections obscure even mimic gravitational wave signals therefore successfully characterizing removing glitches advanced ligo data utmost importance here we present first application deep transfer learning glitch classification showing knowledge deep learning algorithms trained realworld object recognition can be transferred classifying glitches timeseries based their spectrogram images using gravity spy dataset containing handlabeled multiduration spectrograms obtained real ligo data we demonstrate method enables optimal use very deep convolutional neural networks classification given small training datasets significantly reduces time training networks achieves stateoftheart accuracy above perfect precisionrecall out classes furthermore new types glitches can be classified accurately given few labeled examples technique once trained via transfer learning we show convolutional neural networks can be truncated used excellent feature extractors unsupervised clustering methods identify new classes based their morphology without any labeled examples therefore provides new framework dynamic glitch classification gravitational wave detectors which are expected encounter new types noise they undergo gradual improvements attain design sensitivity
"Genetic-algorithm-optimized neural networks for gravitational wave
  classification",General Relativity and Quantum Cosmology,gravitationalwave detection strategies are based signal analysis technique known matched filtering despite success matched filtering due its computational cost there has been recent interest developing deep convolutional neural networks cnns signal detection designing these networks remains challenge most procedures adopt trial error strategy set hyperparameter values we propose new method hyperparameter optimization based genetic algorithms gas we compare six different ga variants explore different choices gaoptimized fitness score we show ga can discover highquality architectures when initial hyperparameter seed values are far good solution well refining already good networks example when starting architecture proposed george huerta network optimized over dimensional hyperparameter space has fewer trainable parameters while obtaining increase accuracy our test problem using genetic algorithm optimization refine existing network should be especially useful if problem context eg statistical properties noise signal model etc changes one needs rebuild network all our experiments we find ga discovers significantly less complicated networks compared seed network suggesting it can be used prune wasteful network structures while we have restricted our attention cnn classifiers our ga hyperparameter optimization strategy can be applied within other machine learning settings
Detecting anthropogenic cloud perturbations with deep learning,Atmospheric and Oceanic Physics,one most pressing questions climate science effect anthropogenic aerosol earths energy balance aerosols provide seeds which cloud droplets form changes amount aerosol available cloud can change its brightness other physical properties such optical thickness spatial extent clouds play critical role moderating global temperatures small perturbations can lead significant amounts cooling warming uncertainty effect so large it not currently known if it negligible provides large enough cooling largely negate presentday warming co work uses deep convolutional neural networks look two particular perturbations clouds due anthropogenic aerosol assess their properties prevalence providing valuable insights into their climatic effects
Using Machine Learning for Model Physics: an Overview,Atmospheric and Oceanic Physics,overview generic mathematical object mapping introduced its relation model physics parameterization explained machine learning ml tools can be used emulate andor approximate mappings are introduced applications ml emulate existing parameterizations develop new parameterizations ensure physical constraints control accuracy developed applications are described some ml approaches allow developers go beyond standard parameterization paradigm are discussed
"Learning and Dynamical Models for Sub-seasonal Climate Forecasting:
  Comparison and Collaboration",Atmospheric and Oceanic Physics,subseasonal climate forecasting ssf prediction key climate variables such temperature precipitation week month time horizon skillful ssf would have substantial societal value areas such agricultural productivity hydrology water resource management emergency planning extreme events such droughts wildfires despite its societal importance ssf has stayed challenging problem compared both shortterm weather forecasting longterm seasonal forecasting recent studies have shown potential machine learning ml models advance ssf paper first time we perform finegrained comparison suite modern ml models startoftheart physicsbased dynamical models subseasonal experiment subx project ssf western contiguous united states additionally we explore mechanisms enhance ml models using forecasts dynamical models empirical results illustrate average ml models outperform dynamical models while ml models tend be conservatives their forecasts compared subx models further we illustrate ml models make forecasting errors under extreme weather conditions eg cold waves due polar vortex highlighting need separate models extreme events finally we show suitably incorporating dynamical model forecasts inputs ml models can substantially improve forecasting performance ml models ssf dataset constructed work dynamical model predictions code ml models are released along paper benefit broader machine learning community
Deep learning to represent sub-grid processes in climate models,Atmospheric and Oceanic Physics,representation nonlinear subgrid processes especially clouds has been major source uncertainty climate models decades cloudresolving models better represent many these processes can now be run globally but only shortterm simulations most few years because computational limitations here we demonstrate deep learning can be used capture many advantages cloudresolving modeling fraction computational cost we train deep neural network represent all atmospheric subgrid processes climate model learning multiscale model which convection treated explicitly trained neural network then replaces traditional subgrid parameterizations global general circulation model which it freely interacts resolved dynamics surfaceflux scheme prognostic multiyear simulations are stable closely reproduce not only mean climate cloudresolving simulation but also key aspects variability including precipitation extremes equatorial wave spectrum furthermore neural network approximately conserves energy despite not being explicitly instructed finally we show neural network parameterization generalizes new surface forcing patterns but struggles cope temperatures far outside its training manifold our results show feasibility using deep learning climate model parameterization broader context we anticipate datadriven earth system model development could play key role reducing climate prediction uncertainty coming decade
"Increasing the skill of short-term wind speed ensemble forecasts
  combining forecasts and observations via a new dynamic calibration",Atmospheric and Oceanic Physics,all numerical weather prediction models used wind industry need produce their forecasts starting main synoptic hours utc once analysis becomes available sixhour latency time between two consecutive model runs calls strategies fill gap providing new accurate predictions having least hourly frequency done accommodate request frequent accurate fresh information traders system regulators continuously adapt their work strategies here we propose strategy where quasireal time observed wind speed weather model predictions are combined means novel ensemble model output statistics emos strategy success our strategy measured comparisons against observed wind speed synop stations over italy years
"Computing equivariant matrices on homogeneous spaces for Geometric Deep
  Learning and Automorphic Lie Algebras",Representation Theory,we develop elementary method compute spaces equivariant maps homogeneous space gh lie group module group lie group not required be compact more generally we study spaces invariant sections homogeneous vector bundles take special interest case where fibres are algebras these latter cases have natural global algebra structure we classify these automorphic algebras case where homogeneous space has compact stabilisers work has applications theoretical development geometric deep learning also theory automorphic lie algebras
"Whitney extension theorems on symmetric spaces, an example",Representation Theory,whitney introduced problem extending function set points mathbbrn analytic function ambient space article we prove whitney type extension theorems data some homogeneous spaces we use harmonic analysis homogeneous spaces representation theory compact well noncompact reductive groups
"Computing equivariant matrices on homogeneous spaces for Geometric Deep
  Learning and Automorphic Lie Algebras",Representation Theory,we develop elementary method compute spaces equivariant maps homogeneous space gh lie group module group lie group not required be compact more generally we study spaces invariant sections homogeneous vector bundles take special interest case where fibres are algebras these latter cases have natural global algebra structure we classify these automorphic algebras case where homogeneous space has compact stabilisers work has applications theoretical development geometric deep learning also theory automorphic lie algebras
"Computing equivariant matrices on homogeneous spaces for Geometric Deep
  Learning and Automorphic Lie Algebras",Representation Theory,we develop elementary method compute spaces equivariant maps homogeneous space gh lie group module group lie group not required be compact more generally we study spaces invariant sections homogeneous vector bundles take special interest case where fibres are algebras these latter cases have natural global algebra structure we classify these automorphic algebras case where homogeneous space has compact stabilisers work has applications theoretical development geometric deep learning also theory automorphic lie algebras
"Computing equivariant matrices on homogeneous spaces for Geometric Deep
  Learning and Automorphic Lie Algebras",Representation Theory,we develop elementary method compute spaces equivariant maps homogeneous space gh lie group module group lie group not required be compact more generally we study spaces invariant sections homogeneous vector bundles take special interest case where fibres are algebras these latter cases have natural global algebra structure we classify these automorphic algebras case where homogeneous space has compact stabilisers work has applications theoretical development geometric deep learning also theory automorphic lie algebras
"The Honorific Effect: Exploring the Impact of Japanese Linguistic
  Formalities on AI-Generated Physics Explanations",Physics Education,study investigates influence japanese honorifics responses large language models llms when explaining law conservation momentum we analyzed outputs six stateoftheart ai models including variations chatgpt coral gemini using different honorific forms our findings reveal honorifics significantly affect quality consistency formality aigenerated responses demonstrating llms ability interpret adapt social context cues embedded language notable variations were observed across different models some emphasizing historical context derivations while others focused intuitive explanations study highlights potential using honorifics adjust depth complexity aigenerated explanations educational contexts furthermore responsiveness ai models cultural linguistic elements underscores importance considering cultural factors ai development educational applications these results open new avenues research aiassisted education cultural adaptation ai systems significant implications personalizing learning experiences developing culturally sensitive ai tools global education
Advances in apparent conceptual physics reasoning in GPT-4,Physics Education,chatgpt built large language model trained enormous corpus human text emulate human conversation despite lacking any explicit programming regarding laws physics recent work has demonstrated gpt could pass introductory physics course some nominal level register something close minimal understanding newtonian mechanics force concept inventory work replicates those results also demonstrates latest version gpt has reached much higher mark latter context indeed its responses come quite close perfectly demonstrating expertlevel competence few very notable exceptions limitations we briefly comment implications future physics education pedagogy
"The Honorific Effect: Exploring the Impact of Japanese Linguistic
  Formalities on AI-Generated Physics Explanations",Physics Education,study investigates influence japanese honorifics responses large language models llms when explaining law conservation momentum we analyzed outputs six stateoftheart ai models including variations chatgpt coral gemini using different honorific forms our findings reveal honorifics significantly affect quality consistency formality aigenerated responses demonstrating llms ability interpret adapt social context cues embedded language notable variations were observed across different models some emphasizing historical context derivations while others focused intuitive explanations study highlights potential using honorifics adjust depth complexity aigenerated explanations educational contexts furthermore responsiveness ai models cultural linguistic elements underscores importance considering cultural factors ai development educational applications these results open new avenues research aiassisted education cultural adaptation ai systems significant implications personalizing learning experiences developing culturally sensitive ai tools global education
"The Honorific Effect: Exploring the Impact of Japanese Linguistic
  Formalities on AI-Generated Physics Explanations",Physics Education,study investigates influence japanese honorifics responses large language models llms when explaining law conservation momentum we analyzed outputs six stateoftheart ai models including variations chatgpt coral gemini using different honorific forms our findings reveal honorifics significantly affect quality consistency formality aigenerated responses demonstrating llms ability interpret adapt social context cues embedded language notable variations were observed across different models some emphasizing historical context derivations while others focused intuitive explanations study highlights potential using honorifics adjust depth complexity aigenerated explanations educational contexts furthermore responsiveness ai models cultural linguistic elements underscores importance considering cultural factors ai development educational applications these results open new avenues research aiassisted education cultural adaptation ai systems significant implications personalizing learning experiences developing culturally sensitive ai tools global education
Advances in apparent conceptual physics reasoning in GPT-4,Physics Education,chatgpt built large language model trained enormous corpus human text emulate human conversation despite lacking any explicit programming regarding laws physics recent work has demonstrated gpt could pass introductory physics course some nominal level register something close minimal understanding newtonian mechanics force concept inventory work replicates those results also demonstrates latest version gpt has reached much higher mark latter context indeed its responses come quite close perfectly demonstrating expertlevel competence few very notable exceptions limitations we briefly comment implications future physics education pedagogy
Improving Reflexive Surfaces Efficiency with Genetic Algorithms,Instrumentation and Detectors,we propose using genetic algorithm improve efficiency reflexive surfaces devices where receivers position different classic parabolic antenna technique we show we can improve efficiency arapuca photodetector
"Improvement studies on neutron-gamma separation in HPGe detectors by
  using neural networks",Instrumentation and Detectors,neutrons emitted heavyion fusionevaporation hife reactions together gammarays cause unwanted backgrounds gammaray spectra especially nuclear reactions where relativistic ion beams ribs are used these neutrons are serious problem they have be rejected order obtain clearer gammaray peaks study radiation energy three criteria which were previously determined separation between neutron gammarays hpge detectors have been used artificial neural network ann improving decomposition power according preliminary results obtained ann method ratio neutron rejection has been improved factor ratio lost gammarays has been decreased factor
"Automatic trajectory recognition in Active Target Time Projection
  Chambers data by means of hierarchical clustering",Instrumentation and Detectors,automatic reconstruction threedimensional particle tracks active target time projection chambers data can be challenging task especially presence noise article we propose nonparametric algorithm based idea clustering point triplets instead original points we define appropriate distance measure point triplets then apply singlelink hierarchical clustering triplets compared parametric approaches like ransac hough transform new algorithm has advantage potentially finding trajectories even shapes are not known beforehand feature particularly important lowenergy nuclear physics experiments active targets operating inside magnetic field algorithm has been validated using data experiments performed active target time projection chamber developed national superconducting cyclotron laboratory nsclthe results demonstrate capability algorithm identify isolate particle tracks describe nonanalytical trajectories curved tracks vertex detection recall was precision straight tracks vertex detection recall was precision case test set containing only straight linear tracks algorithm performed better than iterative hough transform
"Improvement studies on neutron-gamma separation in HPGe detectors by
  using neural networks",Instrumentation and Detectors,neutrons emitted heavyion fusionevaporation hife reactions together gammarays cause unwanted backgrounds gammaray spectra especially nuclear reactions where relativistic ion beams ribs are used these neutrons are serious problem they have be rejected order obtain clearer gammaray peaks study radiation energy three criteria which were previously determined separation between neutron gammarays hpge detectors have been used artificial neural network ann improving decomposition power according preliminary results obtained ann method ratio neutron rejection has been improved factor ratio lost gammarays has been decreased factor
"Improvement studies on neutron-gamma separation in HPGe detectors by
  using neural networks",Instrumentation and Detectors,neutrons emitted heavyion fusionevaporation hife reactions together gammarays cause unwanted backgrounds gammaray spectra especially nuclear reactions where relativistic ion beams ribs are used these neutrons are serious problem they have be rejected order obtain clearer gammaray peaks study radiation energy three criteria which were previously determined separation between neutron gammarays hpge detectors have been used artificial neural network ann improving decomposition power according preliminary results obtained ann method ratio neutron rejection has been improved factor ratio lost gammarays has been decreased factor
"Physics-informed machine learning for composition-process-property alloy
  design: shape memory alloy demonstration",Materials Science (Condensed Matter),machine learning ml shown predict new alloys their performances high dimensional multipletargetproperty design space considers chemistry multistep processing routes characterization methodology variations physicsinformed featured engineering approach shown enable otherwise poorly performing ml models perform well same data specifically previously engineered elemental features based alloy chemistries are combined newly engineered heat treatment process features new features result first transforming heat treatment parameter data it was previously recorded using nonlinear mathematical relationships known describe thermodynamics kinetics phase transformations alloys ability ml model be used predictive design validated using blind predictions composition process property relationships thermal hysteresis shape memory alloys smas complex microstructures created via multiple meltinghomogenizationsolutionizationprecipitation processing stage variations are captured addition mean transformation temperatures smas quantitative models hysteresis exhibited such highly processed alloys demonstrate ability ml models design physical complexities have challenged physicsbased modeling approaches decades
Materials science in the era of large language models: a perspective,Materials Science (Condensed Matter),large language models llms have garnered considerable interest due their impressive natural language capabilities which conjunction various emergent properties make them versatile tools workflows ranging complex code generation heuristic finding combinatorial problems paper we offer perspective their applicability materials science research arguing their ability handle ambiguous requirements across range tasks disciplines mean they could be powerful tool aid researchers we qualitatively examine basic llm theory connecting it relevant properties techniques literature before providing two case studies demonstrate their use task automation knowledge extraction atscale their current stage development we argue llms should be viewed less oracles novel insight more tireless workers can accelerate unify exploration across domains it our hope paper can familiarise material science researchers concepts needed leverage these tools their own research
"ABO3 Perovskites' Formability Prediction and Crystal Structure
  Classification using Machine Learning",Materials Science (Condensed Matter),renewable energy sources are great interest combat global warming yet promising sources like photovoltaic pv cells are not efficient cheap enough act alternative traditional energy sources perovskite has high potential pv material but engineering right material specific application often lengthy process paper abo type perovskites formability predicted its crystal structure classified using machine learning high accuracy which provides fast screening process although study was done solarcell application mind prediction framework generic enough be used other purposes formability perovskite predicted its crystal structure classified accuracy respectively using random forest after fold crossvalidation our machine learning model may aid accelerated development desired perovskite structure providing quick mechanism get insight into materials properties advance
"Towards explainable message passing networks for predicting carbon
  dioxide adsorption in metal-organic frameworks",Materials Science (Condensed Matter),metalorganic framework mofs are nanoporous materials could be used capture carbon dioxide exhaust gas fossil fuel power plants mitigate climate change work we design train message passing neural network mpnn predict simulated co adsorption mofs towards providing insights into what substructures mofs are important prediction we introduce soft attention mechanism into readout function quantifies contributions node representations towards graph representations we investigate different mechanisms sparse attention ensure only most relevant substructures are identified
"Illuminating the property space in crystal structure prediction using
  Quality-Diversity algorithms",Materials Science (Condensed Matter),identification materials exceptional properties essential objective enable technological progress we propose application textitqualitydiversity algorithms field crystal structure prediction objective these algorithms identify diverse set highperforming solutions which has been successful range fields such robotics architecture aeronautical engineering these methods rely high number evaluations we employ machinelearning surrogate models compute interatomic potential material properties are used guide optimisation consequently we also show value using neural networks model crystal properties enable identification novel compositionstructure combinations work we specifically study application mapelites algorithm predict polymorphs tio we rediscover known ground state addition set other polymorphs distinct properties we validate our method sio sic systems where we show algorithm can uncover multiple local minima distinct electronic mechanical properties
"Population-based Optimization for Kinetic Parameter Identification in
  Glycolytic Pathway in Saccharomyces cerevisiae",Biomolecules,models systems biology are mathematical descriptions biological processes are used answer questions gain better understanding biological phenomena dynamic models represent network through rates production consumption individual species ordinary differential equations describe rates reactions model include set parameters parameters are important quantities understand analyze biological systems moreover perturbation kinetic parameters are correlated upregulation system cellintrinsic cellextrinsic factors including mutations environment changes here we aim using wellestablished models biological pathways identify parameter values point their potential perturbationdeviation we present our populationbased optimization framework able identify kinetic parameters dynamic model based only input output data ie timecourses selected metabolites our approach can deal identification nonmeasurable parameters well discovering deviation parameters we present our proposed optimization framework example wellstudied glycolytic pathway saccharomyces cerevisiae
Seq-SetNet: Exploring Sequence Sets for Inferring Structures,Biomolecules,sequence set widelyused type data source large variety fields typical example protein structure prediction which takes multiple sequence alignment msa input aims infer structural information it almost all existing approaches exploit msas indirect fashion ie they transform msas into positionspecific scoring matrices pssm represent distribution amino acid types each column pssm could capture columnwise characteristics msa however columnwise characteristics embedded each individual component sequence were nearly totally neglected drawback pssm rooted fact msa essentially unordered sequence set rather than matrix specifically interchange any two sequences will not affect whole msa contrast pixels image essentially form matrix since any two rows pixels cannot be interchanged therefore traditional deep neural networks designed image processing cannot be directly applied sequence sets here we proposed novel deep neural network framework called seqsetnet sequence set processing employing it symmetric function module integrate features calculated preceding layers seqsetnet are immune order sequences input msa advantage enables us directly fully exploit msas considering each component protein individually we evaluated seqsetnet using it extract structural information msa protein secondary structure prediction experimental results popular benchmark sets suggests seqsetnet outperforms stateoftheart approaches precision these results clearly suggest advantages seqsetnet sequence set processing it can be readily used wide range fields say natural language processing
Folding membrane proteins by deep transfer learning,Biomolecules,computational elucidation membrane protein mp structures challenging partially due lack sufficient solved structures homology modeling here we describe highthroughput deep transfer learning method first predicts mp contacts learning nonmembrane proteins nonmps then predicting threedimensional structure models using predicted contacts distance restraints tested nonredundant mps our method has contact prediction accuracy least better than existing methods predicts correct folds mps tmscore least generates threedimensional models rmsd less than angstrom angstrom mps respectively rigorous blind test continuous automated model evaluation cameo project shows our method predicted highresolution threedimensional models two recent test mps residues rmsd close angstrom we estimated our method could predict correct folds between reviewed human multipass mps including few hundred new folds which shall facilitate discovery drugs targeting membrane proteins
"Molecule optimization via multi-objective evolutionary in implicit
  chemical space",Biomolecules,machine learning methods have been used accelerate molecule optimization process however efficient search optimized molecules satisfying several properties scarce labeled data remains challenge machine learning molecule optimization study we propose momo multiobjective molecule optimization framework address challenge combining learning chemical knowledge paretobased multiobjective evolutionary search learn chemistry it employs selfsupervised codec construct implicit chemical space acquire continues representation molecules explore established chemical space momo uses multiobjective evolution comprehensively efficiently search similar molecules multiple desirable properties we demonstrate high performance momo four multiobjective property similarity optimization tasks illustrate search capability momo through case studies remarkably our approach significantly outperforms previous approaches optimizing three objectives simultaneously results show optimization capability momo suggesting improve success rate lead molecule optimization
"DeepFoldit -- A Deep Reinforcement Learning Neural Network Folding
  Proteins",Biomolecules,despite considerable progress ab initio protein structure prediction remains suboptimal crowdsourcing approach online puzzle video game foldit provided several useful results matched even outperformed algorithmically computed solutions using foldit wefold crowd had several successful participations critical assessment techniques protein structure prediction based recent foldit standalone version we trained deep reinforcement neural network called deepfoldit improve score assigned unfolded protein using qlearning method experience replay paper focused model improvement through hyperparameter tuning we examined various implementations examining different model architectures changing hyperparameter values improve accuracy model new model hyperparameters also improved its ability generalize initial results latest implementation show given set small unfolded training proteins deepfoldit learns action sequences improve score both training set novel test proteins our approach combines intuitive user interface foldit efficiency deep reinforcement learning
"Identifying Entangled Physics Relationships through Sparse Matrix
  Decomposition to Inform Plasma Fusion Design",Plasma Physics,sustainable burn platform through inertial confinement fusion icf has been ongoing challenge over years mitigating engineering limitations improving current design involves understanding complex coupling physical processes while sophisticated simulations codes are used model icf implosions these tools contain necessary numerical approximation but miss physical processes limit predictive capability identification relationships between controllable design inputs icf experiments measurable outcomes eg yield shape performed experiments can help guide future design experiments development simulation codes potentially improve accuracy computational models used simulate icf experiments we use sparse matrix decomposition methods identify clusters few related design variables sparse principal component analysis spca identifies groupings are related physical origin variables laser hohlraum capsule variable importance analysis finds addition variables highly correlated neutron yield such picket power laser energy variables represent dramatic change icf design such number pulse steps are also very important obtained sparse components are then used train random forest rf surrogate predicting total yield rf performance training testing data compares performance rf surrogate trained using all design variables considered work intended inform design changes future icf experiments augmenting expert intuition simulations results
"Robust Regression for Automatic Fusion Plasma Analysis based on
  Generative Modeling",Plasma Physics,first step realize automatic experimental data analysis fusion plasma experiments fitting noisy data temperature density spatial profiles which are obtained routinely however it has been difficult construct algorithms fit all data without over underfitting paper we show difficulty originates lack knowledge probability distribution measurement data follow we demonstrate use machine learning technique estimate data distribution construct optimal generative model we show fitting algorithm based generative modeling outperforms classical heuristic methods terms stability well accuracy
"Deep convolutional neural networks for multi-scale time-series
  classification and application to disruption prediction in fusion devices",Plasma Physics,multiscale mutliphysics nature fusion plasmas makes predicting plasma events challenging recent advances deep convolutional neural network architectures cnn utilizing dilated convolutions enable accurate predictions sequences which have longrange multiscale characteristics such timeseries generated diagnostic instruments observing fusion plasmas here we apply neural network architecture popular problem disruption prediction fusion tokamaks utilizing raw data single diagnostic electron cyclotron emission imaging ecei diagnostic diiid tokamak ecei measures fundamental plasma quantity electron temperature high temporal resolution over entire plasma discharge making it sensitive number potential predisruptions markers different temporal spatial scales promising initial disruption prediction results are obtained training deep cnn large receptive field achieving fscore individual timeslices using only ecei data
"Identifying Entangled Physics Relationships through Sparse Matrix
  Decomposition to Inform Plasma Fusion Design",Plasma Physics,sustainable burn platform through inertial confinement fusion icf has been ongoing challenge over years mitigating engineering limitations improving current design involves understanding complex coupling physical processes while sophisticated simulations codes are used model icf implosions these tools contain necessary numerical approximation but miss physical processes limit predictive capability identification relationships between controllable design inputs icf experiments measurable outcomes eg yield shape performed experiments can help guide future design experiments development simulation codes potentially improve accuracy computational models used simulate icf experiments we use sparse matrix decomposition methods identify clusters few related design variables sparse principal component analysis spca identifies groupings are related physical origin variables laser hohlraum capsule variable importance analysis finds addition variables highly correlated neutron yield such picket power laser energy variables represent dramatic change icf design such number pulse steps are also very important obtained sparse components are then used train random forest rf surrogate predicting total yield rf performance training testing data compares performance rf surrogate trained using all design variables considered work intended inform design changes future icf experiments augmenting expert intuition simulations results
"Deep neural network Grad-Shafranov solver constrained with measured
  magnetic signals",Plasma Physics,neural network solving gradshafranov equation constrained measured magnetic signals reconstruct magnetic equilibria real time developed database created optimize neural networks free parameters contain offline efit results output network kstar experimental discharges two different campaigns input data network constitute magnetic signals measured rogowski coil plasma current magnetic pickup coils normal tangential components magnetic fields flux loops poloidal magnetic fluxes developed neural networks fully reconstruct not only poloidal flux function psileft zright but also toroidal current density function jphileft zright offline efit quality preserve robustness networks against few missing input data imputation scheme utilized eliminate required additional training sets large number possible combinations missing inputs
"Deep Portfolio Optimization via Distributional Prediction of Residual
  Factors",Portfolio Management,recent developments deep learning techniques have motivated intensive research machine learningaided stock trading strategies however since financial market has highly nonstationary nature hindering application typical datahungry machine learning methods leveraging financial inductive biases important ensure better sample efficiency robustness study we propose novel method constructing portfolio based predicting distribution financial quantity called residual factors which known be generally useful hedging risk exposure common market factors key technical ingredients are twofold first we introduce computationally efficient extraction method residual information which can be easily combined various prediction algorithms second we propose novel neural network architecture allows us incorporate widely acknowledged financial inductive biases such amplitude invariance timescale invariance we demonstrate efficacy our method us japanese stock market data through ablation experiments we also verify each individual technique contributes improving performance trading strategies we anticipate our techniques may have wide applications various financial problems
Portfolio Optimization for Cointelated Pairs: SDEs vs. Machine Learning,Portfolio Management,recent rise machine learning candidate partially replace classic financial mathematics methodologies we investigate performances both solving problem dynamic portfolio optimization continuoustime finitehorizon setting portfolio two assets are intertwined financial mathematics approach we model asset prices not via common approaches used pairs trading such high correlation cointegration but cointelation model aims reconcile both shortterm risk longterm equilibrium we maximize overall pl financial mathematics approach dynamically switches between meanvariance optimal strategy power utility maximizing strategy we use stochastic control formulation problem power utility maximization solve numerically resulting hjb equation deep galerkin method we turn machine learning same pl maximization problem use clustering analysis devise bands combined inband optimization although approach model agnostic results obtained data simulated same cointelation model fm give edge ml
Metaheuristic Approach to Solve Portfolio Selection Problem,Portfolio Management,paper heuristic method based tabusearch tokenring search being used order solve portfolio optimization problem seminal meanvariance model markowitz being considered addition cardinality quantity constraints better capture dynamics trading procedure model becomes nphard problem can not be solved using exact method combination three different neighborhood relations being explored tabu search addition new constructive method initial solution proposed finally show how proposed techniques perform public benchmarks
"Financial Portfolio Optimization: Computationally guided agents to
  investigate, analyse and invest!?",Portfolio Management,financial portfolio optimization widely studied problem mathematics statistics financial computational literature it adheres determining optimal combination weights associated financial assets held portfolio practice it faces challenges virtue varying math formulations parameters business constraints complex financial instruments empirical nature data no longer onesided thereby reflecting upside downside trends repeated yet unidentifiable cyclic behaviours potentially caused due high frequency volatile movements asset trades portfolio optimization under such circumstances theoretically computationally challenging work presents novel mechanism reach optimal solution encoding variety optimal solutions solution bank guide search process global investment objective formulation it conceptualizes role individual solver agents contribute optimal solutions bank solutions superagent solver learns solution bank thus reflects knowledgebased computationally guided agents approach investigate analyse reach optimal solution informed investment decisions conceptual understanding classes solver agents represent varying problem formulations mathematically oriented deterministic solvers along stochasticsearch driven evolutionary swarmintelligence based techniques optimal weights are discussed algorithmic implementation presented enhanced neighbourhood generation mechanism simulated annealing algorithm framework inclusion heuristic knowledge human expertise financial literature related investment decision making process reflected via introduction controlled perturbation strategies using decision matrix neighbourhood generation
Reinforcement Learning for Portfolio Management,Portfolio Management,thesis we develop comprehensive account expressive power modelling efficiency performance advantages socalled trading agents ie deep soft recurrent qnetwork dsrqn mixture score machines msm based both traditional system identification modelbased approach well contextindependent agents modelfree approach analysis provides conclusive support ability modelfree reinforcement learning methods act universal trading agents which are not only capable reducing computational memory complexity owing their linear scaling size universe but also serve generalizing strategies across assets markets regardless trading universe which they have been trained relatively low volume daily returns financial market data addressed via data augmentation generative approach choice pretraining strategies both which are validated against current stateoftheart models rigour risksensitive framework which includes transaction costs considered its performance advantages are demonstrated variety scenarios synthetic timeseries sinusoidal sawtooth chirp waves simulated market series surrogate data based through real market data sp euro stoxx analysis simulations confirm superiority universal modelfree reinforcement learning agents over current portfolio management model asset allocation strategies achieved performance advantage much annualized cumulative returns annualized sharpe ratio
"Deep Learning of the Eddington Tensor in the Core-collapse Supernova
  Simulation",High Energy Astrophysical Phenomena,we trained deep neural networks dnns function neutrino energy density flux fluid velocity reproduce eddington tensor neutrinos obtained our firstprinciples corecollapse supernova ccsn simulations although moment method which one most popular approximations neutrino transport requires closure relation none analytical closure relations commonly employed literature captures all aspects neutrino angular distribution momentum space paper we developed closure relation using dnn takes neutrino energy density flux fluid velocity input eddington tensor output we consider two kinds dnns conventional dnn named componentwise neural network cwnn tensorbasis neural network tbnn we found diagonal component eddington tensor reproduced better dnns than mclosure relation especially low intermediate energies offdiagonal component dnns agree better boltzmann solver than closure large radii comparison between two dnns tbnn has slightly better performance than cwnn new closure relations hand based dnns well reproduce eddington tensor much smaller costs we opened up new possibility moment method
"Identification of 4FGL uncertain sources at Higher Resolutions with
  Inverse Discrete Wavelet Transform",High Energy Astrophysical Phenomena,forthcoming era big astronomical data it burden find out target sources groundbased spacebased telescopes although machine learning ml methods have been extensively utilized address issue incorporation indepth data analysis can significantly enhance efficiency identifying target sources when dealing massive volumes astronomical data work we focused task finding agn candidates identifying bl lacfsrq candidates fgl dr uncertain sources we studied correlations among attributes fgl dr catalogue proposed novel method named fdidwt transform original data transformed dataset characterized lowdimensional featurehighlighted estimation correlation features fractal dimension fd theory multiresolution analysis inverse discrete wavelet transform idwt combining fdidwt method improved lightweight matchboxconvd model we accomplished two missions distinguish active galactic nuclei agns others nonagns fgl dr uncertain sources accuracy namely mission classify blazar candidates uncertain type bcus into bl lacertae objects bl lacs flat spectrum radio quasars fsrqs accuracy namely mission there are agn candidates mission bl lacs candidates fsrq candidates mission were found results show high consistency greater than results previous works addition our method has advantage finding less variable relatively faint sources than ordinary methods
"Deep Learning of the Eddington Tensor in the Core-collapse Supernova
  Simulation",High Energy Astrophysical Phenomena,we trained deep neural networks dnns function neutrino energy density flux fluid velocity reproduce eddington tensor neutrinos obtained our firstprinciples corecollapse supernova ccsn simulations although moment method which one most popular approximations neutrino transport requires closure relation none analytical closure relations commonly employed literature captures all aspects neutrino angular distribution momentum space paper we developed closure relation using dnn takes neutrino energy density flux fluid velocity input eddington tensor output we consider two kinds dnns conventional dnn named componentwise neural network cwnn tensorbasis neural network tbnn we found diagonal component eddington tensor reproduced better dnns than mclosure relation especially low intermediate energies offdiagonal component dnns agree better boltzmann solver than closure large radii comparison between two dnns tbnn has slightly better performance than cwnn new closure relations hand based dnns well reproduce eddington tensor much smaller costs we opened up new possibility moment method
"Deep Learning of the Eddington Tensor in the Core-collapse Supernova
  Simulation",High Energy Astrophysical Phenomena,we trained deep neural networks dnns function neutrino energy density flux fluid velocity reproduce eddington tensor neutrinos obtained our firstprinciples corecollapse supernova ccsn simulations although moment method which one most popular approximations neutrino transport requires closure relation none analytical closure relations commonly employed literature captures all aspects neutrino angular distribution momentum space paper we developed closure relation using dnn takes neutrino energy density flux fluid velocity input eddington tensor output we consider two kinds dnns conventional dnn named componentwise neural network cwnn tensorbasis neural network tbnn we found diagonal component eddington tensor reproduced better dnns than mclosure relation especially low intermediate energies offdiagonal component dnns agree better boltzmann solver than closure large radii comparison between two dnns tbnn has slightly better performance than cwnn new closure relations hand based dnns well reproduce eddington tensor much smaller costs we opened up new possibility moment method
"Identification of 4FGL uncertain sources at Higher Resolutions with
  Inverse Discrete Wavelet Transform",High Energy Astrophysical Phenomena,forthcoming era big astronomical data it burden find out target sources groundbased spacebased telescopes although machine learning ml methods have been extensively utilized address issue incorporation indepth data analysis can significantly enhance efficiency identifying target sources when dealing massive volumes astronomical data work we focused task finding agn candidates identifying bl lacfsrq candidates fgl dr uncertain sources we studied correlations among attributes fgl dr catalogue proposed novel method named fdidwt transform original data transformed dataset characterized lowdimensional featurehighlighted estimation correlation features fractal dimension fd theory multiresolution analysis inverse discrete wavelet transform idwt combining fdidwt method improved lightweight matchboxconvd model we accomplished two missions distinguish active galactic nuclei agns others nonagns fgl dr uncertain sources accuracy namely mission classify blazar candidates uncertain type bcus into bl lacertae objects bl lacs flat spectrum radio quasars fsrqs accuracy namely mission there are agn candidates mission bl lacs candidates fsrq candidates mission were found results show high consistency greater than results previous works addition our method has advantage finding less variable relatively faint sources than ordinary methods
"Polymers for Extreme Conditions Designed Using Syntax-Directed
  Variational Autoencoders",Soft Condensed Matter,designdiscovery new materials highly nontrivial owing nearinfinite possibilities material candidates multiple required propertyperformance objectives thus machine learning tools are now commonly employed virtually screen material candidates desired properties learning theoretical mapping materialtoproperty space referred emphforward problem however approach inefficient severely constrained candidates human imagination can conceive thus work polymers we tackle materials discovery challenge solving emphinverse problem directly generating candidates satisfy desired propertyperformance objectives we utilize syntaxdirected variational autoencoders vae tandem gaussian process regression gpr models discover polymers expected be robust under three extreme conditions high temperatures high electric field high temperature emphand high electric field useful critical structural electrical energy storage applications approach learn augment human ingenuity general can be extended discover polymers other targeted properties performance measures
"Sparse Regression for Discovery of Constitutive Models from Oscillatory
  Shear Measurements",Soft Condensed Matter,we propose sparse regression alternative neural networks discovery parsimonious constitutive models cms oscillatory shear experiments symmetry frameinvariance are strictly imposed using tensor basis functions isolate describe unknown nonlinear terms cms we generate synthetic experimental data using giesekus phanthien tanner cms consider two different scenarios complete information scenario we assume shear stress along first second normal stress differences measured leads sparse linear regression problem can be solved efficiently using regularization partial information scenario we assume only shear stress data available leads more challenging sparse nonlinear regression problem which we propose greedy twostage algorithm both scenarios proposed methods fit interpolate training data remarkably well predictions inferred cms extrapolate satisfactorily beyond range training data oscillatory shear they also extrapolate reasonably well flow conditions like startup steady uniaxial extension are not used identification cms we discuss ramifications experimental design potential algorithmic improvements implications nonuniqueness cms inferred partial information
Polymer Informatics: Current Status and Critical Next Steps,Soft Condensed Matter,artificial intelligence ai based approaches are beginning impact several domains human life science technology polymer informatics one such domain where ai machine learning ml tools are being used efficient development design discovery polymers surrogate models are trained available polymer data instant property prediction allowing screening promising polymer candidates specific target property requirements questions regarding synthesizability potential retrosynthesis steps create target polymer are being explored using statistical means datadriven strategies tackle unique challenges resulting extraordinary chemical physical diversity polymers small large scales are being explored other major hurdles polymer informatics are lack widespread availability curated organized data approaches create machinereadable representations capture not just structure complex polymeric situations but also synthesis processing conditions methods solve inverse problems wherein polymer recommendations are made using advanced ai algorithms meet application targets are being investigated various parts burgeoning polymer informatics ecosystem mature become integrated efficiency improvements accelerated discoveries increased productivity can result here we review emergent components polymer informatics ecosystem discuss imminent challenges opportunities
"Sparse Regression for Discovery of Constitutive Models from Oscillatory
  Shear Measurements",Soft Condensed Matter,we propose sparse regression alternative neural networks discovery parsimonious constitutive models cms oscillatory shear experiments symmetry frameinvariance are strictly imposed using tensor basis functions isolate describe unknown nonlinear terms cms we generate synthetic experimental data using giesekus phanthien tanner cms consider two different scenarios complete information scenario we assume shear stress along first second normal stress differences measured leads sparse linear regression problem can be solved efficiently using regularization partial information scenario we assume only shear stress data available leads more challenging sparse nonlinear regression problem which we propose greedy twostage algorithm both scenarios proposed methods fit interpolate training data remarkably well predictions inferred cms extrapolate satisfactorily beyond range training data oscillatory shear they also extrapolate reasonably well flow conditions like startup steady uniaxial extension are not used identification cms we discuss ramifications experimental design potential algorithmic improvements implications nonuniqueness cms inferred partial information
"Sparse Regression for Discovery of Constitutive Models from Oscillatory
  Shear Measurements",Soft Condensed Matter,we propose sparse regression alternative neural networks discovery parsimonious constitutive models cms oscillatory shear experiments symmetry frameinvariance are strictly imposed using tensor basis functions isolate describe unknown nonlinear terms cms we generate synthetic experimental data using giesekus phanthien tanner cms consider two different scenarios complete information scenario we assume shear stress along first second normal stress differences measured leads sparse linear regression problem can be solved efficiently using regularization partial information scenario we assume only shear stress data available leads more challenging sparse nonlinear regression problem which we propose greedy twostage algorithm both scenarios proposed methods fit interpolate training data remarkably well predictions inferred cms extrapolate satisfactorily beyond range training data oscillatory shear they also extrapolate reasonably well flow conditions like startup steady uniaxial extension are not used identification cms we discuss ramifications experimental design potential algorithmic improvements implications nonuniqueness cms inferred partial information
"Deep learning for size-agnostic inverse design of random-network 3D
  printed mechanical metamaterials",Applied Physics,practical applications mechanical metamaterials often involve solving inverse problems where objective find multiple microarchitectures give rise given set properties limited resolution additive manufacturing techniques often requires solving such inverse problems specific sizes one should therefore find multiple microarchitectural designs exhibit desired properties specimen given dimensions moreover candidate microarchitectures should be resistant fatigue fracture meaning peak stresses should be minimized well such multiobjective inverse design problem formidably difficult solve but its solution key realworld applications mechanical metamaterials here we propose modular approach titled deepdram combines four decoupled models including two deep learning models dlm deep generative model dgm based conditional variational autoencoders cvae direct finite element fe simulations deepdram deep learning design randomnetwork metamaterials integrates these models into unified framework capable finding many solutions multiobjective inverse design problem posed here integrated framework first introduces desired elastic properties dgm which returns set candidate designs candidate designs together target specimen dimensions are then passed dlm which predicts their actual elastic properties considering specimen size after filtering step based closeness actual properties desired ones last step uses direct fe simulations identify designs minimum peak stresses
"Development of Use-specific High Performance Cyber-Nanomaterial Optical
  Detectors by Effective Choice of Machine Learning Algorithms",Applied Physics,due their inherent variabilitiesnanomaterialbased sensors are challenging translate into realworld applicationswhere reliabilityreproducibility keyrecently we showed bayesian inference can be employed engineered variability layered nanomaterialbased optical transmission filters determine optical wavelengths high accuracyprecisionin many practical applications sensing costspeed longterm reliability can be equal more important considerationsthough various machine learning tools are frequently used sensordetector networks address thesenonetheless their effectiveness nanomaterialbased sensors has not been exploredhere we show best choice ml algorithm cybernanomaterial detector mainly determined specific use considerationsegaccuracy computational costspeed resilience against driftsageing effectswhen sufficient datacomputing resources are providedhighest sensing accuracy can be achieved knn bayesian inference algorithmsbut but can be computationally expensive realtime applicationsin contrastartificial neural networks are computationally expensive trainbut provide fastest result under testing conditions remain reasonably accuratewhen data limitedsvms perform well even small training setswhile other algorithms show considerable reduction accuracy if data scarcehencesetting lower limit size required training datawe show trackingmodeling longterm drifts detector performance over large year periodit possible improve predictive accuracy no need recalibrationour research shows first time if ml algorithm chosen specific usecaselowcost solutionprocessed cybernanomaterial detectors can be practically implemented under diverse operational requirementsdespite their inherent variabilities
Fabry-Perot Lasers as Enablers for Parallel Reservoir Computing,Applied Physics,we introduce use fabryperot fp lasers potential neuromorphic computing machines parallel processing capabilities use optical injection between master fp laser slave fp laser under feedback we demonstrate potential scaling up processing power longitudinal mode granularity perform realtime processing signal equalization gbaud intensity modulation direct detection optical communication systems we demonstrate improvement classification performance number nodes increases capability simultaneous processing arbitrary data streams extensive numerical simulations show up longitudinal modes typical fabryperot lasers can be leveraged so enhance classification performance
"Comparing domain wall synapse with other Non Volatile Memory devices for
  on-chip learning in Analog Hardware Neural Network",Applied Physics,resistive random access memory rram phase change memory pcm devices have been popularly used synapses crossbar array based analog neural network nn circuit achieve more energy time efficient data classification compared conventional computers here we demonstrate advantages recently proposed spin orbit torque driven domain wall dw device synapse compared rram pcm devices respect onchip learning training hardware such nn synaptic characteristic dw synapse obtained us micromagnetic modeling turns out be much more linear symmetric between positive negative update than rram pcm synapse makes design peripheral analog circuits onchip learning much easier dw synapse based nn compared rram pcm synapses we next incorporate dw synapse veriloga model crossbar array based nn circuit we design spice circuit simulator successful onchip learning demonstrated through spice simulations popular fishers iris dataset time energy required learning turn out be orders magnitude lower dw synapse based nn circuit compared rram pcm synapse based nn circuits
"Tomographic Reconstruction of Triaxial Strain Fields from Bragg-Edge
  Neutron Imaging",Applied Physics,paper presents proofofconcept demonstration triaxial strain tomography braggedge neutron imaging within threedimensional sample braggedge neutron transmission can provide highresolution images average through thickness strain within polycrystalline material poses associated rich tomography problem which seeks reconstruct full triaxial strain field these images presented demonstration important step towards solving problem towards technique capable studying residual strain stress within engineering components gaussian process based approach used ensures reconstruction satisfies equilibrium known boundary conditions approach demonstrated experimentally nontrivial steel sample use raden instrument japan proton accelerator research complex validation reconstruction provided comparison conventional strain scans kowari constantwavelength strain diffractometer australian nuclear science technology organisation simulations via finite element analysis
Interval-valued fuzzy soft $β$-covering approximation spaces,General Mathematics,concept intervalvalued fuzzy soft betacovering approximation spaces ifsbetacass introduced combine theories soft sets rough sets intervalvalued fuzzy sets some fundamental propositions concerning intervalvalued fuzzy soft betaneighborhoods soft betaneighborhoods ifsbetacass are explored then four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are researched finally relationships four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are investigated
Interval-valued fuzzy soft $β$-covering approximation spaces,General Mathematics,concept intervalvalued fuzzy soft betacovering approximation spaces ifsbetacass introduced combine theories soft sets rough sets intervalvalued fuzzy sets some fundamental propositions concerning intervalvalued fuzzy soft betaneighborhoods soft betaneighborhoods ifsbetacass are explored then four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are researched finally relationships four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are investigated
Interval-valued fuzzy soft $β$-covering approximation spaces,General Mathematics,concept intervalvalued fuzzy soft betacovering approximation spaces ifsbetacass introduced combine theories soft sets rough sets intervalvalued fuzzy sets some fundamental propositions concerning intervalvalued fuzzy soft betaneighborhoods soft betaneighborhoods ifsbetacass are explored then four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are researched finally relationships four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are investigated
Interval-valued fuzzy soft $β$-covering approximation spaces,General Mathematics,concept intervalvalued fuzzy soft betacovering approximation spaces ifsbetacass introduced combine theories soft sets rough sets intervalvalued fuzzy sets some fundamental propositions concerning intervalvalued fuzzy soft betaneighborhoods soft betaneighborhoods ifsbetacass are explored then four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are researched finally relationships four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are investigated
Interval-valued fuzzy soft $β$-covering approximation spaces,General Mathematics,concept intervalvalued fuzzy soft betacovering approximation spaces ifsbetacass introduced combine theories soft sets rough sets intervalvalued fuzzy sets some fundamental propositions concerning intervalvalued fuzzy soft betaneighborhoods soft betaneighborhoods ifsbetacass are explored then four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are researched finally relationships four kinds intervalvalued fuzzy soft betacoverings based fuzzy rough sets are investigated
Monte Carlo wavelets: a randomized approach to frame discretization,Functional Analysis,paper we propose study family continuous wavelets general domains corresponding stochastic discretization we call monte carlo wavelets first using tools theory reproducing kernel hilbert spaces associated integral operators we define family continuous wavelets spectral calculus then we propose stochastic discretization based monte carlo estimates integral operators using concentration measure results we establish convergence such discretization derive convergence rates under natural regularity assumptions
"Composition operators on reproducing kernel Hilbert spaces with analytic
  positive definite functions",Functional Analysis,paper we specify what functions induce bounded composition operators reproducing kernel hilbert space rkhs associated analytic positive definite function defined mathbfrd we prove only affine transforms can do so pretty large class rkhs our result covers not only paleywiener space real line studied previous works but also much more general rkhss corresponding analytic positive definite functions where existing methods do not work our method only relies intrinsic properties rkhss we establish connection between behavior composition operators asymptotic properties greatest zeros orthogonal polynomials weighted lspaces real line we also investigate compactness composition operators show any bounded composition operators cannot be compact our situation
"Singular Value Decomposition of Operators on Reproducing Kernel Hilbert
  Spaces",Functional Analysis,reproducing kernel hilbert spaces rkhss play important role many statistics machine learning applications ranging support vector machines gaussian processes kernel embeddings distributions operators acting such spaces are instance required embed conditional probability distributions order implement kernel bayes rule build sequential data models it was recently shown transfer operators such perronfrobenius koopman operator can also be approximated similar fashion using covariance crosscovariance operators eigenfunctions these operators can be obtained solving associated matrix eigenvalue problems goal paper provide solid functional analytic foundation eigenvalue decomposition rkhs operators extend approach singular value decomposition results are illustrated simple guiding examples
"Construction and Monte Carlo estimation of wavelet frames generated by a
  reproducing kernel",Functional Analysis,we introduce construction multiscale tight frames general domains frame elements are obtained spectral filtering integral operator associated reproducing kernel our construction extends classical wavelets well generalized wavelets both continuous discrete noneuclidean structures such riemannian manifolds weighted graphs moreover it allows study relation between continuous discrete frames random sampling regime where discrete frames can be seen monte carlo estimates continuous ones pairing spectral regularization learning theory we show sample frame tends its population counterpart derive explicit finitesample rates spaces sobolev besov regularity our results prove stability frames constructed empirical data sense all stochastic discretizations have same underlying limit regardless set initial training samples
Monte Carlo wavelets: a randomized approach to frame discretization,Functional Analysis,paper we propose study family continuous wavelets general domains corresponding stochastic discretization we call monte carlo wavelets first using tools theory reproducing kernel hilbert spaces associated integral operators we define family continuous wavelets spectral calculus then we propose stochastic discretization based monte carlo estimates integral operators using concentration measure results we establish convergence such discretization derive convergence rates under natural regularity assumptions
Solving and Learning Nonlinear PDEs with Gaussian Processes,Numerical Analysis,we introduce simple rigorous unified framework solving nonlinear partial differential equations pdes solving inverse problems ips involving identification parameters pdes using framework gaussian processes proposed approach provides natural generalization collocation kernel methods nonlinear pdes ips has guaranteed convergence very general class pdes comes equipped path compute error bounds specific pde approximations inherits stateoftheart computational complexity linear solvers dense kernel matrices main idea our method approximate solution given pde maximum posteriori map estimator gaussian process conditioned solving pde finite number collocation points although optimization problem infinitedimensional it can be reduced finitedimensional one introducing additional variables corresponding values derivatives solution collocation points generalizes representer theorem arising gaussian process regression reduced optimization problem has form quadratic objective function subject nonlinear constraints it solved variant gaussnewton method resulting algorithm can be interpreted solving successive linearizations nonlinear pde practice found converge small number iterations wide range pdes most traditional approaches ips interleave parameter updates numerical solution pde our algorithm solves both parameter pde solution simultaneously experiments nonlinear elliptic pdes burgers equation regularized eikonal equation ip permeability identification darcy flow illustrate efficacy scope our framework
"A least-squares method for sparse low rank approximation of multivariate
  functions",Numerical Analysis,paper we propose lowrank approximation method based discrete leastsquares approximation multivariate function random noisyfree observations sparsity inducing regularization techniques are used within classical algorithms lowrank approximation order exploit possible sparsity lowrank approximations sparse lowrank approximations are constructed robust updated greedy algorithm which includes optimal selection regularization parameters approximation ranks using cross validation techniques numerical examples demonstrate capability approximating functions many variables even when very few function evaluations are available thus proving interest proposed algorithm propagation uncertainties through complex computational models
"Solving Allen-Cahn and Cahn-Hilliard Equations using the Adaptive
  Physics Informed Neural Networks",Numerical Analysis,phase field models particular allencahn type cahnhilliard type equations have been widely used investigate interfacial dynamic problems designing accurate efficient stable numerical algorithms solving phase field models has been active field decades paper we focus using deep neural network design automatic numerical solver allencahn cahnhilliard equations proposing improved physics informed neural network pinn though pinn has been embraced investigate many differential equation problems we find direct application pinn solving phasefield equations wont provide accurate solutions many cases thus we propose various techniques add approximation power pinn major contribution paper we propose embrace adaptive idea both space time introduce various sampling strategies such we are able improve efficiency accuracy pinn solving phase field equations addition improved pinn has no restriction explicit form pdes making it applicable wider class pde problems shedding light numerical approximations other pdes general
"Learning Runge-Kutta Integration Schemes for ODE Simulation and
  Identification",Numerical Analysis,deriving analytical solutions ordinary differential equations usually restricted small subset problems numerical techniques are considered inevitably numerical simulation differential equation will then always be distinct true analytical solution efficient integration scheme shall further not only provide trajectory throughout given state but also be derived ensure generated simulation be close analytical one consequently several integration schemes were developed different classes differential equations unfortunately when considering integration complex nonlinear systems well identification nonlinear equations data choice integration scheme often far being trivial paper we propose novel framework learn integration schemes minimize integrationrelated cost function we demonstrate relevance proposed learningbased approach nonlinear equations include quantitative analysis wrt classical stateoftheart integration techniques especially where latter may not apply
"Gamblets for opening the complexity-bottleneck of implicit schemes for
  hyperbolic and parabolic ODEs/PDEs with rough coefficients",Numerical Analysis,implicit schemes are popular methods integration time dependent pdes such hyperbolic parabolic pdes however necessity solve corresponding linear systems each time step constitutes complexity bottleneck their application pdes rough coefficients we present generalization gamblets introduced citeowhadimultigrid enabling resolution these implicit systems nearlinear complexity provide rigorous apriori error bounds resulting numerical approximations hyperbolic parabolic pdes these generalized gamblets induce multiresolution decomposition solution space adapted both underlying hyperbolic parabolic pde system odes resulting space discretization timesteps numerical scheme
The bistable brain: a neuronal model with symbiotic interactions,Chaotic Dynamics,general behavior large complex aggregates elementary components can not be understood nor extrapolated properties few components brain good example type networked systems where some patterns behavior are observed independently topology number coupled units following insight we have studied dynamics different aggregates logistic maps according particular it symbiotic coupling scheme imitates neuronal excitation coupling all these aggregates show some common dynamical properties concretely bistable behavior reported here certain detail thus qualitative relationship neural systems suggested through naive model many such networked logistic maps whose behavior mimics wakingsleeping bistability displayed brain systems due its relevance some regions multistability are determined sketched all these logistic models
Scale-invariance of ruggedness measures in fractal fitness landscapes,Chaotic Dynamics,paper deals using chaos direct trajectories targets analyzes ruggedness fractality resulting fitness landscapes targeting problem formulated dynamic fitness landscape four different chaotic maps generating such landscape are studied using computational approach we analyze properties landscapes quantify their fractal rugged characteristics particular it shown ruggedness measures such correlation length information content are scaleinvariant selfsimilar
"Evolving Chaos: Identifying New Attractors of the Generalised Lorenz
  Family",Chaotic Dynamics,recent paper we presented intelligent evolutionary search technique through genetic programming gp finding new analytical expressions nonlinear dynamical systems similar classical lorenz attractors which also exhibit chaotic behaviour phase space paper we extend our previous finding explore yet another gallery new chaotic attractors which are derived original lorenz system equations compared previous exploration sinusoidal type transcendental nonlinearity here we focus only crossproduct higherpower type nonlinearities three state equations we here report over different structures chaotic attractors along their one set parameter values phase space dynamics largest lyapunov exponents lle expressions these new lorenzlike nonlinear dynamical systems have been automatically evolved through multigene genetic programming mggp past two decades there have been many claims designing new chaotic attractors incremental extension lorenz family we provide here large family chaotic systems whose structure closely resemble original lorenz system but drastically different phase space dynamics advances state art knowledge discovering new chaotic systems which can find application many realworld problems work may also find its archival value future domain new chaotic system discovery
Scale-invariance of ruggedness measures in fractal fitness landscapes,Chaotic Dynamics,paper deals using chaos direct trajectories targets analyzes ruggedness fractality resulting fitness landscapes targeting problem formulated dynamic fitness landscape four different chaotic maps generating such landscape are studied using computational approach we analyze properties landscapes quantify their fractal rugged characteristics particular it shown ruggedness measures such correlation length information content are scaleinvariant selfsimilar
Scale-invariance of ruggedness measures in fractal fitness landscapes,Chaotic Dynamics,paper deals using chaos direct trajectories targets analyzes ruggedness fractality resulting fitness landscapes targeting problem formulated dynamic fitness landscape four different chaotic maps generating such landscape are studied using computational approach we analyze properties landscapes quantify their fractal rugged characteristics particular it shown ruggedness measures such correlation length information content are scaleinvariant selfsimilar
Incorporating Polar Field Data for Improved Solar Flare Prediction,Solar and Stellar Astrophysics,paper we consider incorporating data associated suns north south polar field strengths improve solar flare prediction performance using machine learning models when used supplement local data active regions photospheric magnetic field sun polar field data provides global information predictor while such global features have been previously proposed predicting next solar cycles intensity paper we propose using them help classify individual solar flares we conduct experiments using hmi data employing four different machine learning algorithms can exploit polar field information additionally we propose novel probabilistic mixture experts model can simply effectively incorporate polar field data provide onpar prediction performance stateoftheart solar flare prediction algorithms such recurrent neural network rnn our experimental results indicate usefulness polar field data solar flare prediction which can improve heidke skill score hss much
"Single-Frame Super-Resolution of Solar Magnetograms: Investigating
  Physics-Based Metrics \& Losses",Solar and Stellar Astrophysics,breakthroughs our understanding physical phenomena have traditionally followed improvements instrumentation studies magnetic field sun its influence solar dynamo space weather events have benefited improvements resolution measurement frequency new instruments however order fully understand solar cycle highquality data across timescales longer than typical lifespan solar instrument are required moment discrepancies between measurement surveys prevent combined use all available data work we show machine learning can help bridge gap between measurement surveys learning textbfsuperresolve lowresolution magnetic field images textbftranslate between characteristics contemporary instruments orbit we also introduce notion physicsbased metrics losses superresolution preserve underlying physics constrain solution space possible superresolution outputs
"Estimating activity cycles with probabilistic methods I. Bayesian
  Generalised Lomb-Scargle Periodogram with Trend",Solar and Stellar Astrophysics,period estimation one central topics astronomical time series analysis where data often unevenly sampled especially challenging are studies stellar magnetic cycles there periods looked are order same length than datasets themselves datasets often contain trends origin which either real longterm cycle instrumental effect but these effects cannot be reliably separated while they can lead erroneous period determinations if not properly handled study we aim developing method can handle trends properly performing extensive set testing we show optimal procedure when contrasted methods do not include trend directly model effect form noise whether constant heteroscedastic results also investigated we introduce bayesian generalised lombscargle periodogram trend bglst which probabilistic linear regression model using gaussian priors coefficients uniform prior frequency parameter we show using synthetic data when there no prior information whether what extent true model data contains linear trend introduced bglst method preferable methods which either detrend data leave data untrended before fitting periodic model whether use noise different than constant variance model depends density data sampling well true noise type process
"Interpreting LSTM Prediction on Solar Flare Eruption with Time-series
  Clustering",Solar and Stellar Astrophysics,we conduct post hoc analysis solar flare predictions made long short term memory lstm model employing data form spaceweather hmi active region patches sharp parameters calculated data proximity magnetic polarity inversion line where flares originate we train lstm model binary classification provide prediction score probability mx class flares occur next hour we then develop dimensionreduction technique reduce dimensions sharp parameter lstm inputs demonstrate different patterns sharp parameters corresponding transition low high prediction score our work shows subset sharp parameters contain key signals strong solar flare eruptions are imminent dynamics these parameters have highly uniform trajectory many events whose lstm prediction scores mx class flares transition very low very high results demonstrate existence few threshold values sharp parameters when surpassed indicate high probability eruption strong flare our method has distilled knowledge solar flare eruption learnt deep learning model provides more interpretable approximation which provides physical insight processes driving solar flares
Incorporating Polar Field Data for Improved Solar Flare Prediction,Solar and Stellar Astrophysics,paper we consider incorporating data associated suns north south polar field strengths improve solar flare prediction performance using machine learning models when used supplement local data active regions photospheric magnetic field sun polar field data provides global information predictor while such global features have been previously proposed predicting next solar cycles intensity paper we propose using them help classify individual solar flares we conduct experiments using hmi data employing four different machine learning algorithms can exploit polar field information additionally we propose novel probabilistic mixture experts model can simply effectively incorporate polar field data provide onpar prediction performance stateoftheart solar flare prediction algorithms such recurrent neural network rnn our experimental results indicate usefulness polar field data solar flare prediction which can improve heidke skill score hss much
"Quantized Non-Volatile Nanomagnetic Synapse based Autoencoder for
  Efficient Unsupervised Network Anomaly Detection",Mesoscale and Nanoscale Physics,autoencoder based anomaly detection paradigm implementing autoencoder edge devices capable learning realtime exceedingly challenging due limited hardware energy computational resources we show these limitations can be addressed designing autoencoder lowresolution nonvolatile memorybased synapses employing effective quantized neural network learning algorithm we propose ferromagnetic racetrack engineered notches hosting magnetic domain wall dw autoencoder synapses where limited state state synaptic weights are manipulated spin orbit torque sot current pulses performance anomaly detection proposed autoencoder model evaluated nslkdd dataset limited resolution dw device stochasticity aware training autoencoder performed which yields comparable anomaly detection performance autoencoder having floatingpoint precision weights while limited number quantized states inherent stochastic nature dw synaptic weights nanoscale devices are known negatively impact performance our hardwareaware training algorithm shown leverage these imperfect device characteristics generate improvement anomaly detection accuracy compared accuracy obtained floatingpoint trained weights furthermore our dwbased approach demonstrates remarkable reduction least three orders magnitude weight updates during training compared floatingpoint approach implying substantial energy savings our method work could stimulate development extremely energy efficient nonvolatile multistate synapsebased processors can perform realtime training inference edge unsupervised data
"Accelerate & Actualize: Can 2D Materials Bridge the Gap Between
  Neuromorphic Hardware and the Human Brain?",Mesoscale and Nanoscale Physics,twodimensional materials present exciting opportunity devices systems beyond von neumann computing architecture paradigm due their diversity electronic structure physical properties atomicallythin van der waals structures enable ease integration conventional electronic materials siliconbased hardware all major classes nonvolatile memory nvm devices have been demonstrated using materials including their operation synaptic devices applications neuromorphic computing hardware their atomicallythin structure superior physical properties ie mechanical strength electrical thermal conductivity well gatetunable electronic properties provide performance advantages novel functionality nvm devices systems however device performance variability compared incumbent materials technology remain major concerns real applications ultimately progress materials novel class electronic materials specifically their application area neuromorphic electronics will depend their scalable synthesis thinfilm form desired crystal quality defect density phase purity
"Controllable reset behavior in domain wall-magnetic tunnel junction
  artificial neurons for task-adaptable computation",Mesoscale and Nanoscale Physics,neuromorphic computing spintronic devices has been interest due limitations cmosdriven von neumann computing domain wallmagnetic tunnel junction dwmtj devices have been shown be able intrinsically capture biological neuron behavior edgyrelaxed behavior where frequently firing neuron experiences lower action potential threshold may provide additional artificial neuronal functionality when executing repeated tasks study we demonstrate behavior can be implemented dwmtj artificial neurons via three alternative mechanisms shape anisotropy magnetic field currentdriven soft reset using micromagnetics analytical device modeling classify optdigits handwritten digit dataset we show edgyrelaxed behavior improves both classification accuracy classification rate ordered datasets while sacrificing little no accuracy randomized dataset work establishes methods which artificial spintronic neurons can be flexibly adapted datasets
"Quantized Non-Volatile Nanomagnetic Synapse based Autoencoder for
  Efficient Unsupervised Network Anomaly Detection",Mesoscale and Nanoscale Physics,autoencoder based anomaly detection paradigm implementing autoencoder edge devices capable learning realtime exceedingly challenging due limited hardware energy computational resources we show these limitations can be addressed designing autoencoder lowresolution nonvolatile memorybased synapses employing effective quantized neural network learning algorithm we propose ferromagnetic racetrack engineered notches hosting magnetic domain wall dw autoencoder synapses where limited state state synaptic weights are manipulated spin orbit torque sot current pulses performance anomaly detection proposed autoencoder model evaluated nslkdd dataset limited resolution dw device stochasticity aware training autoencoder performed which yields comparable anomaly detection performance autoencoder having floatingpoint precision weights while limited number quantized states inherent stochastic nature dw synaptic weights nanoscale devices are known negatively impact performance our hardwareaware training algorithm shown leverage these imperfect device characteristics generate improvement anomaly detection accuracy compared accuracy obtained floatingpoint trained weights furthermore our dwbased approach demonstrates remarkable reduction least three orders magnitude weight updates during training compared floatingpoint approach implying substantial energy savings our method work could stimulate development extremely energy efficient nonvolatile multistate synapsebased processors can perform realtime training inference edge unsupervised data
"Shape-Dependent Multi-Weight Magnetic Artificial Synapses for
  Neuromorphic Computing",Mesoscale and Nanoscale Physics,neuromorphic computing artificial synapses provide multiweight conductance state set based inputs neurons analogous brain additional properties synapse beyond multiple weights can be needed can depend application requiring need generating different synapse behaviors same materials here we measure artificial synapses based magnetic materials use magnetic tunnel junction magnetic domain wall fabricating lithographic notches domain wall track underneath single magnetic tunnel junction we achieve stable resistance states can be repeatably controlled electrically using spin orbit torque we analyze effect geometry synapse behavior showing trapezoidal device has asymmetric weight updates high controllability while straight device has higher stochasticity but stable resistance levels device data input into neuromorphic computing simulators show usefulness applicationspecific synaptic functions implementing artificial neural network applied streamed fashionmnist data we show trapezoidal magnetic synapse can be used metaplastic function efficient online learning implementing convolutional neural network cifar image recognition we show straight magnetic synapse achieves nearideal inference accuracy due stability its resistance levels work shows multiweight magnetic synapses are feasible technology neuromorphic computing provides design guidelines emerging artificial synapse technologies
"Metadynamics for Training Neural Network Model Chemistries: a
  Competitive Assessment",Chemical Physics,neural network nn model chemistries mcs promise facilitate accurate exploration chemical space simulation large reactive systems one important path improving these models add layers physical detail especially longrange forces short range however these models are data driven data limited little systematically known about how data should be sampled test data chosen randomly some sampling techniques can provide poor information about generality if sampling method narrow test error can appear encouragingly tiny while model fails catastrophically elsewhere manuscript we competitively evaluate two common sampling methods molecular dynamics md normalmode sampling nms one uncommon alternative metadynamics metamd preparing training geometries we show md inefficient sampling method sense additional samples do not improve generality we also show metamd easily implemented any nnmc software package cost scales linearly number atoms sample molecule metamd blackbox way ensure samples always reach out new regions chemical space while remaining relevant chemistry near kbt it one cheap tool address issue generalization
"Generative Design of Functional Metal Complexes Utilizing the Internal
  Knowledge of Large Language Models",Chemical Physics,designing functional transition metal complexes tmcs faces challenges due vast search space metals ligands requiring efficient optimization strategies traditional genetic algorithms gas are commonly used employing random mutations crossovers driven explicit mathematical objectives explore space transferring knowledge between different ga tasks however difficult we integrate large language models llms into evolutionary optimization framework llmeo apply it both single multiobjective optimization tmcs we find llmeo surpasses traditional gas leveraging chemical knowledge llms gained during their extensive pretraining remarkably without supervised finetuning llms utilize full historical data optimization processes outperforming those focusing only topperforming tmcs llmeo successfully identifies eight top tmcs largest homolumo gaps proposing only candidates out million tmcs space through prompt engineering using natural language llmeo introduces unparalleled flexibility into multiobjective optimizations thereby circumventing necessity intricate mathematical formulations generative models llms can suggest new ligands tmcs unique properties merging both internal knowledge external chemistry data thus combining benefits efficient optimization molecular generation increasing potential llms pretrained foundational models new posttraining inference strategies we foresee broad applications llmbased evolutionary optimization chemistry materials design
"Neural networks and kernel ridge regression for excited states dynamics
  of CH$_2$NH$_2^+$: From single-state to multi-state representations and
  multi-property machine learning models",Chemical Physics,excitedstate dynamics simulations are powerful tool investigate photoinduced reactions molecules materials provide complementary information experiments since applicability these simulation techniques limited costs underlying electronic structure calculations we develop assess different machine learning models task machine learning models are trained emph ab initio calculations excited electronic states using methylenimmonium cation chnh model system prediction excitedstate properties multiple outputs are desirable which straightforward neural networks but less explored kernel ridge regression we overcome challenge kernel ridge regression case energy predictions encoding electronic states explicitly inputs addition molecular representation we adopt strategy also our neural networks comparison such state encoding enables not only kernel ridge regression multiple outputs but leads also more accurate machine learning models statespecific properties important goal excitedstate machine learning models their use dynamics simulations which needs not only statespecific information but also couplings ie properties involving pairs states accordingly we investigate performance different models such coupling elements furthermore we explore how combining all properties single neural network affects accuracy ultimate test our machine learning models we carry out excitedstate dynamics simulations based predicted energies forces couplings thus show scopes possibilities machine learning treatment electronically excited states
Molecular Dynamics with Neural-Network Potentials,Chemical Physics,molecular dynamics simulations are important tool describing evolution chemical system time however these simulations are inherently held back either prohibitive cost accurate electronic structure theory computations limited accuracy classical empirical force fields machine learning techniques can help overcome these limitations providing access potential energies forces other molecular properties modeled directly after electronic structure reference only fraction original computational cost present text discusses several practical aspects conducting machine learning driven molecular dynamics simulations first we study efficient selection reference data points basis active learning inspired adaptive sampling scheme followed analysis machinelearning based model simulating molecular dipole moments framework predicting infrared spectra via molecular dynamics simulations finally we show machine learning models can offer valuable aid understanding chemical systems beyond simple prediction quantities
"Machine Learning Molecular Dynamics for the Simulation of Infrared
  Spectra",Chemical Physics,machine learning has emerged invaluable tool many research areas present work we harness power predict highly accurate molecular infrared spectra unprecedented computational efficiency account vibrational anharmonic dynamical effects typically neglected conventional quantum chemistry approaches we base our machine learning strategy ab initio molecular dynamics simulations while these simulations are usually extremely time consuming even small molecules we overcome these limitations leveraging power variety machine learning techniques not only accelerating simulations several orders magnitude but also greatly extending size systems can be treated end we develop molecular dipole moment model based environment dependent neural network charges combine it neural network potentials behler parrinello contrary prevalent big data philosophy we are able obtain very accurate machine learning models prediction infrared spectra based only few hundreds electronic structure reference points made possible through introduction fully automated sampling scheme use molecular forces during neural network potential training we demonstrate power our machine learning approach applying it model infrared spectra methanol molecule nalkanes containing up atoms protonated alanine tripeptide which same time represents first application machine learning techniques simulate dynamics peptide all these case studies we find excellent agreement between infrared spectra predicted via machine learning models respective theoretical experimental spectra
"Dimensionality Reduction of Complex Metastable Systems via Kernel
  Embeddings of Transition Manifolds",Dynamical Systems,we present novel kernelbased machine learning algorithm identifying lowdimensional geometry effective dynamics highdimensional multiscale stochastic systems recently framework computation optimal reaction coordinates such systems based learning parametrization lowdimensional transition manifold certain function space article we enhance approach embedding learning transition manifold reproducing kernel hilbert space exploiting favorable properties kernel embeddings under mild assumptions kernel manifold structure shown be preserved under embedding distortion bounds can be derived leads more robust more efficient algorithm compared previous parametrization approaches
"Stability Analysis of Fractional Order Memristor Synapse-coupled
  Hopfield Neural Network with Ring Structure",Dynamical Systems,memristor nonlinear twoterminal electrical element incorporates memory features nanoscale properties enabling us design very highdensity artificial neural networks enhance memory property we should use mathematical frameworks like fractional calculus which capable doing so here we first present fractionalorder memristor synapsecoupling hopfield neural network two neurons then extend model neural network ring structure consists subnetwork neurons increasing synchronization network necessary sufficient conditions stability equilibrium points are investigated highlighting dependency stability fractionalorder value number neurons numerical simulations bifurcation analysis along lyapunov exponents are given twoneuron case substantiates theoretical findings suggesting possible routes towards chaos when fractional order system increases nneuron case also it revealed stability depends structure number subnetworks
"Automatic Implementation of Neural Networks through Reaction Networks --
  Part I: Circuit Design and Convergence Analysis",Dynamical Systems,information processing relying biochemical interactions cellular environment essential biological organisms implementation molecular computational systems holds significant interest potential fields synthetic biology molecular computation twopart article aims introduce programmable biochemical reaction network bcrn system endowed mass action kinetics realizes fully connected neural network fcnn has potential act automatically vivo part feedforward propagation computation backpropagation component all bridging processes fcnn are ingeniously designed specific bcrn modules based their dynamics approach addresses design gap biochemical assignment module judgment termination module provides novel precise robust realization bimolecular reactions learning process through equilibrium approaching we demonstrate designed bcrn system achieves fcnn functionality exponential convergence target computational results thereby enhancing theoretical support such work finally performance construction further evaluated two typical logic classification problems
"Eigendecompositions of Transfer Operators in Reproducing Kernel Hilbert
  Spaces",Dynamical Systems,transfer operators such perronfrobenius koopman operator play important role global analysis complex dynamical systems eigenfunctions these operators can be used detect metastable sets project dynamics onto dominant slow processes separate superimposed signals we extend transfer operator theory reproducing kernel hilbert spaces show these operators are related hilbert space representations conditional distributions known conditional mean embeddings machine learning community moreover numerical methods compute empirical estimates these embeddings are akin datadriven methods approximation transfer operators such extended dynamic mode decomposition its variants one main benefit presented kernelbased approaches these methods can be applied any domain where similarity measure given kernel available we illustrate results aid guiding examples highlight potential applications molecular dynamics well video text data analysis
"Data-driven modelling of nonlinear dynamics by barycentric coordinates
  and memory",Dynamical Systems,we present numerical method model dynamical systems data we use recently introduced method scalable probabilistic approximation spa project points euclidean space convex polytopes represent these projected states system new lowerdimensional coordinates denoting their position polytope we then introduce specific nonlinear transformation construct model dynamics polytope transform back into original state space overcome potential loss information projection lowerdimensional polytope we use memory sense delayembedding theorem takens construction our method produces stable models we illustrate capacity method reproduce even chaotic dynamics attractors multiple connected components various examples
"Enzyme promiscuity prediction using hierarchy-informed multi-label
  classification",Cell Behavior,experimental efforts are costly time consuming computational characterization enzyme capabilities attractive alternative we present evaluate several machinelearning models predict which distinct enzymes defined via enzyme commission ec numbers are likely interact given query molecule our data consists enzymesubstrate interactions brenda database some interactions are attributed natural selection involve enzymes natural substrates majority interactions however involve nonnatural substrates thus reflecting promiscuous enzymatic activities we frame enzyme promiscuity prediction problem multilabel classification task we maximally utilize inhibitor unlabelled data train prediction models can take advantage known hierarchical relationships between enzyme classes we report hierarchical multilabel neural network epphmcnf best model solving problem outperforming knearest neighbors similaritybased other machine learning models we show inhibitor information during training consistently improves predictive power particularly epphmcnf we also show all promiscuity prediction models perform worse under realistic data split when compared random data split when evaluating performance nonnatural substrates compared natural substrates we provide python code epphmcnf other models repository termed epp enzyme promiscuity prediction httpsgithubcomhassounlabepp
"Ag-dependent (in silico) approach implies a deterministic kinetics for
  homeostatic memory cell turnover",Cell Behavior,verhulstlike mathematical modeling has been used investigate several complex biological issues such immune memory equilibrium cellmediated immunity mammals regulation mechanisms both these processes are still not sufficiently understood recent paper choo et al immunol pp used agindependent approach quantitatively analyze memory cell turnover some empirical data concluded immune homeostasis behaves stochastically rather than deterministically paper here presented we use silico agdependent approach simulate process antigenic mutation study its implications memory dynamics our results have suggested deterministic kinetics homeostatic equilibrium what contradicts choo et al findings accordingly our calculations are indication more extensive empirical protocol studying homeostatic turnover should be considered
"Enzyme promiscuity prediction using hierarchy-informed multi-label
  classification",Cell Behavior,experimental efforts are costly time consuming computational characterization enzyme capabilities attractive alternative we present evaluate several machinelearning models predict which distinct enzymes defined via enzyme commission ec numbers are likely interact given query molecule our data consists enzymesubstrate interactions brenda database some interactions are attributed natural selection involve enzymes natural substrates majority interactions however involve nonnatural substrates thus reflecting promiscuous enzymatic activities we frame enzyme promiscuity prediction problem multilabel classification task we maximally utilize inhibitor unlabelled data train prediction models can take advantage known hierarchical relationships between enzyme classes we report hierarchical multilabel neural network epphmcnf best model solving problem outperforming knearest neighbors similaritybased other machine learning models we show inhibitor information during training consistently improves predictive power particularly epphmcnf we also show all promiscuity prediction models perform worse under realistic data split when compared random data split when evaluating performance nonnatural substrates compared natural substrates we provide python code epphmcnf other models repository termed epp enzyme promiscuity prediction httpsgithubcomhassounlabepp
"Enzyme promiscuity prediction using hierarchy-informed multi-label
  classification",Cell Behavior,experimental efforts are costly time consuming computational characterization enzyme capabilities attractive alternative we present evaluate several machinelearning models predict which distinct enzymes defined via enzyme commission ec numbers are likely interact given query molecule our data consists enzymesubstrate interactions brenda database some interactions are attributed natural selection involve enzymes natural substrates majority interactions however involve nonnatural substrates thus reflecting promiscuous enzymatic activities we frame enzyme promiscuity prediction problem multilabel classification task we maximally utilize inhibitor unlabelled data train prediction models can take advantage known hierarchical relationships between enzyme classes we report hierarchical multilabel neural network epphmcnf best model solving problem outperforming knearest neighbors similaritybased other machine learning models we show inhibitor information during training consistently improves predictive power particularly epphmcnf we also show all promiscuity prediction models perform worse under realistic data split when compared random data split when evaluating performance nonnatural substrates compared natural substrates we provide python code epphmcnf other models repository termed epp enzyme promiscuity prediction httpsgithubcomhassounlabepp
"Enzyme promiscuity prediction using hierarchy-informed multi-label
  classification",Cell Behavior,experimental efforts are costly time consuming computational characterization enzyme capabilities attractive alternative we present evaluate several machinelearning models predict which distinct enzymes defined via enzyme commission ec numbers are likely interact given query molecule our data consists enzymesubstrate interactions brenda database some interactions are attributed natural selection involve enzymes natural substrates majority interactions however involve nonnatural substrates thus reflecting promiscuous enzymatic activities we frame enzyme promiscuity prediction problem multilabel classification task we maximally utilize inhibitor unlabelled data train prediction models can take advantage known hierarchical relationships between enzyme classes we report hierarchical multilabel neural network epphmcnf best model solving problem outperforming knearest neighbors similaritybased other machine learning models we show inhibitor information during training consistently improves predictive power particularly epphmcnf we also show all promiscuity prediction models perform worse under realistic data split when compared random data split when evaluating performance nonnatural substrates compared natural substrates we provide python code epphmcnf other models repository termed epp enzyme promiscuity prediction httpsgithubcomhassounlabepp
"Machine learning for multiple yield curve markets: fast calibration in
  the Gaussian affine framework",Pricing of Securities,calibration highly challenging task particular multiple yield curve markets paper first attempt study chances challenges application machine learning techniques we employ gaussian process regression machine learning methodology having many similarities extended kalman filtering technique which has been applied many times interest rate markets term structure models we find very good results single curve markets many challenges multi curve markets vasicek framework gaussian process regression implemented adam optimizer nonlinear conjugate gradient method where latter performs best we also point towards future research
Solving optimal stopping problems with Deep Q-Learning,Pricing of Securities,we propose reinforcement learning rl approach model optimal exercise strategies optiontype products we pursue rl avenue order learn optimal actionvalue function underlying stopping problem addition retrieving optimal qfunction any time step one can also price contract inception we first discuss standard setting one exercise right later extend framework case multiple stopping opportunities presence constraints we propose approximate qfunction deep neural network which does not require specification basis functions leastsquares monte carlo framework scalable higher dimensions we derive lower bound option price obtained trained neural network upper bound dual formulation stopping problem which can also be expressed terms qfunction our methodology illustrated examples covering pricing swing options
"Numerical Simulation of Exchange Option with Finite Liquidity:
  Controlled Variate Model",Pricing of Securities,paper we develop numerical pricing methodologies european style exchange options written pair correlated assets market finite liquidity contrast standard multiasset blackscholes framework trading our market model has direct impact assets price price impact incorporated into dynamics first asset through specific trading strategy large trader liquidity model twodimensional milstein scheme implemented simulate pair assets prices option value numerically estimated monte carlo margrabe option controlled variate time complexity these numerical schemes are included finally we provide deep learning framework implement model effectively production environment
"Machine learning for multiple yield curve markets: fast calibration in
  the Gaussian affine framework",Pricing of Securities,calibration highly challenging task particular multiple yield curve markets paper first attempt study chances challenges application machine learning techniques we employ gaussian process regression machine learning methodology having many similarities extended kalman filtering technique which has been applied many times interest rate markets term structure models we find very good results single curve markets many challenges multi curve markets vasicek framework gaussian process regression implemented adam optimizer nonlinear conjugate gradient method where latter performs best we also point towards future research
"A random forest based approach for predicting spreads in the primary
  catastrophe bond market",Pricing of Securities,we introduce random forest approach enable spreads prediction primary catastrophe bond market we investigate whether all information provided investors offering circular prior new issuance equally important predicting its spread whole population nonlife catastrophe bonds issued december may used random forest shows impressive predictive power unseen primary catastrophe bond data explaining total variability comparison linear regression our benchmark model has inferior predictive performance explaining only total variability all details provided offering circular are predictive spread but varying degree stability results studied usage random forest can speed up investment decisions catastrophe bond industry
Fano schemes of generic intersections and machine learning,Algebraic Geometry,we investigate fano schemes conditionally generic intersections ie hypersurfaces projective space chosen generically up additional conditions via correspondence between generic properties algebraic varieties events probability spaces occur probability one we use obtained results fano schemes solve problem machine learning
Tensor decomposition for learning Gaussian mixtures from moments,Algebraic Geometry,data processing machine learning important challenge recover exploit models can represent accurately data we consider problem recovering gaussian mixture models datasets we investigate symmetric tensor decomposition methods tackling problem where tensor built empirical moments data distribution we consider identifiable tensors which have unique decomposition showing moment tensors built spherical gaussian mixtures have property we prove symmetric tensors interpolation degree strictly less than half their order are identifiable we present algorithm based simple linear algebra operations compute their decomposition illustrative experimentations show impact tensor decomposition method recovering gaussian mixtures comparison other stateoftheart approaches
Computational complexity of learning algebraic varieties,Algebraic Geometry,we analyze complexity fitting variety coming class varieties configuration points bbb cn complexity measure called algebraic complexity computes euclidean distance degree eddegree certain variety called hypothesis variety number points configuration increases problem fitting nsphere configuration points bbb cn we give closed formula algebraic complexity hypothesis variety grows case case we conjecture generalization formula supported numerical experiments
Fano schemes of generic intersections and machine learning,Algebraic Geometry,we investigate fano schemes conditionally generic intersections ie hypersurfaces projective space chosen generically up additional conditions via correspondence between generic properties algebraic varieties events probability spaces occur probability one we use obtained results fano schemes solve problem machine learning
Fano schemes of generic intersections and machine learning,Algebraic Geometry,we investigate fano schemes conditionally generic intersections ie hypersurfaces projective space chosen generically up additional conditions via correspondence between generic properties algebraic varieties events probability spaces occur probability one we use obtained results fano schemes solve problem machine learning
Uncertainty Quantification in Working Memory via Moment Neural Networks,Biological Physics,humans possess finely tuned sense uncertainty helps anticipate potential errors vital adaptive behavior survival however underlying neural mechanisms remain unclear study applies moment neural networks mnns explore neural mechanism uncertainty quantification working memory wm mnn captures nonlinear coupling first two moments spiking neural networks snns identifying firing covariance key indicator uncertainty encoded information trained wm task model demonstrates coding precision uncertainty quantification comparable human performance analysis reveals link between probabilistic samplingbased coding uncertainty representation transferring mnns weights snn replicates these results furthermore study provides testable predictions demonstrating how noise heterogeneity enhance wm performance highlighting their beneficial role rather than being mere biological byproducts these findings offer insights into how brain effectively manages uncertainty exceptional accuracy
"High-resolution Markov state models for the dynamics of Trp-cage
  miniprotein constructed over slow folding modes identified by state-free
  reversible VAMPnets",Biological Physics,statefree reversible vampnets srvs are neural networkbased framework capable learning leading eigenfunctions transfer operator dynamical system trajectory data molecular dynamics simulations these datadriven collective variables cvs capture slowest modes dynamics are useful enhanced sampling free energy estimation work we employ srv coordinates feature set markov state model msm construction compared current state art msms constructed srv coordinates are more robust choice input features exhibit faster implied timescale convergence permit use shorter lagtimes construct higher kinetic resolution models we apply methodology study folding kinetics conformational landscape trpcage miniprotein folding unfolding mean first passage times are good agreement prior literature nine macrostate model presented unfolded ensemble comprises central kinetic hub interconversions several metastable unfolded conformations which serves gateway folded ensemble folded ensemble comprises native state partially unfolded intermediate loop state previously unreported shortlived intermediate we were able resolve due high timeresolution srvmsm we propose srvs excellent candidate integration into modern msm construction pipelines
Ensembles of Protein Molecules as Statistical Analog Computers,Biological Physics,class analog computers built large numbers microscopic probabilistic machines discussed it postulated such computers are implemented biological systems ensembles protein molecules formalism based abstract computational model referred protein molecule machine pmm pmm continuoustime firstorder markov system real input output vectors finite set discrete states inputdependent conditional probability densities state transitions output pmm function its input state components input vector called generalized potentials can be interpreted membrane potential concentrations neurotransmitters components output vector called generalized currents can represent ion currents flows second messengers ensemble pmms epmm set independent identical pmms same input vector output vector equal sum output vectors individual pmms paper suggests biological neurons have much more sophisticated computational resources than presently popular models artificial neurons
Genetic Algorithms in Time-Dependent Environments,Biological Physics,influence timedependent fitnesses infinite population dynamics simple genetic algorithms without crossover analyzed based general arguments schematic phase diagram constructed allows one characterize asymptotic states dependence mutation rate time scale changes furthermore notion regular changes raised which population can be shown converge towards generalized quasispecies based error thresholds optimal mutation rate are approximately calculated generational genetic algorithm moving needleinthehaystack landscape so found phase diagram fully consistent our general considerations
Machine learning for protein folding and dynamics,Biological Physics,many aspects study protein folding dynamics have been affected recent advances machine learning methods prediction protein structures their sequences are now heavily based machine learning tools way simulations are performed explore energy landscape protein systems also changing forcefields are started be designed means machine learning methods these methods are also used extract essential information large simulation datasets enhance sampling rare events such foldingunfolding transitions while significant challenges still need be tackled we expect these methods play important role study protein folding dynamics near future we discuss here recent advances all these fronts questions need be addressed machine learning approaches become mainstream protein simulation
"Machine-Learning-Driven New Geologic Discoveries at Mars Rover Landing
  Sites: Jezero and NE Syrtis",Earth and Planetary Astrophysics,hierarchical bayesian classifier trained pixel scale spectral data crism compact reconnaissance imaging spectrometer mars imagery its utility detecting rare phases demonstrated new geologic discoveries near mars rover landing site akaganeite found sediments jezero crater floor fluvial deposits ne syrtis jarosite silica are found jezero crater floor while chloritesmectite al phyllosilicates are found jezero crater walls these detections point multistage multichemistry history water jezero crater surrounding region provide new information guiding mars rovers landed exploration particular akaganeite silica jarosite floor deposits suggest either later episode salty ferich waters postdate jezero delta groundwater alteration portions jezero sedimentary sequence
Bayesian Deep Learning for Exoplanet Atmospheric Retrieval,Earth and Planetary Astrophysics,over past decade study extrasolar planets has evolved rapidly plain detection identification comprehensive categorization characterization exoplanet systems their atmospheres atmospheric retrieval inverse modeling technique used determine exoplanetary atmospheres temperature structure composition observed spectrum both timeconsuming computeintensive requiring complex algorithms compare thousands millions atmospheric models observational data find most probable values associated uncertainties each model parameter rocky terrestrial planets retrieved atmospheric composition can give insight into surface fluxes gaseous species necessary maintain stability atmosphere which may turn provide insight into geological andor biological processes active planet these atmospheres contain many molecules some them biosignatures spectral fingerprints indicative biological activity which will become observable next generation telescopes runtimes traditional retrieval models scale number model parameters so more molecular species are considered runtimes can become prohibitively long recent advances machine learning ml computer vision offer new ways reduce time perform retrieval orders magnitude given sufficient data set train here we present mlbased retrieval framework called intelligent exoplanet atmospheric retrieval inara consists bayesian deep learning model retrieval data set synthetic rocky exoplanetary spectra generated using nasa planetary spectrum generator our work represents first ml retrieval model rocky terrestrial exoplanets first synthetic data set terrestrial spectra generated scale
"Machine-Learning-Driven New Geologic Discoveries at Mars Rover Landing
  Sites: Jezero and NE Syrtis",Earth and Planetary Astrophysics,hierarchical bayesian classifier trained pixel scale spectral data crism compact reconnaissance imaging spectrometer mars imagery its utility detecting rare phases demonstrated new geologic discoveries near mars rover landing site akaganeite found sediments jezero crater floor fluvial deposits ne syrtis jarosite silica are found jezero crater floor while chloritesmectite al phyllosilicates are found jezero crater walls these detections point multistage multichemistry history water jezero crater surrounding region provide new information guiding mars rovers landed exploration particular akaganeite silica jarosite floor deposits suggest either later episode salty ferich waters postdate jezero delta groundwater alteration portions jezero sedimentary sequence
"Machine-Learning-Driven New Geologic Discoveries at Mars Rover Landing
  Sites: Jezero and NE Syrtis",Earth and Planetary Astrophysics,hierarchical bayesian classifier trained pixel scale spectral data crism compact reconnaissance imaging spectrometer mars imagery its utility detecting rare phases demonstrated new geologic discoveries near mars rover landing site akaganeite found sediments jezero crater floor fluvial deposits ne syrtis jarosite silica are found jezero crater floor while chloritesmectite al phyllosilicates are found jezero crater walls these detections point multistage multichemistry history water jezero crater surrounding region provide new information guiding mars rovers landed exploration particular akaganeite silica jarosite floor deposits suggest either later episode salty ferich waters postdate jezero delta groundwater alteration portions jezero sedimentary sequence
Bayesian Deep Learning for Exoplanet Atmospheric Retrieval,Earth and Planetary Astrophysics,over past decade study extrasolar planets has evolved rapidly plain detection identification comprehensive categorization characterization exoplanet systems their atmospheres atmospheric retrieval inverse modeling technique used determine exoplanetary atmospheres temperature structure composition observed spectrum both timeconsuming computeintensive requiring complex algorithms compare thousands millions atmospheric models observational data find most probable values associated uncertainties each model parameter rocky terrestrial planets retrieved atmospheric composition can give insight into surface fluxes gaseous species necessary maintain stability atmosphere which may turn provide insight into geological andor biological processes active planet these atmospheres contain many molecules some them biosignatures spectral fingerprints indicative biological activity which will become observable next generation telescopes runtimes traditional retrieval models scale number model parameters so more molecular species are considered runtimes can become prohibitively long recent advances machine learning ml computer vision offer new ways reduce time perform retrieval orders magnitude given sufficient data set train here we present mlbased retrieval framework called intelligent exoplanet atmospheric retrieval inara consists bayesian deep learning model retrieval data set synthetic rocky exoplanetary spectra generated using nasa planetary spectrum generator our work represents first ml retrieval model rocky terrestrial exoplanets first synthetic data set terrestrial spectra generated scale
Topological graph clustering with thin position,Geometric Topology,clustering algorithm partitions set data points into smaller sets clusters such each subset more tightly packed than whole many approaches clustering translate vector data into graph edges reflecting distance similarity metric points then look highly connected subgraphs we introduce such algorithm based ideas borrowed topological notion thin position knots dimensional manifolds
"Big Data Approaches to Knot Theory: Understanding the Structure of the
  Jones Polynomial",Geometric Topology,we examine structure dimensionality jones polynomial using manifold learning techniques our data set consists more than million knots up crossings two other special families up crossings we introduce describe method using filtrations analyze infinite data sets where representative sampling impossible impractical essential requirement working knots data knot invariants particular method provides new approach analyzing knot invariants using principal component analysis using approach jones polynomial data we find it can be viewed approximately dimensional manifold description surprisingly stable respect filtration crossing number results suggest further structures be examined understood
Topological graph clustering with thin position,Geometric Topology,clustering algorithm partitions set data points into smaller sets clusters such each subset more tightly packed than whole many approaches clustering translate vector data into graph edges reflecting distance similarity metric points then look highly connected subgraphs we introduce such algorithm based ideas borrowed topological notion thin position knots dimensional manifolds
Topological graph clustering with thin position,Geometric Topology,clustering algorithm partitions set data points into smaller sets clusters such each subset more tightly packed than whole many approaches clustering translate vector data into graph edges reflecting distance similarity metric points then look highly connected subgraphs we introduce such algorithm based ideas borrowed topological notion thin position knots dimensional manifolds
"Big Data Approaches to Knot Theory: Understanding the Structure of the
  Jones Polynomial",Geometric Topology,we examine structure dimensionality jones polynomial using manifold learning techniques our data set consists more than million knots up crossings two other special families up crossings we introduce describe method using filtrations analyze infinite data sets where representative sampling impossible impractical essential requirement working knots data knot invariants particular method provides new approach analyzing knot invariants using principal component analysis using approach jones polynomial data we find it can be viewed approximately dimensional manifold description surprisingly stable respect filtration crossing number results suggest further structures be examined understood
"Universal consistency of the $k$-NN rule in metric spaces and Nagata
  dimension",Metric Geometry,nearest neighbour learning rule under uniform distance tie breaking universally consistent every metric space sigmafinite dimensional sense nagata was pointed out cerou guyader consequence main result those elaborated detail assouad quentin de gromard we show it possible give direct proof along same lines original theorem charles stone about universal consistency knn classifier finite dimensional euclidean space generalization nontrivial because distance ties being more prevalent noneuclidean setting way we investigate relevant geometric properties metrics limitations stone argument constructing various examples
A Note on John Simplex with Positive Dilation,Metric Geometry,we prove johns theorem simplices rd positive dilation factor which improves previously known upper bound bound tight view lower bound furthermore we give example isnt optimal lower bound when our results answered both questions regarding johns theorem simplices positive dilation raised citelemecostly
"Universal consistency of the $k$-NN rule in metric spaces and Nagata
  dimension",Metric Geometry,nearest neighbour learning rule under uniform distance tie breaking universally consistent every metric space sigmafinite dimensional sense nagata was pointed out cerou guyader consequence main result those elaborated detail assouad quentin de gromard we show it possible give direct proof along same lines original theorem charles stone about universal consistency knn classifier finite dimensional euclidean space generalization nontrivial because distance ties being more prevalent noneuclidean setting way we investigate relevant geometric properties metrics limitations stone argument constructing various examples
"Universal consistency of the $k$-NN rule in metric spaces and Nagata
  dimension",Metric Geometry,nearest neighbour learning rule under uniform distance tie breaking universally consistent every metric space sigmafinite dimensional sense nagata was pointed out cerou guyader consequence main result those elaborated detail assouad quentin de gromard we show it possible give direct proof along same lines original theorem charles stone about universal consistency knn classifier finite dimensional euclidean space generalization nontrivial because distance ties being more prevalent noneuclidean setting way we investigate relevant geometric properties metrics limitations stone argument constructing various examples
A Note on John Simplex with Positive Dilation,Metric Geometry,we prove johns theorem simplices rd positive dilation factor which improves previously known upper bound bound tight view lower bound furthermore we give example isnt optimal lower bound when our results answered both questions regarding johns theorem simplices positive dilation raised citelemecostly
An enriched category theory of language: from syntax to semantics,Category Theory,state art language models return natural language text continuation any piece input text ability generate coherent text extensions implies significant sophistication including knowledge grammar semantics paper we propose mathematical framework passing probability distributions extensions given texts such ones learned todays large language models enriched category containing semantic information roughly speaking we model probability distributions texts category enriched over unit interval objects category are expressions language hom objects are conditional probabilities one expression extension another category syntactical it describes what goes what then via yoneda embedding we pass enriched category unit intervalvalued copresheaves syntactical category category enriched copresheaves semantic it where we find meaning logical operations such entailment building blocks more elaborate semantic concepts
Learners' Languages,Category Theory,backprop functor deep learning gradient descent backpropagation can be conceptualized strong monoidal functor paraeuctolearn category parameterized euclidean spaces learners category developed explicitly capture parameter update backpropagation it was soon realized there isomorphism learncongparaslens where slens symmetric monoidal category simple lenses used functional programming note we observe slens full subcategory poly category polynomial functors one variable via functor amapsto aya using fact polyotimes monoidal closed we show map ato paraslens has natural interpretation terms dynamical systems more precisely generalized moore machines whose interface internalhom type ayabyb finally we review fact category pcoalg dynamical systems any poly forms topos consider logical propositions can be stated its internal language we give gradient descent example we conclude discussing some directions future work
An enriched category theory of language: from syntax to semantics,Category Theory,state art language models return natural language text continuation any piece input text ability generate coherent text extensions implies significant sophistication including knowledge grammar semantics paper we propose mathematical framework passing probability distributions extensions given texts such ones learned todays large language models enriched category containing semantic information roughly speaking we model probability distributions texts category enriched over unit interval objects category are expressions language hom objects are conditional probabilities one expression extension another category syntactical it describes what goes what then via yoneda embedding we pass enriched category unit intervalvalued copresheaves syntactical category category enriched copresheaves semantic it where we find meaning logical operations such entailment building blocks more elaborate semantic concepts
An enriched category theory of language: from syntax to semantics,Category Theory,state art language models return natural language text continuation any piece input text ability generate coherent text extensions implies significant sophistication including knowledge grammar semantics paper we propose mathematical framework passing probability distributions extensions given texts such ones learned todays large language models enriched category containing semantic information roughly speaking we model probability distributions texts category enriched over unit interval objects category are expressions language hom objects are conditional probabilities one expression extension another category syntactical it describes what goes what then via yoneda embedding we pass enriched category unit intervalvalued copresheaves syntactical category category enriched copresheaves semantic it where we find meaning logical operations such entailment building blocks more elaborate semantic concepts
Learners' Languages,Category Theory,backprop functor deep learning gradient descent backpropagation can be conceptualized strong monoidal functor paraeuctolearn category parameterized euclidean spaces learners category developed explicitly capture parameter update backpropagation it was soon realized there isomorphism learncongparaslens where slens symmetric monoidal category simple lenses used functional programming note we observe slens full subcategory poly category polynomial functors one variable via functor amapsto aya using fact polyotimes monoidal closed we show map ato paraslens has natural interpretation terms dynamical systems more precisely generalized moore machines whose interface internalhom type ayabyb finally we review fact category pcoalg dynamical systems any poly forms topos consider logical propositions can be stated its internal language we give gradient descent example we conclude discussing some directions future work
"CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer
  Electromagnetic Calorimeters with Generative Adversarial Networks",High Energy Physics - Experiment,precise modeling subatomic particle interactions propagation through matter paramount advancement nuclear particle physics searches precision measurements most computationally expensive step simulation pipeline typical experiment large hadron collider lhc detailed modeling full complexity physics processes govern motion evolution particle showers inside calorimeters we introduce textsccalogan new fast simulation technique based generative adversarial networks gans we apply these neural networks modeling electromagnetic showers longitudinally segmented calorimeter achieve speedup factors comparable better than existing full simulation techniques cpu timestimes even faster gpu up simtimes there are still challenges achieving precision across entire phase space but our solution can reproduce variety geometric shower shape properties photons positrons charged pions represents significant stepping stone toward full neural networkbased detector simulation could save significant computing time enable many analyses now future
Inclusive Flavour Tagging Algorithm,High Energy Physics - Experiment,identifying flavour neutral mesons production one most important components needed study timedependent cp violation harsh environment large hadron collider makes it particularly hard succeed task we present inclusive flavourtagging algorithm upgrade algorithms currently used lhcb experiment specifically probabilistic model which efficiently combines information reconstructed vertices tracks using machine learning proposed algorithm does not use information about underlying physics process it reduces dependence performance lower level identification capacities thus increases overall performance proposed inclusive flavourtagging algorithm applicable tag flavour mesons any protonproton experiment
"The use of Convolutional Neural Networks for signal-background
  classification in Particle Physics experiments",High Energy Physics - Experiment,success convolutional neural networks cnns image classification has prompted efforts study their use classifying image data obtained particle physics experiments here we discuss our efforts apply cnns image data particle physics experiments classify signal background work we present extensive convolutional neural architecture search achieving high accuracy signalbackground discrimination hep classification usecase based simulated data ice cube neutrino observatory atlaslike detector we demonstrate among other things we can achieve same accuracy complex resnet architectures cnns less parameters present comparisons computational requirements training inference times
"CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer
  Electromagnetic Calorimeters with Generative Adversarial Networks",High Energy Physics - Experiment,precise modeling subatomic particle interactions propagation through matter paramount advancement nuclear particle physics searches precision measurements most computationally expensive step simulation pipeline typical experiment large hadron collider lhc detailed modeling full complexity physics processes govern motion evolution particle showers inside calorimeters we introduce textsccalogan new fast simulation technique based generative adversarial networks gans we apply these neural networks modeling electromagnetic showers longitudinally segmented calorimeter achieve speedup factors comparable better than existing full simulation techniques cpu timestimes even faster gpu up simtimes there are still challenges achieving precision across entire phase space but our solution can reproduce variety geometric shower shape properties photons positrons charged pions represents significant stepping stone toward full neural networkbased detector simulation could save significant computing time enable many analyses now future
Machine Learning Algorithms for $b$-Jet Tagging at the ATLAS Experiment,High Energy Physics - Experiment,separation bquark initiated jets those coming lighter quark flavors btagging fundamental tool atlas physics program cern large hadron collider most powerful btagging algorithms combine information lowlevel taggers exploiting reconstructed track vertex information into machine learning classifiers potential modern deep learning techniques explored using simulated events compared achievable more traditional classifiers such boosted decision trees
"Opening the black box of neural nets: case studies in stop/top
  discrimination",High Energy Physics - Phenomenology,we introduce techniques exploring functionality neural network extracting simple humanreadable approximations its performance performing gradient ascent input space network we are able produce large populations artificial events which strongly excite given classifier studying populations these events we then directly produce what are essentially contour maps networks classification function combined suite tools identifying input dimensions deemed most important network we can utilize these maps efficiently interpret dominant criteria which network makes its classification test case we study networks trained discriminate supersymmetric stop production dilepton channel standard model backgrounds case heavy stop decaying light neutralino we find individual neurons large mutual information mtellell humandesigned variable optimizing analysis network selects events significant missing pt oriented azimuthally away both leptons efficiently rejecting toverlinet background case light stop threebody decays wbwidetilde chi little phase space we find neurons smoothly interpolate between similar toprejection strategy isrtagging strategy allowing more missing momentum we also find neural network trained stealth stop parameter point learns novel angular correlations
"Simulation of electron-proton scattering events by a Feature-Augmented
  and Transformed Generative Adversarial Network (FAT-GAN)",High Energy Physics - Phenomenology,we apply generative adversarial network gan technology build event generator simulates particle production electronproton scattering free theoretical assumptions about underlying particle dynamics difficulty efficiently training gan event simulator lies learning complicated patterns distributions particles physical properties we develop gan selects set transformed features particle momenta can be generated easily generator uses these produce set augmented features improve sensitivity discriminator new featureaugmented transformed gan fatgan able faithfully reproduce distribution final state electron momenta inclusive electron scattering without need input derived domainbased theoretical assumptions developed technology can play significant role boosting science existing future accelerator facilities such electronion collider
"Folded context condensation in Path Integral formalism for infinite
  context transformers",High Energy Physics - Phenomenology,short note written rapid communication long context training share idea how train it low memory usage note we generalize attention algorithm neural network generative pretrained transformers reinterpret it path integral formalism first role transformer understood time evolution token state second it suggested all keytoken states same time querytoken can attend attention query token states result repetitive time evolution it discussed token states past sequence meats token states present sequence so attention between separated sequences becomes possible maintaining infinite contextual information just using low memory limited size sequence experiment input token window size was taken one gpu gb memory was used pretraining it was confirmed more than length context preserved sampling result training code other details will be included revised version note later
Pileup Mitigation with Machine Learning (PUMML),High Energy Physics - Phenomenology,pileup involves contamination energy distribution arising primary collision interest leading vertex radiation soft collisions pileup we develop new technique removing contamination using machine learning convolutional neural networks network takes input energy distribution charged leading vertex particles charged pileup particles all neutral particles outputs energy distribution particles coming leading vertex alone pumml algorithm performs remarkably well eliminating pileup distortion wide range simple complex jet observables we test robustness algorithm number ways discuss how network can be trained directly data
Goodness of fit by Neyman-Pearson testing,High Energy Physics - Phenomenology,neymanpearson strategy hypothesis testing can be employed goodness fit if alternative hypothesis selected data exploring rich parametrised family models while controlling impact statistical fluctuations new physics learning machine nplm methodology has been developed concrete implementation idea target detection new physical effects context high energy physics collider experiments paper we conduct comparison approach goodness fit others particular classifierbased strategies share strong similarities nplm our comparison nplm emerges more sensitive test small departures data expected distribution not biased towards detecting specific types anomalies these features make it suited agnostic searches new physics collider experiments its deployment other scientific industrial scenarios should be investigated
"Comparative analysis of neural network architectures for short-term
  FOREX forecasting",Mathematical Finance,present document delineates analysis design implementation benchmarking various neural network architectures within shortterm frequency prediction system foreign exchange market forex our aim simulate judgment human expert technical analyst using system responds promptly changes market conditions thus enabling optimization shortterm trading strategies we designed implemented series lstm neural network architectures which are taken input exchange rate values generate shortterm market trend forecasting signal ann custom architecture based technical analysis indicator simulators we performed comparative analysis results came useful conclusions regarding suitability each architecture cost terms time computational power implement them ann custom architecture produces better prediction quality higher sensitivity using fewer resources spending less time than lstm architectures ann custom architecture appears be ideal use lowpower computing systems use cases need fast decisions least possible computational cost
"Deep Learning in a Generalized HJM-type Framework Through Arbitrage-Free
  Regularization",Mathematical Finance,we introduce regularization approach arbitragefree factormodel selection considered model selection problem seeks learn closest arbitragefree hjmtype model any prespecified factormodel asymptotic solution priori computationally intractable problem represented limit parameter family optimizers computationally tractable model selection tasks each these simplified modelselection tasks seeks learn most similar model prescribed factormodel subject penalty detecting when reference measure local martingalemeasure entire underlying financial market simple expression penalty terms obtained bond market withing affineterm structure setting it used formulate deeplearning approach arbitragefree affine termstructure modelling numerical implementations are also performed evaluate performance bond market
Trading algorithms with learning in latent alpha models,Mathematical Finance,alpha signals statistical arbitrage strategies are often driven latent factors paper analyses how optimally trade latent factors cause prices jump diffuse moreover we account effect traders actions quoted prices prices they receive trading under fairly general assumptions we demonstrate how trader can learn posterior distribution over latent states explicitly solve latent optimal trading problem we provide verification theorem methodology calibrating model deriving variation expectationmaximization algorithm illustrate efficacy optimal strategy we demonstrate its performance through simulations compare it strategies which ignore learning latent factors we also provide calibration results particular model using intel corporation stock example
"Comparative analysis of neural network architectures for short-term
  FOREX forecasting",Mathematical Finance,present document delineates analysis design implementation benchmarking various neural network architectures within shortterm frequency prediction system foreign exchange market forex our aim simulate judgment human expert technical analyst using system responds promptly changes market conditions thus enabling optimization shortterm trading strategies we designed implemented series lstm neural network architectures which are taken input exchange rate values generate shortterm market trend forecasting signal ann custom architecture based technical analysis indicator simulators we performed comparative analysis results came useful conclusions regarding suitability each architecture cost terms time computational power implement them ann custom architecture produces better prediction quality higher sensitivity using fewer resources spending less time than lstm architectures ann custom architecture appears be ideal use lowpower computing systems use cases need fast decisions least possible computational cost
Statistical Arbitrage in Rank Space,Mathematical Finance,equity market dynamics are conventionally investigated name space where stocks are indexed company names contrast indexing stocks based their ranks capitalization we gain different perspective market dynamics rank space here we demonstrate superior performance statistical arbitrage rank space over name space driven robust market representation enhanced meanreverting properties residual returns rank space our statistical arbitrage algorithm features intraday rebalancing mechanism effective conversion between portfolios name rank space we explore statistical arbitrage without neural networks both name rank space show portfolios obtained rank space neural networks significantly outperform those name space
"Cellular Automata Model for Non-Structural Proteins Comparing
  Transmissibility and Pathogenesis of SARS Covid (CoV-2, CoV) and MERS Covid",Other Quantitative Biology,significantly higher transmissibility sars cov compared sars cov can be attributed mutations structural proteins spike nucleocapsid membrane envelope role played nonstructural proteins nsps accessory proteins orfs viral replication assembly shedding nonstructural proteins nsps avail host protein synthesis machinery initiate viral replication along neutralization host immune defense key protein out nsps nonstructural protein nsp also known leader protein nsp leads process hijacking host resources blocking host translation paper concentrates analysis nsps sars covid cov cov mers covid based cellular automata enhanced machine learning caml model developed study biological strings computational model compares deviation structure function cov cov employing caml model parameters derived out ca evolution amino acid chains nsps comparative analysis points higher transmissibility cov compared cov major nsps ii deviation mers covid sars cov respect virulence pathogenesis machine learning ml framework has been designed map caml model parameters physical domain features reported invitroinvivoinsilico experimental studies ml framework enables us learn permissible range model parameters derived out mutational study sixteen nsps three viruses
Open Data Resources for Fighting COVID-19,Other Quantitative Biology,we provide insight into open data resources pertinent study spread covid pandemic its control we identify variables required analyze fundamental aspects like seasonal behaviour regional mortality rates effectiveness government measures open data resources along datadriven methodologies provide many opportunities improve response different administrations virus we describe present limitations difficulties encountered most opendata resources facilitate access main opendata portals resources we identify most relevant institutions world scale providing covid information andor auxiliary variables demographics mobility etc we also describe several open resources access covid datasets countrywide level ie china italy spain france germany us etc attempt facilitate rapid response study seasonal behaviour covid we enumerate main open resources terms weather climate variables concoteam team which composed different researches universities spain italy france germany united kingdom argentina main goal concoteam develop datadriven methods better understanding control pandemic
"Cellular Automata Model for Non-Structural Proteins Comparing
  Transmissibility and Pathogenesis of SARS Covid (CoV-2, CoV) and MERS Covid",Other Quantitative Biology,significantly higher transmissibility sars cov compared sars cov can be attributed mutations structural proteins spike nucleocapsid membrane envelope role played nonstructural proteins nsps accessory proteins orfs viral replication assembly shedding nonstructural proteins nsps avail host protein synthesis machinery initiate viral replication along neutralization host immune defense key protein out nsps nonstructural protein nsp also known leader protein nsp leads process hijacking host resources blocking host translation paper concentrates analysis nsps sars covid cov cov mers covid based cellular automata enhanced machine learning caml model developed study biological strings computational model compares deviation structure function cov cov employing caml model parameters derived out ca evolution amino acid chains nsps comparative analysis points higher transmissibility cov compared cov major nsps ii deviation mers covid sars cov respect virulence pathogenesis machine learning ml framework has been designed map caml model parameters physical domain features reported invitroinvivoinsilico experimental studies ml framework enables us learn permissible range model parameters derived out mutational study sixteen nsps three viruses
"Cellular Automata Model for Non-Structural Proteins Comparing
  Transmissibility and Pathogenesis of SARS Covid (CoV-2, CoV) and MERS Covid",Other Quantitative Biology,significantly higher transmissibility sars cov compared sars cov can be attributed mutations structural proteins spike nucleocapsid membrane envelope role played nonstructural proteins nsps accessory proteins orfs viral replication assembly shedding nonstructural proteins nsps avail host protein synthesis machinery initiate viral replication along neutralization host immune defense key protein out nsps nonstructural protein nsp also known leader protein nsp leads process hijacking host resources blocking host translation paper concentrates analysis nsps sars covid cov cov mers covid based cellular automata enhanced machine learning caml model developed study biological strings computational model compares deviation structure function cov cov employing caml model parameters derived out ca evolution amino acid chains nsps comparative analysis points higher transmissibility cov compared cov major nsps ii deviation mers covid sars cov respect virulence pathogenesis machine learning ml framework has been designed map caml model parameters physical domain features reported invitroinvivoinsilico experimental studies ml framework enables us learn permissible range model parameters derived out mutational study sixteen nsps three viruses
"Cellular Automata Model for Non-Structural Proteins Comparing
  Transmissibility and Pathogenesis of SARS Covid (CoV-2, CoV) and MERS Covid",Other Quantitative Biology,significantly higher transmissibility sars cov compared sars cov can be attributed mutations structural proteins spike nucleocapsid membrane envelope role played nonstructural proteins nsps accessory proteins orfs viral replication assembly shedding nonstructural proteins nsps avail host protein synthesis machinery initiate viral replication along neutralization host immune defense key protein out nsps nonstructural protein nsp also known leader protein nsp leads process hijacking host resources blocking host translation paper concentrates analysis nsps sars covid cov cov mers covid based cellular automata enhanced machine learning caml model developed study biological strings computational model compares deviation structure function cov cov employing caml model parameters derived out ca evolution amino acid chains nsps comparative analysis points higher transmissibility cov compared cov major nsps ii deviation mers covid sars cov respect virulence pathogenesis machine learning ml framework has been designed map caml model parameters physical domain features reported invitroinvivoinsilico experimental studies ml framework enables us learn permissible range model parameters derived out mutational study sixteen nsps three viruses
Quantified limits of the nuclear landscape,Nuclear Theory,chart nuclides limited particle drip lines beyond which nuclear stability proton neutron emission lost predicting range particlebound isotopes poses appreciable challenge nuclear theory it involves extreme extrapolations nuclear masses beyond regions where experimental information available still quantified extrapolations are crucial variety applications including modeling stellar nucleosynthesis we use microscopic nuclear mass models bayesian methodology provide quantified predictions proton neutron separation energies well bayesian probabilities existence throughout nuclear landscape all way particle drip lines we apply nuclear density functional theory several energy density functionals account uncertainties bayesian gaussian processes are trained separationenergy residuals each individual model resulting predictions are combined via bayesian model averaging framework allows account systematic statistical uncertainties propagate them extrapolative predictions we characterize dripline regions where probability nucleus particlebound decreases these regions we provide quantified predictions one twonucleon separation energies according our bayesian model averaging analysis nuclei zleq have probability existence geq extrapolations obtained study will be put through stringent tests when new experimental information exotic nuclei becomes available respect quantified landscape nuclear existence obtained study should be viewed dynamical prediction will be finetuned when new experimental information improved global mass models become available
Trees and Islands -- Machine learning approach to nuclear physics,Nuclear Theory,we implement machine learning algorithms nuclear data these algorithms are purely data driven generate models are capable capture intricate trends gradient boosted trees algorithm employed generate trained model existing nuclear data which used prediction data damping parameter shell correction energies quadrupole deformation pairing gaps level densities giant dipole resonance large number nuclei we particular predict level density parameter superheavy elements which great current interest predictions made machine learning algorithm found have standard deviation
Deep learning: Extrapolation tool for ab initio nuclear theory,Nuclear Theory,ab initio approaches nuclear theory such nocore shell model ncsm have been developed approximately solving finite nuclei realistic strong interactions ncsm other approaches require extrapolation results obtained finite basis space infinite basis space limit assessment uncertainty those extrapolations each observable requires separate extrapolation most observables have no proven extrapolation method we propose feedforward artificial neural network ann method extrapolation tool obtain ground state energy ground state pointproton rootmeansquare rms radius along their extrapolation uncertainties designed anns are sufficient produce results these two very different observables li ab initio ncsm results small basis spaces satisfy following theoretical physics condition independence basis space parameters limit extremely large matrices comparisons ann results other extrapolation methods are also provided
Quantified limits of the nuclear landscape,Nuclear Theory,chart nuclides limited particle drip lines beyond which nuclear stability proton neutron emission lost predicting range particlebound isotopes poses appreciable challenge nuclear theory it involves extreme extrapolations nuclear masses beyond regions where experimental information available still quantified extrapolations are crucial variety applications including modeling stellar nucleosynthesis we use microscopic nuclear mass models bayesian methodology provide quantified predictions proton neutron separation energies well bayesian probabilities existence throughout nuclear landscape all way particle drip lines we apply nuclear density functional theory several energy density functionals account uncertainties bayesian gaussian processes are trained separationenergy residuals each individual model resulting predictions are combined via bayesian model averaging framework allows account systematic statistical uncertainties propagate them extrapolative predictions we characterize dripline regions where probability nucleus particlebound decreases these regions we provide quantified predictions one twonucleon separation energies according our bayesian model averaging analysis nuclei zleq have probability existence geq extrapolations obtained study will be put through stringent tests when new experimental information exotic nuclei becomes available respect quantified landscape nuclear existence obtained study should be viewed dynamical prediction will be finetuned when new experimental information improved global mass models become available
Quantified limits of the nuclear landscape,Nuclear Theory,chart nuclides limited particle drip lines beyond which nuclear stability proton neutron emission lost predicting range particlebound isotopes poses appreciable challenge nuclear theory it involves extreme extrapolations nuclear masses beyond regions where experimental information available still quantified extrapolations are crucial variety applications including modeling stellar nucleosynthesis we use microscopic nuclear mass models bayesian methodology provide quantified predictions proton neutron separation energies well bayesian probabilities existence throughout nuclear landscape all way particle drip lines we apply nuclear density functional theory several energy density functionals account uncertainties bayesian gaussian processes are trained separationenergy residuals each individual model resulting predictions are combined via bayesian model averaging framework allows account systematic statistical uncertainties propagate them extrapolative predictions we characterize dripline regions where probability nucleus particlebound decreases these regions we provide quantified predictions one twonucleon separation energies according our bayesian model averaging analysis nuclei zleq have probability existence geq extrapolations obtained study will be put through stringent tests when new experimental information exotic nuclei becomes available respect quantified landscape nuclear existence obtained study should be viewed dynamical prediction will be finetuned when new experimental information improved global mass models become available
"Projected Regression Methods for Inverting Fredholm Integrals: Formalism
  and Application to Analytical Continuation",Strongly Correlated Electrons,we present machine learning approach inversion fredholm integrals first kind approach provides natural regularization cases where inverse fredholm kernel illconditioned it also provides efficient stable treatment constraints key observation stability forward problem permits construction large database outputs physically meaningful inputs we apply machine learning database generate regression function controlled complexity which returns approximate solutions previously unseen inputs approximate solutions are then projected onto subspace functions satisfying relevant constraints we also derive present uncertainty estimates we illustrate approach applying it analytical continuation problem quantum manybody physics which involves reconstructing frequency dependence physical excitation spectra data obtained specific points complex frequency plane under standard error metrics method performs well better than maximum entropy method low input noise substantially more robust increased input noise we expect methodology be similarly effective any problem involving formally illconditioned inversion provided forward problem can be efficiently solved
Machine learning electron correlation in a disordered medium,Strongly Correlated Electrons,learning data has led paradigm shift computational materials science particular it has been shown neural networks can learn potential energy surface interatomic forces through examples thus bypassing computationally expensive density functional theory calculations combining manybody techniques deep learning approach we demonstrate fullyconnected neural network able learn complex collective behavior electrons strongly correlated systems specifically we consider andersonhubbard ah model which canonical system studying interplay between electron correlation strong localization ground states ah model square lattice are obtained using realspace gutzwiller method obtained solutions are used train multitask multilayer neural network which subsequently can accurately predict quantities such local probability double occupation quasiparticle weight given disorder potential neighborhood input
"Machine learning for many-body physics: The case of the Anderson
  impurity model",Strongly Correlated Electrons,machine learning methods are applied finding greens function anderson impurity model basic model system quantum manybody condensedmatter physics different methods parametrizing greens function are investigated representation terms legendre polynomials found be superior due its limited number coefficients its applicability state art methods solution dependence errors size training set determined results indicate machine learning approach dynamical meanfield theory may be feasible
"Projected Regression Methods for Inverting Fredholm Integrals: Formalism
  and Application to Analytical Continuation",Strongly Correlated Electrons,we present machine learning approach inversion fredholm integrals first kind approach provides natural regularization cases where inverse fredholm kernel illconditioned it also provides efficient stable treatment constraints key observation stability forward problem permits construction large database outputs physically meaningful inputs we apply machine learning database generate regression function controlled complexity which returns approximate solutions previously unseen inputs approximate solutions are then projected onto subspace functions satisfying relevant constraints we also derive present uncertainty estimates we illustrate approach applying it analytical continuation problem quantum manybody physics which involves reconstructing frequency dependence physical excitation spectra data obtained specific points complex frequency plane under standard error metrics method performs well better than maximum entropy method low input noise substantially more robust increased input noise we expect methodology be similarly effective any problem involving formally illconditioned inversion provided forward problem can be efficiently solved
"Projected Regression Methods for Inverting Fredholm Integrals: Formalism
  and Application to Analytical Continuation",Strongly Correlated Electrons,we present machine learning approach inversion fredholm integrals first kind approach provides natural regularization cases where inverse fredholm kernel illconditioned it also provides efficient stable treatment constraints key observation stability forward problem permits construction large database outputs physically meaningful inputs we apply machine learning database generate regression function controlled complexity which returns approximate solutions previously unseen inputs approximate solutions are then projected onto subspace functions satisfying relevant constraints we also derive present uncertainty estimates we illustrate approach applying it analytical continuation problem quantum manybody physics which involves reconstructing frequency dependence physical excitation spectra data obtained specific points complex frequency plane under standard error metrics method performs well better than maximum entropy method low input noise substantially more robust increased input noise we expect methodology be similarly effective any problem involving formally illconditioned inversion provided forward problem can be efficiently solved
Learning Clustered Representation for Complex Free Energy Landscapes,Statistical Mechanics,paper we first analyzed inductive bias underlying data scattered across complex free energy landscapes fel exploited it train deep neural networks which yield reduced clustered representation fel our parametric method called information distilling metastability idm endtoend differentiable thus scalable ultralarge dataset idm also clustering algorithm able cluster samples meantime reducing dimensions besides unsupervised learning method idm differs many existing dimensionality reduction clustering methods it neither requires cherrypicked distance metric nor groundtrue number clusters it can be used unroll zoomin hierarchical fel respect different timescales through multiple experiments we show idm can achieve physically meaningful representations which partition fel into welldefined metastable states hence are amenable downstream tasks such mechanism analysis kinetic modeling
"Learning to grow: control of material self-assembly using evolutionary
  reinforcement learning",Statistical Mechanics,we show neural networks trained evolutionary reinforcement learning can enact efficient molecular selfassembly protocols presented molecular simulation trajectories networks learn change temperature chemical potential order promote assembly desired structures choose between competing polymorphs first case networks reproduce qualitative sense results previouslyknown protocols but faster higher fidelity second case they identify strategies previously unknown which we can extract physical insight networks take input elapsed time simulation microscopic information system are both effective latter more so evolutionary scheme we have used simple implement can be applied broad range examples experimental selfassembly whether not one can monitor experiment it proceeds our results have been achieved no human input beyond specification which order parameter promote pointing way design synthesis protocols artificial intelligence
"How to train your demon to do fast information erasure without heat
  production",Statistical Mechanics,timedependent protocols perform irreversible logical operations such memory erasure cost work produce heat placing bounds efficiency computers here we use prototypical computer model physical memory show it possible learn feedbackcontrol protocols do fast memory erasure without input work production heat these protocols which are enacted neuralnetwork demon do not violate second law thermodynamics because demon generates more heat than memory absorbs result form nonlocal heat exchange which one computation rendered energetically favorable while compensating one produces heat elsewhere tactic could be used rationally design flow energy within computer
"Bayesian feature selection with strongly-regularizing priors maps to the
  Ising Model",Statistical Mechanics,identifying small subsets features are relevant prediction andor classification tasks central problem machine learning statistics feature selection task especially important computationally difficult modern datasets where number features can be comparable even exceed number samples here we show feature selection bayesian inference takes universal form reduces calculating magnetizations ising model under some mild conditions our results exploit observation evidence takes universal form stronglyregularizing priors priors have large effect posterior probability even infinite data limit we derive explicit expressions feature selection generalized linear models large class statistical techniques include linear logistic regression we illustrate power our approach analyzing feature selection logistic regressionbased classifier trained distinguish between letters notmnist dataset
"Solving Statistical Mechanics on Sparse Graphs with Feedback Set
  Variational Autoregressive Networks",Statistical Mechanics,we propose method solving statistical mechanics problems defined sparse graphs it extracts small feedback vertex set fvs sparse graph converting sparse system much smaller system manybody dense interactions effective energy every configuration fvs then learns variational distribution parameterized using neural networks approximate original boltzmann distribution method able estimate free energy compute observables generate unbiased samples via direct sampling without autocorrelation extensive experiments show our approach more accurate than existing approaches sparse spin glasses random graphs realworld networks our approach significantly outperforms standard methods sparse systems such beliefpropagation algorithm structured sparse systems such twodimensional lattices our approach significantly faster more accurate than recently proposed variational autoregressive networks using convolution neural networks
"Streaming, Memory Limited Matrix Completion with Noise",Spectral Theory,paper we consider streaming memorylimited matrix completion problem when observed entries are noisy versions small random fraction original entries we are interested scenarios where matrix size very large so matrix very hard store manipulate here columns observed matrix are presented sequentially goal complete missing entries after one pass data limited memory space limited computational complexity we propose streaming algorithm which produces estimate original matrix vanishing mean square error uses memory space scaling linearly ambient dimension matrix ie memory required store output alone spends computations much number nonzero entries input matrix
Spectral Analysis Of Weighted Laplacians Arising In Data Clustering,Spectral Theory,graph laplacians computed weighted adjacency matrices are widely used identify geometric structure data clusters particular their spectral properties play central role number unsupervised semisupervised learning algorithms when suitably scaled graph laplacians approach limiting continuum operators large data limit studying these limiting operators therefore sheds light learning algorithms paper devoted study parameterized family divergence form elliptic operators arise large data limit graph laplacians link between threeparameter family graph laplacians threeparameter family differential operators explained spectral properties these differential operators are analyzed situation where data comprises two nearly separated clusters sense which made precise particular we investigate how spectral gap depends three parameters entering graph laplacian parameter measuring size perturbation perfectly clustered case numerical results are presented which exemplify extend analysis computations study situations which there are two nearly separated clusters but which violate assumptions used our theory situations which more than two clusters are present also going beyond our theory situations which demonstrate relevance our studies differential operators understanding finite data problems via graph laplacian findings provide insight into parameter choices made learning algorithms which are based weighted adjacency matrices they also provide basis analysis consistency various unsupervised semisupervised learning algorithms large data limit
"Streaming, Memory Limited Matrix Completion with Noise",Spectral Theory,paper we consider streaming memorylimited matrix completion problem when observed entries are noisy versions small random fraction original entries we are interested scenarios where matrix size very large so matrix very hard store manipulate here columns observed matrix are presented sequentially goal complete missing entries after one pass data limited memory space limited computational complexity we propose streaming algorithm which produces estimate original matrix vanishing mean square error uses memory space scaling linearly ambient dimension matrix ie memory required store output alone spends computations much number nonzero entries input matrix
"Streaming, Memory Limited Matrix Completion with Noise",Spectral Theory,paper we consider streaming memorylimited matrix completion problem when observed entries are noisy versions small random fraction original entries we are interested scenarios where matrix size very large so matrix very hard store manipulate here columns observed matrix are presented sequentially goal complete missing entries after one pass data limited memory space limited computational complexity we propose streaming algorithm which produces estimate original matrix vanishing mean square error uses memory space scaling linearly ambient dimension matrix ie memory required store output alone spends computations much number nonzero entries input matrix
"Streaming, Memory Limited Matrix Completion with Noise",Spectral Theory,paper we consider streaming memorylimited matrix completion problem when observed entries are noisy versions small random fraction original entries we are interested scenarios where matrix size very large so matrix very hard store manipulate here columns observed matrix are presented sequentially goal complete missing entries after one pass data limited memory space limited computational complexity we propose streaming algorithm which produces estimate original matrix vanishing mean square error uses memory space scaling linearly ambient dimension matrix ie memory required store output alone spends computations much number nonzero entries input matrix
"Incorporating Physical Knowledge into Machine Learning for Planetary
  Space Physics",Space Physics,recent improvements data collection volume planetary space physics missions have allowed application novel data science techniques cassini mission example collected over gigabytes scientific data represents surge data saturn system machine learning can help scientists work data larger scale unlike many applications machine learning primary use planetary space physics applications infer behavior about system itself raises three concerns first performance machine learning model second need interpretable applications answer scientific questions third how characteristics spacecraft data change these applications comparison these concerns uses black box uninterpretable machine learning methods tend toward evaluations performance only either ignoring underlying physical process less often providing misleading explanations it we build off previous effort applying semisupervised physicsbased classification plasma instabilities saturns magnetosphere we then use previous effort comparison other machine learning classifiers varying data size access physical information access we show incorporating knowledge these orbiting spacecraft data characteristics improves performance interpretability machine learning methods which essential deriving scientific meaning building these findings we present framework incorporating physics knowledge into machine learning problems targeting semisupervised classification space physics data planetary environments these findings present path forward incorporating physical knowledge into space physics planetary mission data analyses scientific discovery
"Toward a Next Generation Particle Precipitation Model: Mesoscale
  Prediction Through Machine Learning (a Case Study and Framework for Progress)",Space Physics,we advance modeling capability electron particle precipitation magnetosphere ionosphere through new database use machine learning ml tools gain utility those data we have compiled curated analyzed made available new more capable database particle precipitation data includes satellite years defense meteorological satellite program dmsp observations temporally aligned solar wind geomagnetic activity data new total electron energy flux particle precipitation nowcast model neural network called precipnet takes advantage increased expressive power afforded ml approaches appropriately utilize diverse information solar wind geomagnetic activity importantly their time histories more capable representation organizing parameters target electron energy flux observations precipnet achieves reduction errors current stateoftheart model oval variation assessment tracking intensity online nowcasting ovation prime better captures dynamic changes auroral flux provides evidence it can capably reconstruct mesoscale phenomena we create apply new framework space weather model evaluation culminates previous guidance across solarterrestrial research community research approach results are representative new frontier space weather research intersection traditional data sciencedriven discovery provides foundation future efforts
"Incorporating Physical Knowledge into Machine Learning for Planetary
  Space Physics",Space Physics,recent improvements data collection volume planetary space physics missions have allowed application novel data science techniques cassini mission example collected over gigabytes scientific data represents surge data saturn system machine learning can help scientists work data larger scale unlike many applications machine learning primary use planetary space physics applications infer behavior about system itself raises three concerns first performance machine learning model second need interpretable applications answer scientific questions third how characteristics spacecraft data change these applications comparison these concerns uses black box uninterpretable machine learning methods tend toward evaluations performance only either ignoring underlying physical process less often providing misleading explanations it we build off previous effort applying semisupervised physicsbased classification plasma instabilities saturns magnetosphere we then use previous effort comparison other machine learning classifiers varying data size access physical information access we show incorporating knowledge these orbiting spacecraft data characteristics improves performance interpretability machine learning methods which essential deriving scientific meaning building these findings we present framework incorporating physics knowledge into machine learning problems targeting semisupervised classification space physics data planetary environments these findings present path forward incorporating physical knowledge into space physics planetary mission data analyses scientific discovery
"Incorporating Physical Knowledge into Machine Learning for Planetary
  Space Physics",Space Physics,recent improvements data collection volume planetary space physics missions have allowed application novel data science techniques cassini mission example collected over gigabytes scientific data represents surge data saturn system machine learning can help scientists work data larger scale unlike many applications machine learning primary use planetary space physics applications infer behavior about system itself raises three concerns first performance machine learning model second need interpretable applications answer scientific questions third how characteristics spacecraft data change these applications comparison these concerns uses black box uninterpretable machine learning methods tend toward evaluations performance only either ignoring underlying physical process less often providing misleading explanations it we build off previous effort applying semisupervised physicsbased classification plasma instabilities saturns magnetosphere we then use previous effort comparison other machine learning classifiers varying data size access physical information access we show incorporating knowledge these orbiting spacecraft data characteristics improves performance interpretability machine learning methods which essential deriving scientific meaning building these findings we present framework incorporating physics knowledge into machine learning problems targeting semisupervised classification space physics data planetary environments these findings present path forward incorporating physical knowledge into space physics planetary mission data analyses scientific discovery
"Toward a Next Generation Particle Precipitation Model: Mesoscale
  Prediction Through Machine Learning (a Case Study and Framework for Progress)",Space Physics,we advance modeling capability electron particle precipitation magnetosphere ionosphere through new database use machine learning ml tools gain utility those data we have compiled curated analyzed made available new more capable database particle precipitation data includes satellite years defense meteorological satellite program dmsp observations temporally aligned solar wind geomagnetic activity data new total electron energy flux particle precipitation nowcast model neural network called precipnet takes advantage increased expressive power afforded ml approaches appropriately utilize diverse information solar wind geomagnetic activity importantly their time histories more capable representation organizing parameters target electron energy flux observations precipnet achieves reduction errors current stateoftheart model oval variation assessment tracking intensity online nowcasting ovation prime better captures dynamic changes auroral flux provides evidence it can capably reconstruct mesoscale phenomena we create apply new framework space weather model evaluation culminates previous guidance across solarterrestrial research community research approach results are representative new frontier space weather research intersection traditional data sciencedriven discovery provides foundation future efforts
"Semi-discrete optimization through semi-discrete optimal transport: a
  framework for neural architecture search",Analysis of PDEs,paper we introduce theoretical framework semidiscrete optimization using ideas optimal transport our primary motivation field deep learning specifically task neural architecture search aim mind we discuss geometric theoretical motivation new techniques neural architecture search companion paper we show algorithms inspired our framework are competitive contemporaneous methods we introduce riemannianlike metric space probability measures over semidiscrete space mathbbrd times mathcalg where mathcalg finite weighted graph such riemmanian structure hand we derive formal expressions gradient flow relative entropy functional well second order dynamics optimization said energy then aim providing rigorous motivation gradient flow equations derived formally we also consider iterative procedure known minimizing movement scheme ie implicit euler scheme jko scheme apply it relative entropy respect suitable cost function some specific choices metric cost we rigorously show minimizing movement scheme relative entropy functional converges gradient flow process provided formal riemannian structure flow coincides system reactiondiffusion equations mathbbrd
"Wasserstein Gradient Flows of MMD Functionals with Distance Kernel and
  Cauchy Problems on Quantile Functions",Analysis of PDEs,we give comprehensive description wasserstein gradient flows maximum mean discrepancy mmd functionals mathcal fnu textmmdkcdot nu towards given target measures nu real line where we focus negative distance kernel kxy xy one dimension wasserstein space can be isometrically embedded into cone mathcal subset quantile functions leading characterization wasserstein gradient flows via solution associated cauchy problem based construction appropriate counterpart mathcal fnu its subdifferential we provide solution cauchy problem discrete target measures nu results piecewise linear solution formula we prove invariance smoothing properties flow subsets mathcal certain mathcal fnuflows implies initial point measures instantly become absolutely continuous stay so over time finally we illustrate behavior flow various numerical examples using implicit euler scheme which easily computable bisection algorithm continuous targets nu also explicit euler scheme can be employed although limited convergence guarantees
"On the Convergence of Gradient Descent Training for Two-layer
  ReLU-networks in the Mean Field Regime",Analysis of PDEs,we describe necessary sufficient condition convergence minimum bayes risk when training twolayer relunetworks gradient descent mean field regime omnidirectional initial parameter distribution article extends recent results chizat bach reluactivated networks situation which there are no parameters which exactly achieve mbr condition does not depend initalization parameters concerns only weak convergence realization neural network not its parameter distribution
"Solving the Poisson Equation with Dirichlet data by shallow
  ReLU$^α$-networks: A regularity and approximation perspective",Analysis of PDEs,several classes neural pde solvers deep ritz pinns deeponets ability approximate solution solution operator partial differential equation pde hinges abilitiy neural network approximate solution spatial variables we analyze capacity neural networks approximate solutions elliptic pde assuming boundary condition can be approximated efficiently our focus laplace operator dirichlet boundary condition half space neural networks single hidden layer activation function power popular relu activation function
"Semi-discrete optimization through semi-discrete optimal transport: a
  framework for neural architecture search",Analysis of PDEs,paper we introduce theoretical framework semidiscrete optimization using ideas optimal transport our primary motivation field deep learning specifically task neural architecture search aim mind we discuss geometric theoretical motivation new techniques neural architecture search companion paper we show algorithms inspired our framework are competitive contemporaneous methods we introduce riemannianlike metric space probability measures over semidiscrete space mathbbrd times mathcalg where mathcalg finite weighted graph such riemmanian structure hand we derive formal expressions gradient flow relative entropy functional well second order dynamics optimization said energy then aim providing rigorous motivation gradient flow equations derived formally we also consider iterative procedure known minimizing movement scheme ie implicit euler scheme jko scheme apply it relative entropy respect suitable cost function some specific choices metric cost we rigorously show minimizing movement scheme relative entropy functional converges gradient flow process provided formal riemannian structure flow coincides system reactiondiffusion equations mathbbrd
"Stationary Processes, Wiener-Granger Causality, and Matrix Spectral
  Factorization",Complex Variables,granger causality has become indispensable tool analyzing causal relationships between time series paper we provide detailed overview its mathematical foundations trace its historical development explore how recent computational advancements can enhance its application various fields we will not hesitate present proofs full if they are simple transparent more complex theorems which we rely we will provide supporting citations we also discuss potential future directions method particularly context largescale data analysis
"Stationary Processes, Wiener-Granger Causality, and Matrix Spectral
  Factorization",Complex Variables,granger causality has become indispensable tool analyzing causal relationships between time series paper we provide detailed overview its mathematical foundations trace its historical development explore how recent computational advancements can enhance its application various fields we will not hesitate present proofs full if they are simple transparent more complex theorems which we rely we will provide supporting citations we also discuss potential future directions method particularly context largescale data analysis
"Stationary Processes, Wiener-Granger Causality, and Matrix Spectral
  Factorization",Complex Variables,granger causality has become indispensable tool analyzing causal relationships between time series paper we provide detailed overview its mathematical foundations trace its historical development explore how recent computational advancements can enhance its application various fields we will not hesitate present proofs full if they are simple transparent more complex theorems which we rely we will provide supporting citations we also discuss potential future directions method particularly context largescale data analysis
"Stationary Processes, Wiener-Granger Causality, and Matrix Spectral
  Factorization",Complex Variables,granger causality has become indispensable tool analyzing causal relationships between time series paper we provide detailed overview its mathematical foundations trace its historical development explore how recent computational advancements can enhance its application various fields we will not hesitate present proofs full if they are simple transparent more complex theorems which we rely we will provide supporting citations we also discuss potential future directions method particularly context largescale data analysis
"Stationary Processes, Wiener-Granger Causality, and Matrix Spectral
  Factorization",Complex Variables,granger causality has become indispensable tool analyzing causal relationships between time series paper we provide detailed overview its mathematical foundations trace its historical development explore how recent computational advancements can enhance its application various fields we will not hesitate present proofs full if they are simple transparent more complex theorems which we rely we will provide supporting citations we also discuss potential future directions method particularly context largescale data analysis
"Particle Swarm Optimization: An efficient method for tracing periodic
  orbits in 3D galactic potentials",Astrophysics,we propose particle swarm optimization pso alternative method locating periodic orbits threedimensional model barred galaxies we develop appropriate scheme transforms problem finding periodic orbits into problem detecting global minimizers function which defined poincare surface section pss hamiltonian system combining pso method deflection techniques we succeeded tracing systematically several periodic orbits system method succeeded tracing initial conditions periodic orbits cases where newton iterative techniques had difficulties particular we found families periodic orbits associated inner resonances between radial corotation resonances our ferrers bar model main advantages proposed algorithm its simplicity its ability work using function values solely well its ability locate many periodic orbits per run given jacobian constant
Evolutionary design of photometric systems and its application to Gaia,Astrophysics,designing photometric system best fulfil set scientific goals complex task demanding compromise between conflicting requirements subject various constraints specific example determination stellar astrophysical parameters aps effective temperature metallicity etc across wide range stellar types present novel approach problem which makes minimal assumptions about required filter system considering filter system set free parameters it may be designed optimizing some figureofmerit fom respect these parameters example considered fom measure how well filter system can separate stars different aps separation vectorial nature sense local directions ap variance are preferably mutually orthogonal avoid ap degeneracy optimization carried out evolutionary algorithm which uses principles evolutionary biology search parameter space model hfd heuristic filter design applied design photometric systems gaia space astrometry mission optimized systems show number interesting features not least persistence broad overlapping filters these hfd systems perform least well other proposed systems gaia although inadequacies remain all principles underlying hfd are quite generic may be applied filter design numerous other projects such search specific types objects photometric redshift determination
"Particle Swarm Optimization: An efficient method for tracing periodic
  orbits in 3D galactic potentials",Astrophysics,we propose particle swarm optimization pso alternative method locating periodic orbits threedimensional model barred galaxies we develop appropriate scheme transforms problem finding periodic orbits into problem detecting global minimizers function which defined poincare surface section pss hamiltonian system combining pso method deflection techniques we succeeded tracing systematically several periodic orbits system method succeeded tracing initial conditions periodic orbits cases where newton iterative techniques had difficulties particular we found families periodic orbits associated inner resonances between radial corotation resonances our ferrers bar model main advantages proposed algorithm its simplicity its ability work using function values solely well its ability locate many periodic orbits per run given jacobian constant
"Particle Swarm Optimization: An efficient method for tracing periodic
  orbits in 3D galactic potentials",Astrophysics,we propose particle swarm optimization pso alternative method locating periodic orbits threedimensional model barred galaxies we develop appropriate scheme transforms problem finding periodic orbits into problem detecting global minimizers function which defined poincare surface section pss hamiltonian system combining pso method deflection techniques we succeeded tracing systematically several periodic orbits system method succeeded tracing initial conditions periodic orbits cases where newton iterative techniques had difficulties particular we found families periodic orbits associated inner resonances between radial corotation resonances our ferrers bar model main advantages proposed algorithm its simplicity its ability work using function values solely well its ability locate many periodic orbits per run given jacobian constant
Evolutionary design of photometric systems and its application to Gaia,Astrophysics,designing photometric system best fulfil set scientific goals complex task demanding compromise between conflicting requirements subject various constraints specific example determination stellar astrophysical parameters aps effective temperature metallicity etc across wide range stellar types present novel approach problem which makes minimal assumptions about required filter system considering filter system set free parameters it may be designed optimizing some figureofmerit fom respect these parameters example considered fom measure how well filter system can separate stars different aps separation vectorial nature sense local directions ap variance are preferably mutually orthogonal avoid ap degeneracy optimization carried out evolutionary algorithm which uses principles evolutionary biology search parameter space model hfd heuristic filter design applied design photometric systems gaia space astrometry mission optimized systems show number interesting features not least persistence broad overlapping filters these hfd systems perform least well other proposed systems gaia although inadequacies remain all principles underlying hfd are quite generic may be applied filter design numerous other projects such search specific types objects photometric redshift determination
Learning functions varying along a central subspace,Statistics Theory,many functions interest are highdimensional space but exhibit lowdimensional structures paper studies regression sholder function mathbbrd which varies along central subspace dimension while dll direct approximation mathbbrd varepsilon accuracy requires number samples order varepsilonsds paper we analyze generalized contour regression gcr algorithm estimation central subspace use piecewise polynomials function approximation gcr among best estimators central subspace but its sample complexity open question we prove gcr leads mean squared estimation error central subspace if variance quantity exactly known estimation error variance quantity also given paper mean squared regression error proved be order leftnlog nrightfracssd where exponent depends dimension central subspace instead ambient space result demonstrates gcr effective learning lowdimensional central subspace we also propose modified gcr improved efficiency convergence rate validated through several numerical experiments
Aggregated Hold-Out,Statistics Theory,aggregated holdout agghoo method which averages learning rules selected holdout crossvalidation single split we provide first theoretical guarantees agghoo ensuring it can be used safely agghoo performs worst like holdout when risk convex same holds true classification risk additional constant factor holdout oracle inequalities are known bounded losses binary classification we show similar results can be proved under appropriate assumptions other riskminimization problems particular we obtain oracle inequality regularized kernel regression lipschitz loss without requiring variable regressors be bounded numerical experiments show aggregation brings significant improvement over holdout agghoo competitive crossvalidation
Local angles and dimension estimation from data on manifolds,Statistics Theory,data living manifold msubseteq mathbbrm point pin we consider statistic ukn which estimates variance angle between pairs vectors xip xjp data points xi xj near evaluate statistic tool estimation intrinsic dimension consistency local dimension estimator established asymptotic distribution ukn found under minimal regularity assumptions performance proposed methodology compared against stateoftheart methods simulated data
Margin-adaptive model selection in statistical learning,Statistics Theory,classical condition fast learning rates margin condition first introduced mammen tsybakov we tackle paper problem adaptivity condition context model selection general learning framework actually we consider weaker version condition allows one take into account learning within small model can be much easier than within large one requiring strong margin adaptivity makes model selection problem more challenging we first prove general framework some penalization procedures including local rademacher complexities exhibit adaptivity when models are nested contrary previous results holds penalties only depend data our second main result strong margin adaptivity not always possible when models are not nested every model selection procedure even randomized one there problem which it does not demonstrate strong margin adaptivity
"Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence
  Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian
  Rewards",Statistics Theory,we study extension classic stochastic multiarmed bandit problem which involves multiple plays markovian rewards rested bandits setting order tackle problem we consider adaptive allocation rule which each stage combines information sample means all arms kullbackleibler upper confidence bound single arm which selected roundrobin way rewards generated oneparameter exponential family markov chains we provide finitetime upper bound regret incurred adaptive allocation rule which reveals logarithmic dependence regret time horizon which asymptotically optimal our analysis we devise several concentration results markov chains including maximal inequality markov chains may be interest their own right byproduct our analysis we also establish asymptotically optimal finitetime guarantees case multiple plays iid rewards drawn oneparameter exponential family probability densities additionally we provide simulation results illustrate calculating kullbackleibler upper confidence bounds roundrobin way significantly more efficient than calculating them every arm each round expected regrets those two approaches behave similarly
RNN Decoding of Linear Block Codes,Information Theory,designing practical low complexity close optimal channel decoder powerful algebraic codes short moderate block length open research problem recently it has been shown feedforward neural network architecture can improve standard belief propagation decoding despite large example space paper we introduce recurrent neural network architecture decoding linear block codes our method shows comparable bit error rate results compared feedforward neural network significantly less parameters we also demonstrate improved performance over belief propagation sparser tanner graph representations codes furthermore we demonstrate rnn decoder can be used improve performance alternatively reduce computational complexity mrrd algorithm low complexity close optimal decoding short bch codes
Group-Invariant Subspace Clustering,Information Theory,paper we consider problem group invariant subspace clustering where data assumed come union groupinvariant subspaces vector space ie subspaces which are invariant respect action given group algebraically such groupinvariant subspaces are also referred submodules similar well known sparse subspace clustering approach where data assumed come union subspaces we analyze algorithm which following recent work we refer sparse submodule clustering ssmc method based finding groupsparse selfrepresentation data points paper we primarily derive general conditions under which such groupinvariant subspace identification possible particular we extend geometric analysis process we identify related problem geometric functional analysis
Optimal transport with some directed distances,Information Theory,we present toolkit directed distances between quantile functions employing we solve some new optimal transport ot problems which eg considerably flexibilize some prominent ots expressed through wasserstein distances
Sparse Multinomial Logistic Regression via Approximate Message Passing,Information Theory,problem multiclass linear classification feature selection we propose approximate message passing approaches sparse multinomial logistic regression mlr first we propose two algorithms based hybrid generalized approximate message passing hygamp framework one finds maximum posteriori map linear classifier other finds approximation testerrorrate minimizing linear classifier then we design computationally simplified variants these two algorithms next we detail methods tune hyperparameters their assumed statistical models using steins unbiased risk estimate sure expectationmaximization em respectively finally using both synthetic realworld datasets we demonstrate improved errorrate runtime performance relative existing stateoftheart approaches sparse mlr
Near Maximum Likelihood Decoding with Deep Learning,Information Theory,novel efficient neural decoder algorithm proposed proposed decoder based neural belief propagation algorithm automorphism group combining neural belief propagation permutations automorphism group we achieve near maximum likelihood performance high density parity check codes moreover proposed decoder significantly improves decoding complexity compared our earlier work topic we also investigate training process show how it can be accelerated simulations hessian condition number show why learning process accelerated we demonstrate decoding algorithm various linear block codes length up bits
Genetic Algorithm for SU(N) gauge theory on a lattice,High Energy Physics - Lattice,algorithm proposed simulation pure sun lattice gauge theories based genetic algorithmsgas main difference between gas metropolis methodsmps gas treat population points once while mps treat only one point searching space provides gas information about assortment well fitness evolution function producting better solution we apply gas su pure gauge theory dimensional lattice show results are consistent those given mp heatbath methodshbs thermalization speed gas especially faster than simple mps
Genetic Algorithm for SU(2) Gauge Theory on a 2-dimensional Lattice,High Energy Physics - Lattice,algorithm proposed simulation pure sun lattice gauge theories based genetic algorithmsgas we apply gas su pure gauge theory dimensional lattice show results action per plaquette wilson loops are consistent those metropolis methodmps heatbath methodhbs thermalization speed gas especially faster than simple mps
Deep Learning Hamiltonian Monte Carlo,High Energy Physics - Lattice,we generalize hamiltonian monte carlo algorithm stack neural network layers evaluate its ability sample different topologies two dimensional lattice gauge theory we demonstrate our model able successfully mix between modes different topologies significantly reducing computational cost required generated independent gauge field configurations our implementation available httpsgithubcomsaforemlhmcqcd
Genetic Algorithm for SU(2) Gauge Theory on a 2-dimensional Lattice,High Energy Physics - Lattice,algorithm proposed simulation pure sun lattice gauge theories based genetic algorithmsgas we apply gas su pure gauge theory dimensional lattice show results action per plaquette wilson loops are consistent those metropolis methodmps heatbath methodhbs thermalization speed gas especially faster than simple mps
Genetic Algorithm for SU(2) Gauge Theory on a 2-dimensional Lattice,High Energy Physics - Lattice,algorithm proposed simulation pure sun lattice gauge theories based genetic algorithmsgas we apply gas su pure gauge theory dimensional lattice show results action per plaquette wilson loops are consistent those metropolis methodmps heatbath methodhbs thermalization speed gas especially faster than simple mps
On Random Matrices Arising in Deep Neural Networks. Gaussian Case,Mathematical Physics,paper deals distribution singular values product random matrices arising analysis deep neural networks matrices resemble product analogs sample covariance matrices however important difference population covariance matrices which are assumed be nonrandom standard setting statistics random matrix theory are now random moreover are certain functions random data matrices problem has been considered recent work using techniques free probability theory since however free probability theory deals population matrices which are independent data matrices its applicability case requires additional justification we present justification using version standard techniques random matrix theory under assumption entries data matrices are independent gaussian random variables subsequent paper we extend our results case where entries data matrices are just independent identically distributed random variables several finite moments particular extends property socalled macroscopic universality considered random matrices
Multiscale Sparse Microcanonical Models,Mathematical Physics,we study approximations nongaussian stationary processes having long range correlations microcanonical models these models are conditioned empirical value energy vector evaluated single realization asymptotic properties maximum entropy microcanonical macrocanonical processes their convergence gibbs measures are reviewed we show jacobian energy vector controls entropy rate microcanonical processes sampling maximum entropy processes through mcmc algorithms require too many operations when number constraints large we define microcanonical gradient descent processes transporting maximum entropy measure gradient descent algorithm which enforces energy conditions convergence symmetries are analyzed approximations nongaussian processes long range interactions are defined multiscale energy vectors computed wavelet scattering transforms sparsity properties are captured bf norms approximations gaussian ising point processes are studied well image audio texture synthesis
On Random Matrices Arising in Deep Neural Networks. Gaussian Case,Mathematical Physics,paper deals distribution singular values product random matrices arising analysis deep neural networks matrices resemble product analogs sample covariance matrices however important difference population covariance matrices which are assumed be nonrandom standard setting statistics random matrix theory are now random moreover are certain functions random data matrices problem has been considered recent work using techniques free probability theory since however free probability theory deals population matrices which are independent data matrices its applicability case requires additional justification we present justification using version standard techniques random matrix theory under assumption entries data matrices are independent gaussian random variables subsequent paper we extend our results case where entries data matrices are just independent identically distributed random variables several finite moments particular extends property socalled macroscopic universality considered random matrices
On Random Matrices Arising in Deep Neural Networks. Gaussian Case,Mathematical Physics,paper deals distribution singular values product random matrices arising analysis deep neural networks matrices resemble product analogs sample covariance matrices however important difference population covariance matrices which are assumed be nonrandom standard setting statistics random matrix theory are now random moreover are certain functions random data matrices problem has been considered recent work using techniques free probability theory since however free probability theory deals population matrices which are independent data matrices its applicability case requires additional justification we present justification using version standard techniques random matrix theory under assumption entries data matrices are independent gaussian random variables subsequent paper we extend our results case where entries data matrices are just independent identically distributed random variables several finite moments particular extends property socalled macroscopic universality considered random matrices
On Random Matrices Arising in Deep Neural Networks. Gaussian Case,Mathematical Physics,paper deals distribution singular values product random matrices arising analysis deep neural networks matrices resemble product analogs sample covariance matrices however important difference population covariance matrices which are assumed be nonrandom standard setting statistics random matrix theory are now random moreover are certain functions random data matrices problem has been considered recent work using techniques free probability theory since however free probability theory deals population matrices which are independent data matrices its applicability case requires additional justification we present justification using version standard techniques random matrix theory under assumption entries data matrices are independent gaussian random variables subsequent paper we extend our results case where entries data matrices are just independent identically distributed random variables several finite moments particular extends property socalled macroscopic universality considered random matrices
"Learning-based Model Predictive Control for Smart Building Thermal
  Management",Systems and Control (Electrical Engineering and Systems Science),paper proposes learningbased model predictive control mpc approach thermal control fourzone smart building objectives are minimize energy consumption maintain residents comfort proposed control scheme incorporates learning modelbased control occupancy profile building zones are estimated longterm horizon through artificial neural network ann data fed into modelbased predictor get indoor temperature predictions energy plus software utilized actual dataset provider weather data indoor temperature energy consumption optimization problem including actual predicted data solved each step simulation input setpoint temperature heatingcooling system generated comparing results proposed approach conventional mpc results proved significantly better performance proposed method energy savings less cooling power consumption less heating power consumption residents comfort
"Real-Time Progressive Learning: Accumulate Knowledge from Control with
  Neural-Network-Based Selective Memory",Systems and Control (Electrical Engineering and Systems Science),memory basis learning determines storage update forgetting knowledge further determines efficiency learning featured mechanism memory radial basis function neural network based learning control scheme named realtime progressive learning rtpl proposed learn unknown dynamics system guaranteed stability closedloop performance instead lyapunovbased weight update law conventional neural network learning control nnlc which mainly concentrates stability control performance rtpl employs selective memory recursive least squares smrls algorithm update weights neural network achieves following merits improved learning speed without filtering robustness hyperparameter setting neural networks good generalization ability ie reuse learned knowledge different tasks guaranteed learning performance under parameter perturbation moreover rtpl realizes continuous accumulation knowledge result its reasonably allocated memory while nnlc may gradually forget knowledge it has learned corresponding theoretical analysis simulation studies demonstrate effectiveness rtpl
"Multi-objective Evolutionary Approach to Grey-Box Identification of Buck
  Converter",Systems and Control (Electrical Engineering and Systems Science),present study proposes simple greybox identification approach model real dcdc buck converter operating continuous conduction mode problem associated information void observed dynamical data which often obtained over relatively narrow input range alleviated exploiting known static behavior buck converter priori knowledge simple method developed based concept term clusters determine static response candidate models error static behavior then directly embedded into multiobjective framework structure selection essence proposed approach casts greybox identification problem into multiobjective framework balance biasvariance dilemma model building while explicitly integrating priori knowledge into structure selection process results investigation considering case practical buck converter demonstrate it possible identify parsimonious models which can capture both dynamic static behavior system over wide input range
"A Cloud-Edge Framework for Energy-Efficient Event-Driven Control: An
  Integration of Online Supervised Learning, Spiking Neural Networks and Local
  Plasticity Rules",Systems and Control (Electrical Engineering and Systems Science),paper presents novel cloudedge framework addressing computational energy constraints complex control systems our approach centers around learningbased controller using spiking neural networks snn physical plants integrating biologically plausible learning method local plasticity rules we harness efficiency scalability low latency snns design replicates control signals cloudbased controller directly plant reducing need constant plantcloud communication plant updates weights only when errors surpass predefined thresholds ensuring efficiency robustness various conditions applied linear workbench systems satellite rendezvous scenarios including obstacle avoidance our architecture dramatically lowers normalized tracking error increased network size eventdriven nature snns minimizes energy consumption utilizing only about nj conventional computing requirements results demonstrate systems adjustment changing work environments its efficient use computational energy resources moderate increase energy consumption static dynamic obstacles respectively compared nonobstacle scenarios
Deep State Space Models for Nonlinear System Identification,Systems and Control (Electrical Engineering and Systems Science),deep state space models ssms are actively researched model class temporal models developed deep learning community which have close connection classic ssms use deep ssms blackbox identification model can describe wide range dynamics due flexibility deep neural networks additionally probabilistic nature model class allows uncertainty system be modelled work deep ssm class its parameter learning algorithm are explained effort extend toolbox nonlinear identification methods deep learning based method six recent deep ssms are evaluated first unified implementation nonlinear system identification benchmarks
Emulating the Global Change Analysis Model with Deep Learning,General Economics,global change analysis model gcam simulates complex interactions between coupled earth human systems providing valuable insights into coevolution land water energy sectors under different future scenarios understanding sensitivities drivers multisectoral system can lead more robust understanding different pathways particular outcomes interactions complexity coupled humanearth systems make gcam simulations costly run scale requirement large ensemble experiments which explore uncertainty model parameters outputs differentiable emulator similar predictive power but greater efficiency could provide novel scenario discovery analysis gcam its outputs requiring fewer runs gcam first use case we train neural network existing large ensemble explores range gcam inputs related different relative contributions energy production sources focus wind solar we complement existing ensemble interpolated input values wider selection outputs predicting gcam outputs across time sectors regions we report median score emulators predictions score its inputoutput sensitivity
How Many Online Workers are there in the World? A Data-Driven Assessment,General Economics,unknown number people around world are earning income working through online labour platforms such upwork amazon mechanical turk we combine data collected various sources build datadriven assessment number such online workers also known online freelancers globally our headline estimate there are million freelancer profiles registered online labour platforms globally approximately million them have obtained work through platform least once million have completed least projects earned least these numbers suggest substantial growth registered worker accounts but much less growth amount work completed workers our results indicate online freelancing represents nontrivial segment labour today but one spread thinly across countries sectors
Emulating the Global Change Analysis Model with Deep Learning,General Economics,global change analysis model gcam simulates complex interactions between coupled earth human systems providing valuable insights into coevolution land water energy sectors under different future scenarios understanding sensitivities drivers multisectoral system can lead more robust understanding different pathways particular outcomes interactions complexity coupled humanearth systems make gcam simulations costly run scale requirement large ensemble experiments which explore uncertainty model parameters outputs differentiable emulator similar predictive power but greater efficiency could provide novel scenario discovery analysis gcam its outputs requiring fewer runs gcam first use case we train neural network existing large ensemble explores range gcam inputs related different relative contributions energy production sources focus wind solar we complement existing ensemble interpolated input values wider selection outputs predicting gcam outputs across time sectors regions we report median score emulators predictions score its inputoutput sensitivity
Emulating the Global Change Analysis Model with Deep Learning,General Economics,global change analysis model gcam simulates complex interactions between coupled earth human systems providing valuable insights into coevolution land water energy sectors under different future scenarios understanding sensitivities drivers multisectoral system can lead more robust understanding different pathways particular outcomes interactions complexity coupled humanearth systems make gcam simulations costly run scale requirement large ensemble experiments which explore uncertainty model parameters outputs differentiable emulator similar predictive power but greater efficiency could provide novel scenario discovery analysis gcam its outputs requiring fewer runs gcam first use case we train neural network existing large ensemble explores range gcam inputs related different relative contributions energy production sources focus wind solar we complement existing ensemble interpolated input values wider selection outputs predicting gcam outputs across time sectors regions we report median score emulators predictions score its inputoutput sensitivity
How Many Online Workers are there in the World? A Data-Driven Assessment,General Economics,unknown number people around world are earning income working through online labour platforms such upwork amazon mechanical turk we combine data collected various sources build datadriven assessment number such online workers also known online freelancers globally our headline estimate there are million freelancer profiles registered online labour platforms globally approximately million them have obtained work through platform least once million have completed least projects earned least these numbers suggest substantial growth registered worker accounts but much less growth amount work completed workers our results indicate online freelancing represents nontrivial segment labour today but one spread thinly across countries sectors
Computer Assisted Localization of a Heart Arrhythmia,Tissues and Organs,we consider problem locating pointsource heart arrhythmia using data standard diagnostic procedure where reference catheter placed heart arrival times second diagnostic catheter are recorded diagnostic catheter moves around within heart we model situation nonconvex feasibility problem where given set arrival times we look source location consistent available data we develop new optimization approach fast algorithm obtain online proposals next location suggest operator she collects data we validate procedure using monte carlo simulation based patients electrophysiological data proposed procedure robustly quickly locates source arrhythmias without any prior knowledge heart anatomy
Computer Assisted Localization of a Heart Arrhythmia,Tissues and Organs,we consider problem locating pointsource heart arrhythmia using data standard diagnostic procedure where reference catheter placed heart arrival times second diagnostic catheter are recorded diagnostic catheter moves around within heart we model situation nonconvex feasibility problem where given set arrival times we look source location consistent available data we develop new optimization approach fast algorithm obtain online proposals next location suggest operator she collects data we validate procedure using monte carlo simulation based patients electrophysiological data proposed procedure robustly quickly locates source arrhythmias without any prior knowledge heart anatomy
Computer Assisted Localization of a Heart Arrhythmia,Tissues and Organs,we consider problem locating pointsource heart arrhythmia using data standard diagnostic procedure where reference catheter placed heart arrival times second diagnostic catheter are recorded diagnostic catheter moves around within heart we model situation nonconvex feasibility problem where given set arrival times we look source location consistent available data we develop new optimization approach fast algorithm obtain online proposals next location suggest operator she collects data we validate procedure using monte carlo simulation based patients electrophysiological data proposed procedure robustly quickly locates source arrhythmias without any prior knowledge heart anatomy
Computer Assisted Localization of a Heart Arrhythmia,Tissues and Organs,we consider problem locating pointsource heart arrhythmia using data standard diagnostic procedure where reference catheter placed heart arrival times second diagnostic catheter are recorded diagnostic catheter moves around within heart we model situation nonconvex feasibility problem where given set arrival times we look source location consistent available data we develop new optimization approach fast algorithm obtain online proposals next location suggest operator she collects data we validate procedure using monte carlo simulation based patients electrophysiological data proposed procedure robustly quickly locates source arrhythmias without any prior knowledge heart anatomy
Computer Assisted Localization of a Heart Arrhythmia,Tissues and Organs,we consider problem locating pointsource heart arrhythmia using data standard diagnostic procedure where reference catheter placed heart arrival times second diagnostic catheter are recorded diagnostic catheter moves around within heart we model situation nonconvex feasibility problem where given set arrival times we look source location consistent available data we develop new optimization approach fast algorithm obtain online proposals next location suggest operator she collects data we validate procedure using monte carlo simulation based patients electrophysiological data proposed procedure robustly quickly locates source arrhythmias without any prior knowledge heart anatomy
"Optimal estimation for Large-Eddy Simulation of turbulence and
  application to the analysis of subgrid models",Classical Physics,tools optimal estimation are applied study subgrid models largeeddy simulation turbulence concept optimal estimator introduced its properties are analyzed context applications priori tests subgrid models attention focused cook riley model case scalar field isotropic turbulence using dns data relevance beta assumption estimated computing generalized optimal estimators ii error brought assumption alone optimal estimators are computed subgrid variance using various sets variables various techniques histograms neural networks it shown optimal estimators allow thorough exploration models neural networks are proved be relevant very efficient framework further usages are suggested
"Optimal estimation for Large-Eddy Simulation of turbulence and
  application to the analysis of subgrid models",Classical Physics,tools optimal estimation are applied study subgrid models largeeddy simulation turbulence concept optimal estimator introduced its properties are analyzed context applications priori tests subgrid models attention focused cook riley model case scalar field isotropic turbulence using dns data relevance beta assumption estimated computing generalized optimal estimators ii error brought assumption alone optimal estimators are computed subgrid variance using various sets variables various techniques histograms neural networks it shown optimal estimators allow thorough exploration models neural networks are proved be relevant very efficient framework further usages are suggested
"Optimal estimation for Large-Eddy Simulation of turbulence and
  application to the analysis of subgrid models",Classical Physics,tools optimal estimation are applied study subgrid models largeeddy simulation turbulence concept optimal estimator introduced its properties are analyzed context applications priori tests subgrid models attention focused cook riley model case scalar field isotropic turbulence using dns data relevance beta assumption estimated computing generalized optimal estimators ii error brought assumption alone optimal estimators are computed subgrid variance using various sets variables various techniques histograms neural networks it shown optimal estimators allow thorough exploration models neural networks are proved be relevant very efficient framework further usages are suggested
"Optimal estimation for Large-Eddy Simulation of turbulence and
  application to the analysis of subgrid models",Classical Physics,tools optimal estimation are applied study subgrid models largeeddy simulation turbulence concept optimal estimator introduced its properties are analyzed context applications priori tests subgrid models attention focused cook riley model case scalar field isotropic turbulence using dns data relevance beta assumption estimated computing generalized optimal estimators ii error brought assumption alone optimal estimators are computed subgrid variance using various sets variables various techniques histograms neural networks it shown optimal estimators allow thorough exploration models neural networks are proved be relevant very efficient framework further usages are suggested
"Optimal estimation for Large-Eddy Simulation of turbulence and
  application to the analysis of subgrid models",Classical Physics,tools optimal estimation are applied study subgrid models largeeddy simulation turbulence concept optimal estimator introduced its properties are analyzed context applications priori tests subgrid models attention focused cook riley model case scalar field isotropic turbulence using dns data relevance beta assumption estimated computing generalized optimal estimators ii error brought assumption alone optimal estimators are computed subgrid variance using various sets variables various techniques histograms neural networks it shown optimal estimators allow thorough exploration models neural networks are proved be relevant very efficient framework further usages are suggested
"Harnessing the Power of Gradient-Based Simulations for Multi-Objective
  Optimization in Particle Accelerators",Accelerator Physics,particle accelerator operation requires simultaneous optimization multiple objectives multiobjective optimization moo particularly challenging due tradeoffs between objectives evolutionary algorithms such genetic algorithm ga have been leveraged many optimization problems however they do not apply complex control problems design paper demonstrates power differentiability solving moo problems using deep differentiable reinforcement learning ddrl algorithm particle accelerators we compare ddrl algorithm model free reinforcement learning mfrl ga bayesian optimization bo simultaneous optimization heat load trip rates continuous electron beam accelerator facility cebaf underlying problem enforces strict constraints both individual states actions well cumulative global constraint energy requirements beam physicsbased surrogate model based real data developed surrogate model differentiable allows backpropagation gradients results are evaluated form paretofront two objectives we show ddrl outperforms mfrl bo ga high dimensional problems
Towards Unlocking Insights from Logbooks Using AI,Accelerator Physics,electronic logbooks contain valuable information about activities events concerning their associated particle accelerator facilities however highly technical nature logbook entries can hinder their usability automation natural language processing nlp continues advancing it offers opportunities address various challenges logbooks present work explores jointly testing tailored retrieval augmented generation rag model enhancing usability particle accelerator logbooks institutes like desy bessy fermilab bnl slac lbnl cern rag model uses corpus built logbook contributions aims unlock insights these logbooks leveraging retrieval over facility datasets including discussion about potential multimodal sources our goals are increase fairness findability accessibility interoperability reusability logbooks exploiting their information content streamline everyday use enable macroanalysis root cause analysis facilitate problemsolving automation
"Machine learning for design optimization of storage ring nonlinear
  dynamics",Accelerator Physics,novel approach expedite design optimization nonlinear beam dynamics storage rings proposed demonstrated study each iteration neural network surrogate model used suggest new trial solutions multiobjective optimization task surrogate model then updated new solutions process repeated until final optimized solution obtained we apply approach optimize nonlinear beam dynamics spear storage ring where sextupole knobs are adjusted simultaneously improve dynamic aperture momentum aperture approach shown converge pareto front considerably faster than genetic particle swarm algorithms
"Harnessing the Power of Gradient-Based Simulations for Multi-Objective
  Optimization in Particle Accelerators",Accelerator Physics,particle accelerator operation requires simultaneous optimization multiple objectives multiobjective optimization moo particularly challenging due tradeoffs between objectives evolutionary algorithms such genetic algorithm ga have been leveraged many optimization problems however they do not apply complex control problems design paper demonstrates power differentiability solving moo problems using deep differentiable reinforcement learning ddrl algorithm particle accelerators we compare ddrl algorithm model free reinforcement learning mfrl ga bayesian optimization bo simultaneous optimization heat load trip rates continuous electron beam accelerator facility cebaf underlying problem enforces strict constraints both individual states actions well cumulative global constraint energy requirements beam physicsbased surrogate model based real data developed surrogate model differentiable allows backpropagation gradients results are evaluated form paretofront two objectives we show ddrl outperforms mfrl bo ga high dimensional problems
"Harnessing the Power of Gradient-Based Simulations for Multi-Objective
  Optimization in Particle Accelerators",Accelerator Physics,particle accelerator operation requires simultaneous optimization multiple objectives multiobjective optimization moo particularly challenging due tradeoffs between objectives evolutionary algorithms such genetic algorithm ga have been leveraged many optimization problems however they do not apply complex control problems design paper demonstrates power differentiability solving moo problems using deep differentiable reinforcement learning ddrl algorithm particle accelerators we compare ddrl algorithm model free reinforcement learning mfrl ga bayesian optimization bo simultaneous optimization heat load trip rates continuous electron beam accelerator facility cebaf underlying problem enforces strict constraints both individual states actions well cumulative global constraint energy requirements beam physicsbased surrogate model based real data developed surrogate model differentiable allows backpropagation gradients results are evaluated form paretofront two objectives we show ddrl outperforms mfrl bo ga high dimensional problems
Hybrid Synaptic Structure for Spiking Neural Network Realization,Superconductivity,neural networks neuromorphic computing play pivotal roles deep learning machine vision due their dissipative nature inherent limitations traditional semiconductorbased circuits face challenges realizing ultrafast lowpower neural networks however spiking behavior characteristic single flux quantum sfq circuits positions them promising candidates spiking neural networks snns our previous work showcased jjsoma design capable operating tens gigahertz while consuming only fraction power compared traditional circuits documented paper introduces compact sfqbased synapse design applies positive negative weighted inputs jjsoma using rsfq synapse empowers us replicate functionality biological neuron crucial step realizing complete snn jjsynapse can operate ultrahigh frequencies exhibits orders magnitude lower power consumption than cmos counterparts can be conveniently fabricated using commercial nb processes furthermore networks flexibility enables modifications incorporating cryocmos circuits weight value adjustments our endeavor we have successfully designed fabricated partially tested jjsynapse within our cryocooler system integration jjsoma further facilitates realization highspeed inference snn
Hybrid Synaptic Structure for Spiking Neural Network Realization,Superconductivity,neural networks neuromorphic computing play pivotal roles deep learning machine vision due their dissipative nature inherent limitations traditional semiconductorbased circuits face challenges realizing ultrafast lowpower neural networks however spiking behavior characteristic single flux quantum sfq circuits positions them promising candidates spiking neural networks snns our previous work showcased jjsoma design capable operating tens gigahertz while consuming only fraction power compared traditional circuits documented paper introduces compact sfqbased synapse design applies positive negative weighted inputs jjsoma using rsfq synapse empowers us replicate functionality biological neuron crucial step realizing complete snn jjsynapse can operate ultrahigh frequencies exhibits orders magnitude lower power consumption than cmos counterparts can be conveniently fabricated using commercial nb processes furthermore networks flexibility enables modifications incorporating cryocmos circuits weight value adjustments our endeavor we have successfully designed fabricated partially tested jjsynapse within our cryocooler system integration jjsoma further facilitates realization highspeed inference snn
Hybrid Synaptic Structure for Spiking Neural Network Realization,Superconductivity,neural networks neuromorphic computing play pivotal roles deep learning machine vision due their dissipative nature inherent limitations traditional semiconductorbased circuits face challenges realizing ultrafast lowpower neural networks however spiking behavior characteristic single flux quantum sfq circuits positions them promising candidates spiking neural networks snns our previous work showcased jjsoma design capable operating tens gigahertz while consuming only fraction power compared traditional circuits documented paper introduces compact sfqbased synapse design applies positive negative weighted inputs jjsoma using rsfq synapse empowers us replicate functionality biological neuron crucial step realizing complete snn jjsynapse can operate ultrahigh frequencies exhibits orders magnitude lower power consumption than cmos counterparts can be conveniently fabricated using commercial nb processes furthermore networks flexibility enables modifications incorporating cryocmos circuits weight value adjustments our endeavor we have successfully designed fabricated partially tested jjsynapse within our cryocooler system integration jjsoma further facilitates realization highspeed inference snn
Hybrid Synaptic Structure for Spiking Neural Network Realization,Superconductivity,neural networks neuromorphic computing play pivotal roles deep learning machine vision due their dissipative nature inherent limitations traditional semiconductorbased circuits face challenges realizing ultrafast lowpower neural networks however spiking behavior characteristic single flux quantum sfq circuits positions them promising candidates spiking neural networks snns our previous work showcased jjsoma design capable operating tens gigahertz while consuming only fraction power compared traditional circuits documented paper introduces compact sfqbased synapse design applies positive negative weighted inputs jjsoma using rsfq synapse empowers us replicate functionality biological neuron crucial step realizing complete snn jjsynapse can operate ultrahigh frequencies exhibits orders magnitude lower power consumption than cmos counterparts can be conveniently fabricated using commercial nb processes furthermore networks flexibility enables modifications incorporating cryocmos circuits weight value adjustments our endeavor we have successfully designed fabricated partially tested jjsynapse within our cryocooler system integration jjsoma further facilitates realization highspeed inference snn
Hybrid Synaptic Structure for Spiking Neural Network Realization,Superconductivity,neural networks neuromorphic computing play pivotal roles deep learning machine vision due their dissipative nature inherent limitations traditional semiconductorbased circuits face challenges realizing ultrafast lowpower neural networks however spiking behavior characteristic single flux quantum sfq circuits positions them promising candidates spiking neural networks snns our previous work showcased jjsoma design capable operating tens gigahertz while consuming only fraction power compared traditional circuits documented paper introduces compact sfqbased synapse design applies positive negative weighted inputs jjsoma using rsfq synapse empowers us replicate functionality biological neuron crucial step realizing complete snn jjsynapse can operate ultrahigh frequencies exhibits orders magnitude lower power consumption than cmos counterparts can be conveniently fabricated using commercial nb processes furthermore networks flexibility enables modifications incorporating cryocmos circuits weight value adjustments our endeavor we have successfully designed fabricated partially tested jjsynapse within our cryocooler system integration jjsoma further facilitates realization highspeed inference snn
Learning spatio-temporal patterns with Neural Cellular Automata,Pattern Formation and Solitons,neural cellular automata nca are powerful combination machine learning mechanistic modelling we train nca learn complex dynamics time series images pde trajectories our method designed identify underlying local rules govern large scale dynamic emergent behaviours previous work nca focuses learning rules give stationary emergent structures we extend nca capture both transient stable structures within same system well learning rules capture dynamics turing pattern formation nonlinear partial differential equations pdes we demonstrate nca can generalise very well beyond their pde training data we show how constrain nca respect given symmetries we explore effects associated hyperparameters model performance stability being able learn arbitrary dynamics gives nca great potential data driven modelling framework especially modelling biological pattern formation
Learning spatio-temporal patterns with Neural Cellular Automata,Pattern Formation and Solitons,neural cellular automata nca are powerful combination machine learning mechanistic modelling we train nca learn complex dynamics time series images pde trajectories our method designed identify underlying local rules govern large scale dynamic emergent behaviours previous work nca focuses learning rules give stationary emergent structures we extend nca capture both transient stable structures within same system well learning rules capture dynamics turing pattern formation nonlinear partial differential equations pdes we demonstrate nca can generalise very well beyond their pde training data we show how constrain nca respect given symmetries we explore effects associated hyperparameters model performance stability being able learn arbitrary dynamics gives nca great potential data driven modelling framework especially modelling biological pattern formation
Learning spatio-temporal patterns with Neural Cellular Automata,Pattern Formation and Solitons,neural cellular automata nca are powerful combination machine learning mechanistic modelling we train nca learn complex dynamics time series images pde trajectories our method designed identify underlying local rules govern large scale dynamic emergent behaviours previous work nca focuses learning rules give stationary emergent structures we extend nca capture both transient stable structures within same system well learning rules capture dynamics turing pattern formation nonlinear partial differential equations pdes we demonstrate nca can generalise very well beyond their pde training data we show how constrain nca respect given symmetries we explore effects associated hyperparameters model performance stability being able learn arbitrary dynamics gives nca great potential data driven modelling framework especially modelling biological pattern formation
Learning spatio-temporal patterns with Neural Cellular Automata,Pattern Formation and Solitons,neural cellular automata nca are powerful combination machine learning mechanistic modelling we train nca learn complex dynamics time series images pde trajectories our method designed identify underlying local rules govern large scale dynamic emergent behaviours previous work nca focuses learning rules give stationary emergent structures we extend nca capture both transient stable structures within same system well learning rules capture dynamics turing pattern formation nonlinear partial differential equations pdes we demonstrate nca can generalise very well beyond their pde training data we show how constrain nca respect given symmetries we explore effects associated hyperparameters model performance stability being able learn arbitrary dynamics gives nca great potential data driven modelling framework especially modelling biological pattern formation
Learning spatio-temporal patterns with Neural Cellular Automata,Pattern Formation and Solitons,neural cellular automata nca are powerful combination machine learning mechanistic modelling we train nca learn complex dynamics time series images pde trajectories our method designed identify underlying local rules govern large scale dynamic emergent behaviours previous work nca focuses learning rules give stationary emergent structures we extend nca capture both transient stable structures within same system well learning rules capture dynamics turing pattern formation nonlinear partial differential equations pdes we demonstrate nca can generalise very well beyond their pde training data we show how constrain nca respect given symmetries we explore effects associated hyperparameters model performance stability being able learn arbitrary dynamics gives nca great potential data driven modelling framework especially modelling biological pattern formation
Dutch Cross Serial Dependencies in HPSG,Computation and Language (Legacy category),we present analysis dutch cross serial dependencies headdriven phrase structure grammar arguably our analysis differs other analyses we do not refer additional mechanisms eg sequence union head wrapping just standard structure sharing immediate dominance schema linear precedence rule
Higher-Order Coloured Unification and Natural Language Semantics,Computation and Language (Legacy category),paper we show higherorder coloured unification form unification developed automated theorem proving provides general theory modeling interface between interpretation process other sources linguistic non semantic information particular it provides general theory primary occurrence restriction which dalrymple shieber pereira analysis called
Conciseness through Aggregation in Text Generation,Computation and Language (Legacy category),aggregating different pieces similar information necessary generate concise easy understand reports technical domains paper presents general algorithm combines similar messages order generate one more coherent sentences them process not trivial might be expected problems encountered are briefly described
Construction of a Bilingual Dictionary Intermediated by a Third Language,Computation and Language (Legacy category),when using third language construct bilingual dictionary it necessary discriminate equivalencies inappropriate words derived result ambiguity third language we propose method treat utilizing structures dictionaries measure nearness meanings words resulting dictionary wordtoword bilingual dictionary nouns can be used refine entries equivalencies published bilingual dictionaries
Uniform Representations for Syntax-Semantics Arbitration,Computation and Language (Legacy category),psychological investigations have led considerable insight into working human language comprehension system article we look set principles derived psychological findings argue particular organization linguistic knowledge along particular processing strategy present computational model sentence processing based those principles many studies have shown human sentence comprehension incremental interactive process which semantic other higherlevel information interacts syntactic information make informed commitments early possible local ambiguity early commitments may be made using topdown guidance knowledge different types each which must be applicable independently others further evidence studies error recovery delayed decisions points toward arbitration mechanism combining syntactic semantic information resolving ambiguities order account all above we propose all types linguistic knowledge must be represented common form but must be separable so they can be applied independently each other integrated processing time arbitrator we present such uniform representation computational model called compere based representation processing strategy
"Homophonic Quotients of Linguistic Free Groups: German, Korean, and
  Turkish",Group Theory,homophonic quotient groups french english quotient free group generated french respectively english alphabet determined relations representing standard pronunciation rules were explicitly characterized paper we apply same methodology three different language systems german korean turkish we argue our results point some interesting differences between these three languages least their current script systems
Anagrammatic quotients of free groups,Group Theory,we determine structure quotient free group generators english language anagrams group admits surprisingly simple presentation quotient free group possible commutators pairs generators all missing commutators involve least one letters we describe algorithm which can be used determine group given any dictionary provide examples sowpods scrabble dictionary witnessing commutators found
"Homophonic Quotients of Linguistic Free Groups: German, Korean, and
  Turkish",Group Theory,homophonic quotient groups french english quotient free group generated french respectively english alphabet determined relations representing standard pronunciation rules were explicitly characterized paper we apply same methodology three different language systems german korean turkish we argue our results point some interesting differences between these three languages least their current script systems
"Homophonic Quotients of Linguistic Free Groups: German, Korean, and
  Turkish",Group Theory,homophonic quotient groups french english quotient free group generated french respectively english alphabet determined relations representing standard pronunciation rules were explicitly characterized paper we apply same methodology three different language systems german korean turkish we argue our results point some interesting differences between these three languages least their current script systems
"Homophonic Quotients of Linguistic Free Groups: German, Korean, and
  Turkish",Group Theory,homophonic quotient groups french english quotient free group generated french respectively english alphabet determined relations representing standard pronunciation rules were explicitly characterized paper we apply same methodology three different language systems german korean turkish we argue our results point some interesting differences between these three languages least their current script systems
What can we know about that which we cannot even imagine?,History and Philosophy of Physics,essay will consider sequence questions first questions concern biological function intelligence general cognitive prostheses human intelligence particular these will lead into questions concerning human language perhaps most important cognitive prosthesis humanity has ever developed while it traditional rhapsodize about cognitive power encapsulated human language will emphasize how horribly limited human language therefore how limited our cognitive abilities are despite their being augmented language will lead questions whether human mathematics being ultimately formulated terms human language also deeply limited will then combine these questions pose partial sortof sideways answer guiding concern essay what we can ever discern about we cannot even conceive
What can we know about that which we cannot even imagine?,History and Philosophy of Physics,essay will consider sequence questions first questions concern biological function intelligence general cognitive prostheses human intelligence particular these will lead into questions concerning human language perhaps most important cognitive prosthesis humanity has ever developed while it traditional rhapsodize about cognitive power encapsulated human language will emphasize how horribly limited human language therefore how limited our cognitive abilities are despite their being augmented language will lead questions whether human mathematics being ultimately formulated terms human language also deeply limited will then combine these questions pose partial sortof sideways answer guiding concern essay what we can ever discern about we cannot even conceive
What can we know about that which we cannot even imagine?,History and Philosophy of Physics,essay will consider sequence questions first questions concern biological function intelligence general cognitive prostheses human intelligence particular these will lead into questions concerning human language perhaps most important cognitive prosthesis humanity has ever developed while it traditional rhapsodize about cognitive power encapsulated human language will emphasize how horribly limited human language therefore how limited our cognitive abilities are despite their being augmented language will lead questions whether human mathematics being ultimately formulated terms human language also deeply limited will then combine these questions pose partial sortof sideways answer guiding concern essay what we can ever discern about we cannot even conceive
What can we know about that which we cannot even imagine?,History and Philosophy of Physics,essay will consider sequence questions first questions concern biological function intelligence general cognitive prostheses human intelligence particular these will lead into questions concerning human language perhaps most important cognitive prosthesis humanity has ever developed while it traditional rhapsodize about cognitive power encapsulated human language will emphasize how horribly limited human language therefore how limited our cognitive abilities are despite their being augmented language will lead questions whether human mathematics being ultimately formulated terms human language also deeply limited will then combine these questions pose partial sortof sideways answer guiding concern essay what we can ever discern about we cannot even conceive
What can we know about that which we cannot even imagine?,History and Philosophy of Physics,essay will consider sequence questions first questions concern biological function intelligence general cognitive prostheses human intelligence particular these will lead into questions concerning human language perhaps most important cognitive prosthesis humanity has ever developed while it traditional rhapsodize about cognitive power encapsulated human language will emphasize how horribly limited human language therefore how limited our cognitive abilities are despite their being augmented language will lead questions whether human mathematics being ultimately formulated terms human language also deeply limited will then combine these questions pose partial sortof sideways answer guiding concern essay what we can ever discern about we cannot even conceive
